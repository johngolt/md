#### 概述

推荐系统就是系统根据用户的属性，用户在系统里过去的行为，以及当前上下文环境 ( 如网络、手机设备、时间等 )，从而给用户推荐用户可能感兴趣的物品，从这个过程来看，推荐系统就是一个给 user 匹配感兴趣的 item 的过程。推荐和搜索有很多相同又有很多不同的地方，放到一起的原因是两者其实都是一个 match 的过程，搜索引擎需要 match 的是 query 和相关的 doc；推荐系统需要 match 的是 user和相关的 item。

###### 搜索与推荐

不同之处：

1. 意图不同：搜索是用户带着明确的目的，通过给系统输入 query 来主动触发的，搜索过程用户带着明确的搜索意图。而推荐是系统被动触发，用户是以一种闲逛的姿态过来的，系统是带着一种 "猜" 的状态给用户推送物品。
2. 时效不同：搜索需要尽快满足用户此次请求 query，推荐更希望能增加用户的时长和留存从而提升整体 LTV 。
3. 相关性要求不同：搜索有严格的 query 限制，搜索结果需要保证相关性，搜索结果量化评估标准也相对容易。给定一个 query，系统给出不同结果，在上线前就可以通过相关性对结果进行判定相关性好坏。而推荐没有明确的相关性要求。推荐很难在离线阶段从相关性角度结果评定是否好坏，只能从线上效果看用户是否买单做评估。
4. 实体不同：搜索中的两大实体是 query 和 doc，本质上都是文本信息。这就是上文说到的为什么搜索可以通过 query 和 doc 的文本相关性判断是否相关。Query 和 doc 的匹配过程就是在语法层面理解 query 和 doc 之间 gap 的过程。推荐中的两大实体是 user 和 item，两者的表征体系可能完全没有重叠。这就决定了推荐中，user 和 item 的匹配是无法从表面的特征解决两者 gap 的。
5. 个性化要求不同：搜索和推荐天然对个性化需求不同。搜索有用户的主动 query，本质上这个 query 已经在告诉系统这个 "用户" 是谁了，query 本身代表的就是一类用户，而推荐没有用户主动的 query 输入，如果没有用户画像属性和过去行为的刻画，系统基本上就等于瞎猜。

相同之处：

1. 本质都是match过程：如果把 user 比作 query，把 item 比作 doc，那么推荐和搜索在这个层面又是相同的，都是针对一个 query ( 一个 user )，从海量的候选物品库中，根据 query 和 doc 的相关性 ( user 过去的历史、画像等和 item 的匹配程度 )，去推荐匹配的 doc ( item )。
2. 目标相同：搜索和推荐的目标都是针对一次 context ( 或者有明确意图，或者没有 )，从候选池选出尽可能满足需求的物品。两者区别只是挑选过程使用的信息特征不同。
3. 语义鸿沟都是两者醉倒的挑战：在搜索里表现是 query 和 doc 的语义理解，推荐里则是 user 和 item 的理解。

#### 推荐系统的传统匹配模型

##### 基于Collaborative Filtering 的方法

###### CF模型

协同过滤基于一个最基本的假设：一个用户的行为，可以由和他行为相似的用户进行预测。协同过滤的基本思想是基于 <user, item> 的所有交互行为，利用集体智慧进行推荐。CF 按照类型可以分为3种，user-based CF、item-based CF 和 model-based CF。

User-base CF：通过对用户喜欢的item进行分析，如果用户a和用户b喜欢过的item差不多，那么用户a和b是相似的。类似朋友推荐一样，可以将b喜欢过但是a没有看过的item推荐给a。

Item-base CF: item A 和 item B 如果被差不多的人喜欢，认为 item A 和 item B 是相似的。用户如果喜欢 item A，那么给用户推荐 item B 大概率也是喜欢的。

Model-base CF: 也叫基于学习的方法，通过定义一个参数模型来描述用户和物品、用户和用户、物品和物品之间的关系，然后通过已有的用户-物品评分矩阵来优化求解得到参数。例如矩阵分解、隐语义模型LFM等。

CF 协同过滤的思路要解决的问题用数据形式表达就是：矩阵的未知部分如何填充问题。如下所示，已知的值是用户已经交互过的item，如何基于这些已知值填充矩阵剩下的未知值，也就是去预测用户没有交互过的item是矩阵填充要解决的问题。

![](../picture/1/233.png)

矩阵填充可以用经典的`SVD`解决，一般来说`SVD`求解可以分为三步：对 M 矩阵的 missing data 填充为0；求解`SVD`问题，得到`U`矩阵和`V`矩阵；利用`U`和`V`矩阵的低秩`k`维矩阵来估计。对于第二中的`SVD`求解问题，等价于以下的最优化问题：$arg \min_{U,\Sigma, V}(Y-U\Sigma V^T)^2=arg \min_{U,\Sigma,V}\sum_{i=1}^{m}\sum_{j=1}^{n}(y_{ij}-(U\Sigma V^T)_{ij})^2$。其中$y_{ij}$为用户$i$对物品$j$的真实评分，也就是 label，$U$和$V$为模型预估值，求解矩阵$U$和$V$的过程就是最小化用户真实评分矩阵和预测矩阵误差的过程。这种`SVD`求解方法存在以下问题：Missing data和 observe data 权重一样。最小化过程没有正则化，容易产生过拟合。

###### `MF`模型

为解决上述过拟合情况，矩阵分解模型提出的模型如下：$\hat{y}_{ui} = \mathbf{v}_u^T\mathbf{v}_i$。`MF`模型的核心思想可以分成两步：将用户$u$对物品$i$的打分分解成用户的隐向量$\mathbf{v}_u$，以及物品的隐向量$\mathbf{v}_i$；用户$u$和物品$i$的向量点积得到的value，可以用来代表用户$u$对物品$i$的喜好程度，分数越高代表该 item 推荐给用户的概率就越大。同时，`MF`模型引入了$l_2$正则来解决过拟合问题。
$$
L=\sum_{u}\sum_{i}w_{ui}(y_{ui}-\hat{y}_{ui})^2+\lambda(\sum_u||\mathbf{v}_u||^2+\sum_i||\mathbf{v}_i||^2)
$$

###### `FISM`模型

将用户喜欢过的 item 作为用户的表达来刻画用户，用数据公式表示如下：$\hat{y}_{ui} = (\sum_{j \in \mathcal{R}_u}\mathbf{q}_j)^T\mathbf{v}_i$。用户表达不再是独立的隐向量，而是用用户喜欢过的所有 item 的累加求和得到作为 user 的表达；而 item 本身的隐向量$\mathbf{v}_i$是另一套表示，两者最终同样用向量内积表示。对于每一个物品，都有两个嵌入向量$\mathbf{q}$和$\mathbf{v}$，当物品是预测的物品时，使用$\mathbf{v}$，当物品是交互历史中的物品时，使用$\mathbf{q}$。

###### SVD++模型

`MF`模型可以看成是 user-based 的 CF 模型，直接将用户id映射成隐向量，而`FISM`模型可以看成是 item-based 的`CF`模型，将用户交户过的 item 的集合映射成隐向量。`SVD++`正是这两者的结合，数学表达如下：$\hat{y}_{ui} = (\mathbf{v}_u+\sum_{j \in \mathcal{R}_u}\mathbf{q}_j)^T\mathbf{v}_i$。每个用户表达分成两个部分，左边$\mathbf{v}_u$表示用户 id 映射的隐向量，右边是用户交互过的 item 集合的求和。User 和 item 的相似度还是用向量点击来表达。

##### Generic feature-based的方法

上述的方法中，无论是 CF，MF，SVD，SVD++，还是 FISM，都只是利用了 user 和 item 的交互信息，而对于大量的 side information 信息没有利用到。因此，传统模型要讲的第二部分，是如何利用这些特征，去构造 feature-based 的 model。

![](../picture/1/234.png)

###### FM模型

对于每个输入特征，模型都需要学习一个低维的隐向量表达 v，也就是在各种 NN 网络里所谓的 embedding 表示。
$$
\hat{y}(\mathbf{x})=\omega_0+\sum_{i=1}^p\omega_ix_i+\sum_{i=1}^{p}\sum_{j\gt i}^{p}<\mathbf{v}_i,\mathbf{v}_j>x_ix_j
$$
假如只使用 userid 和 itemid，我们可以发现其实 FM 退化成加了 bias 的 MF 模型

![](../picture/1/240.png)

如果输入包含两个变量，用户交互过的 item 集合；itemid 本身，那么，此时的 FM 又将退化成带 bias 的 FISM 模型。同样道理，如果再加上 userid 的隐向量表达，那么 FM 模型将退化成 SVD++ 模型。

![](../picture/1/241.png)

上面介绍的模型都是通过打分预测来解决推荐系统的排序问题，这在很多时候一般都不是最优的，原因有如下几个方面：预测打分用的 RMSE 指标和实际的推荐系统排序指标的 gap，预测打分用的 RMSE 拟合的是最小方差，而实际面临的是个排序问题；观察数据天然存在 bias，用户一般倾向于给自己喜欢的 item 打分，而用户没有打分过的 item 未必就真的是不喜欢。针对推荐系统的排序问题，一般可以用 pairwise 的 ranking 来替代 RMSE。

#### 基于 representation learning 的深度匹配模型

这种方法会分别学习用户的 representation 以及 item 的 representation，也就是 user 和 item 各自的 embedding 向量 ( 或者也叫做隐向量 )，然后通过定义 matching score 的函数，一般是简单的向量点击、或者 cosine 距离来得到两者的匹配分数。

![](../picture/1/235.png)

##### 基于 Collaborative Filtering 的方法

###### CF模型

分别学习 user 和 item 的隐向量。input layer：只有两个，分别是 userid ( one-hot )，itemid ( one-hot )；representation function：线性 embedding layer；matching function：向量内积。 $f_{MF}=(u,i|\mathbf{p}_u,\mathbf{q}_i)=\mathbf{p}_u^T\mathbf{q}_i$，矩阵填补，label就是交互矩阵的值，缺失就是需要填补的。

![](../picture/1/236.png)

###### DMF

DMF 模型也就是深度矩阵分解模型，在传统的 MF 中增加了 MLP 网络。input layer：由两部分组组成，其中 user 由 user 交互过的 item 集合来表示，是个 multi-hot 的打分表示，如 [0 0 4 0 0 … 1 5 …]，在矩阵中用行表示；item 也由交互过的 user 集合来表示，也是个 multi-hot 的表示，如 [5 0 0 3 … 1 3]，在矩阵中用列表示。representation function：Multi-Layer-Perceptron，也就是经典的全连接网络；matching function：用 cosine 点击表示两个向量的匹配分数。

![](../picture/1/237.png)
$$
\hat{Y}_{ij}=F^{DMF}(u_i,v_j|\Theta)= \cos(p_i,q_j) = \frac{p_i^Tq_j}{||p_i||||q_j||}
$$

###### AutoRec模型

借鉴 auto-encoder 的思路，`AutoRec`模型对输入做重建，来建立 user 和 item 的 representation，和 CF 一样，也可以分为 user-based 和 item-based 的模型。对于 item-based `AutoRec`，input 为 R 里的每列，即每个 item 用各个 user 对它的打分作为其向量描述；对于 user-based `AutoRec`则是用 R 里的每行来表示，即每个 user 用他打分过的 item 的向量来表达。用$r_u$表示用户向量，$r_i$表示 item 向量，通过`AutoEncoder`将$r_u$或者$r_i$投射到低维向量空间，然后再将其投射到正常空间，利用`AutoEncoder`中目标值和输入值相近的特性，从而重建出用户对于未交互过的 item 的打分。

input layer：和 DMF 一样，user 用 user 作用过的 item 集合表示，item 则用 itemid 本身表示；representation function：通过 auto-encoder 的结构表示，其中，$h(r;\theta)$表示的是输入层到隐层的重建；由于输入的是用户交互过的 item，所以在隐层中的蓝色节点表示的就是 user representation；而输出的节点表示的是 item 的 representation，这样就可以得到 user 和 item 各自 representation，$h(\mathbf{r};\theta)=f(W.g(Vr+\mu)+b)$。损失函数为最小化预测的平方差以及$W$和$V$矩阵的$L_2$正则：
$$
\min_{\theta}\sum_{i=1}^{n}||\mathbf{r}^{(i)}-h(\mathbf{r}^{(i)};\theta)||_{\mathcal{O}}^2+\frac{\lambda}{2}(||W||_F^2+||V||_F^2)
$$
![](../picture/1/242.png)

###### CDAE模型

 input layer：用户 id，用户历史交互过的 item；以及 itemid。如图所示的 input layer 节点，绿色节点表示每个用户交互过的 item，最下面的红色节点 user node 表示用户本身的偏好，可以认为是 userid的表达；representation function：中间蓝色的隐层节点作为用户表示，其中$V_u$为 input layer 中的 user node 的 representation，针对所有用户 id 会学习一个和 item 无关的$V_u$向量表达，可以认为是用户本身的 bias，例如有些用户打分本身比较严格，再好的 item 打分也不会太高；有些用户打分很宽松，只要 item 别太差都会给高分，加上$V_u$可以更好的刻画用户之间天然的 bias。$\mathbf{z}_u=h(\mathbf{W}^T\mathbf{y}_u+\mathbf{V_u}+b)$，而对于输出层的节点，可以认为是用户 u 对物品 i 的打分预测：$\hat{y}_{ui}=f(\mathbf{W}_i^{\prime T}\mathbf{z}_u+b_i^{\prime})$；matching function：使用向量点积作为匹配分数：$\hat{y}_{ui}=\mathbf{W}_i^{\prime T}\mathbf{V_u}$

![](../picture/1/243.png)

##### 基于 Collaborative Filtering + side information 的方法

###### DCF模型

input layer：除了用户和物品的交互矩阵，还有用户特征 X 和物品特征 Y。representation function：和传统的 CF 表示学习不同，这里引入了用户侧特征X；物品侧特征 Y；user 和 item 侧的特征各自通过一个 auto-encoder 来学习，而交互信息$R$矩阵依然做矩阵分解$U,V$。

![](../picture/1/244.png)

![](../picture/1/245.png)

其中$W_1$，表示的用户侧特征$X$在 auto-encoder 过程中的 encode 部分，也就是输入到隐层的重建，$P_1$表示的是用户特征到交互矩阵$R$的映射；而$W_2$表示物品侧特征$Y$在 auto-encoder 过程中的 encode 部分。$P_2$表示的是物品特征到交互矩阵$R$的映射。

###### Attention Collaborative Filtering模型

在传统的 CF 里引入了 attention 机制。这里的 attention 有两层意思，第一层 attention，认为用户历史交互过的 item 的权重是不一样的；另一个 attention 意思是，用户同一个 item 里到的视觉特征的权重也是不一样的。 input layer：用户侧：userid；用户历史交互过的 item。Item侧：itemid；item 相关的视觉相关特征。representation function：可以分为两个 attention，一个是 component 层级的 attention，主要是提取视觉特征；第二层是 item 层级的 attention，主要提取用户对物品的喜好程度权重。

![](../picture/1/246.png)

总结上述基于 CF 的方法，可以用如下的范式作为表达

![](../picture/1/247.png)

 representation learning：目的是学习到 user 和 item 各自的 representation。特征表达：user 侧特征除了用户 id 本身 userid，可以加上其他 side info；item 侧特征除了物品 id 本身 itemid，还有其他文本特征、图文特征、视频帧特征等信息。模型表达：除了传统的 DNN，其他结构如 Auto-Encoder，Denoise-Auto-Encoder，CNN，RNN 等。

#### 基于 match function learning 的深度匹配模型

基于 match function learning 最大的特点是，不直接学习 user 和 item 的 embedding，而是通过已有的各种输入，通过一个 neural network 框架，来直接拟合 user 和 item 的匹配分数。

![](../picture/1/238.png)

##### CF-based 的深度模型

###### 基于NCF框架的方法

基于神经网络的学习方法对比传统的 CF 网络，在得到 user vector 和 item vector 后，连接了 MLP 网络后，最终拟合输出，得到一个 end-2-end 的 model。这套框架好处就是足够灵活，user 和 item 侧的双塔设计可以加入任意 side info 的特征，而 MLP 网络也可以灵活的设计。

![](../picture/1/239.png)

###### NeuMF模型

同时利用了 MF 和神经网络 MLP 的能力来拟合 matching score；MF 利用向量内积学习 user 和 item 的关联，同时 MLP 部分捕捉两者的其他高阶信息。模型可以分为 GMF 和 MLP 两个部分来看

![](../picture/1/248.png)

GMF部分：User 和 item 都通过 one-hot 编码得到稀疏的输入向量，然后通过一个 embedding 层映射为 user vector 和 item vector。这样就获得了 user 和 item 的隐向量，一般可以通过向量点积或者哈达马积得到交互，不过在 NeuMF 中多连接了一个连接层，也就是 GMF layer：
$$
\hat{y}_{ui} = \alpha_{out}(\mathbf{h}^T(\mathbf{p}_u \odot\mathbf{q}_i))
$$
MLP 部分：输入和 GMF 部分一样，都是 one-hot 的稀疏编码，然后通过 embedding 层映射为 user vector 和 item vector

##### 基于translation框架的方法

#### feature-based的深度模型

#### 推荐系统

推荐系统主要用于解决以下两个问题：

预测：用于预测用户-项目组合的评分值。在这种情况下，我们以用户提供的评分作为训练数据。其目的是利用这些数据对用户没有交互的商品预测其评分。

排序：没有必要为了进行推荐而预测特定商品的用户评分。在线零售商或电子商务公司并不太关心用户的预测。相反，他们更感兴趣的是列出一个有限的清单，能给特定的人群列出最好的东西来呈现给他们。

推荐引擎的期望目标，包括以下四点：

相关性：推荐的东西只有和用户相关才会有意义。用户更有可能购买或消费他们感兴趣的商品。

新颖性：除了相关性之外，新颖性也是另一个重要因素。如果推荐的项目是用户以前没有看过或消费过的，那么推荐也将更有意义。

偶然性：有时推荐一些出乎意料的项目也能促进销售。然而，偶然性与新颖性不同。

多样性：此外，增加推荐的多样性也同样重要。简单地推荐与此类似的商品并没有多大用处。

![](../picture/recommend.jpg)



###### 基于记忆的方法

基于邻域的协同过滤算法，其中用户-项目组合的评分是根据其邻域来预测的。这些邻域可以进一步通过以下两种方式来定义

- 基于用户的协同过滤：找到其他与你类似的人并推荐他们喜欢的东西。

- 基于商品的协同过滤：推荐那些也买了你喜欢的东西的人所买的东西。

然而，基于用户的协同过滤在实现中存在一些以下问题：用户偏好会随时间的推移而改变，推荐系统生成的许多推荐可能会随之变得过时；用户的数量越多，生成推荐的时间就越长;基于用户会导致对托攻击敏感，这种攻击方法是指恶意人员通过绕过推荐系统，使得特定物品的排名高于其他物品。

托攻击是一种针对协同过滤根据近邻偏好产生推荐的特点，恶意注入伪造的用户模型，推高或打压目标排名，从而达到改变推荐系统结果的攻击方式

###### 基于模型的方法

该方法使用机器学习方法，将问题当做普通的机器学习问题，来提取对评分数据的预测。可以使用 PCA、SVD、矩阵分解、聚类、神经网络等技术。

##### 混合方法

基于内容和协同过滤的方法都有各自的优缺点，通过将多个算法结合在一起，我们可以获得一个更好的系统。混合系统利用商品数据和交易数据来进行推荐。许多的组合性技术已经被探索出来了，包括：加权：为推荐系统中的每种算法都赋予不同的权重，使得推荐偏向某种算法；交叉：将所有的推荐结果集合在一起展现，没有偏重；增强：一个系统的推荐将作为下一个系统的输入，循环直至最后一个系统为止；切换：随机选择一种推荐方法

![](../picture/混合.jpg)

协同过滤的过程分为这三步：一开始，收集用户信息，然后以此生成矩阵来计算用户关联，最后作出高可信度的推荐。这种技术分为两大类：一种基于用户，另一种则是基于组成环境的物品。

##### 深度学习

![](../picture/1/142.png)

###### deep crossing

![](../picture/1/144.png)

###### `FNN`

 FNN 相比 Deep Crossing 的创新在于使用 FM 的隐层向量作为 user 和 item 的 Embedding，从而避免了完全从随机状态训练 Embedding。由于 id 类特征大量采用 one-hot 的编码方式，导致其维度极大，向量极稀疏，所以 Embedding 层与输入层的连接极多，梯度下降的效率很低，这大大增加了模型的训练时间和 Embedding 的不稳定性，使用 pre train 的方法完成 Embedding 层的训练，无疑是降低深度学习模型复杂度和训练不稳定性的有效工程经验。

![](../picture/1/143.png) 

###### `PNN`

 PNN 的关键在于在 embedding 层和全连接层之间加入了 Product layer。传统的 DNN 是直接通过多层全连接层完成特征的交叉和组合的，但这样的方式缺乏一定的“针对性”。首先全连接层并没有针对不同特征域之间进行交叉；其次，全连接层的操作也并不是直接针对特征交叉设计的。  因此 PNN 通过加入 Product layer 完成了针对性的特征交叉，其 product 操作在不同特征域之间进行特征组合。并定义了 inner product，outer product 等多种 product 的操作捕捉不同的交叉信息，增强模型表征不同数据模式的能力 。

![](../picture/1/145.png) 

###### `Wide & Deep`

 把单输入层的 Wide 部分和经过多层感知机的 Deep 部分连接起来，一起输入最终的输出层。其中 Wide 部分的主要作用是让模型具有记忆性（Memorization），单层的 Wide 部分善于处理大量稀疏的 id 类特征，便于让模型直接“记住”用户的大量历史信息；Deep 部分的主要作用是让模型具有“泛化性”（Generalization），利用 DNN 表达能力强的特点，挖掘藏在特征后面的数据模式。最终利用 LR 输出层将 Wide 部分和 Deep 部分组合起来，形成统一的模型。 

![](../picture/1/146.png)

###### `DeepFM`

 DeepFM 就是其中之一。DeepFM 对 Wide&Deep 的改进之处在于，它用 FM 替换掉了原来的 Wide 部分，加强了浅层网络部分特征组合的能力。事实上，由于 FM 本身就是由一阶部分和二阶部分组成的，DeepFM 相当于同时组合了原 Wide 部分 + 二阶特征交叉部分 +Deep 部分三种结构，无疑进一步增强了模型的表达能力。

![](../picture/1/147.png) 

###### `Deep & Cross`

 主要的思路使用 Cross 网络替代了原来的 Wide 部分。其中设计 Cross 网络的基本动机是为了增加特征之间的交互力度，使用多层 cross layer 对输入向量进行特征交叉。单层 cross layer 的基本操作是将 cross layer 的输入向量 xl 与原始的输入向量 x0 进行交叉，并加入 bias 向量和原始 xl 输入向量。DCN 本质上还是对 Wide&Deep Wide 部分表达能力不足的问题进行改进，与 DeepFM 的思路非常类似。 

![](../picture/1/148.png)

###### `NFM`

 相对于 DeepFM 和 DCN 对于 Wide&Deep Wide 部分的改进，NFM 可以看作是对 Deep 部分的改进。NFM 的全称是 Neural Factorization Machines，如果我们从深度学习网络架构的角度看待 FM，FM 也可以看作是由单层 LR 与二阶特征交叉组成的 Wide&Deep 的架构，与经典 W&D 的不同之处仅在于 Deep 部分变成了二阶隐向量相乘的形式。再进一步，NFM 从修改 FM 二阶部分的角度出发，用一个带 Bi-interaction Pooling 层的 DNN 替换了 FM 的特征交叉部分，形成了独特的 Wide&Deep 架构。其中 Bi-interaction Pooling 可以看作是不同特征 embedding 的 element-wise product 的形式。这也是 NFM 相比 Google Wide&Deep 的创新之处。

![](../picture/1/149.png)

###### `AFM`

 AFM 其实是对 FM 的二阶部分的每个交叉特征赋予了权重，这个权重控制了交叉特征对最后结果的影响，也就非常类似于 NLP 领域的注意力机制（Attention Mechanism）。为了训练 Attention 权重，AFM 加入了 Attention Net，利用 Attention Net 训练好 Attention 权重后，再反向作用于 FM 二阶交叉特征之上，使 FM 获得根据样本特点调整特征权重的能力。

![](../picture/1/150.png)

###### `DIN`

   DIN 将 Attention 机制作用于深度神经网络，在模型的 embedding layer 和 concatenate layer 之间加入了 attention unit，使模型能够根据候选商品的不同，调整不同特征的权重。 

![](../picture/1/151.png)

##### 召回模型

推荐系统一般分为两个阶段，即召回阶段和排序阶段。召回阶段主要是从全量的商品库中得到用户可能感兴趣的一小部分候选集，排序阶段则是将召回阶段得到的候选集进行精准排序，推荐给用户。

![](../picture/1/218.png)

###### 协同过滤

基于用户的协同过滤：当召回用户A的候选集时，可以先找到和他有相似兴趣的其他用户，然后把那些用户喜欢的、而用户A未交互的物品作为候选集。

基于物品的协同过滤： 计算物品之间的相似度。根据物品的相似度和用户的历史行为给用户生成召回候选集。

###### 向量化召回

通过模型来学习用户和物品的兴趣向量，并通过内积来计算用户和物品之间的相似性，从而得到最终的候选集。

![](../picture/1/214.png)
$$
P(\omega_t=i|U,C) = \frac{e^{v_iu}}{\sum_{j\in V}e^{v_ju}}
$$
两侧分别对 user 和 item 特征通过D`NN`输出向量，并在最后一层计算二个输出向量的内积。

![](../picture/1/215.png)

![](../picture/1/216.png)

多 Embedding 向量召回-用户多兴趣表达，通过一种模型来建模出用户多个 embedding 的表示。

![](../picture/1/217.png)

Multi-Interest 抽取层负责建模用户多个兴趣向量 embedding，然后通过 Label-aware Attention 结构对多个兴趣向量加权。这是因为多个兴趣 embedding 和待推荐的 item 的相关性肯定不同。其中上图中的 K，V 都表示用户多兴趣向量，Q 表示待推荐 item 的 embedding 表示，最终用户的 embedding 表示为：
$$
\vec{\mathbf{v}_u} = Attention(\vec{\mathbf{e}_i}, V_u, V_u)=V_usoftmax{pow(V_u^T\vec{\mathbf{e}_i}, p)}
$$
 $e_i$表示 item embedding，$V_u$表示 Multi-Interest 抽取层输出的用户多个兴趣向量 embedding。然后使用$V_u$和待推荐 item embedding，计算用户u和商品i交互的概率，计算方法和 YouTube DNN 一样。

##### Embedding

 Embedding 层往往采用预训练的方式完成。  Embedding 的训练往往独立于深度学习网络进行。在得到稀疏特征的稠密表达之后，再与其他特征一起输入神经网络进行训练。 

#### 知识图谱

如果两个节点之间存在关系，他们就会被一条无向边连接在一起，那么这个节点，我们就称为**实体**（Entity），它们之间的这条边，我们就称为**关系**（Relationship）。知识图谱的基本单位，便是“实体（Entity）-关系（Relationship）-实体（Entity）”构成的三元组，这也是知识图谱的核心。

![](../picture/1/204.png)

##### 架构

知识图谱的架构主要可以被分为：逻辑架构、技术架构

###### 逻辑架构

在逻辑上，我们通常将知识图谱划分为两个层次：数据层和模式层。模式层：在数据层之上，是知识图谱的核心，存储经过提炼的知识，通常通过本体库来管理这一层。数据层：存储真实的数据。本体库可以理解为面向对象里的“类”这样一个概念，本体库就储存着知识图谱的类

模式层：实体-关系-实体，实体-属性-性值；数据层：比尔盖茨-妻子-梅琳达·盖茨，比尔盖茨-总裁-微软

###### 技术架构

知识图谱有自顶向下和自底向上两种构建方式，这里提到的构建技术主要是自底向上的构建技术。构建知识图谱是一个迭代更新的过程，根据知识获取的逻辑，每一轮迭代包含三个阶段：信息抽取：从各种类型的数据源中提取出实体、属性以及实体间的相互关系，在此基础上形成本体化的知识表达；知识融合：在获得新知识之后，需要对其进行整合，以消除矛盾和歧义，比如某些实体可能有多种表达，某个特定称谓也许对应于多个不同的实体等；知识加工：对于经过融合的新知识，需要经过质量评估之后，才能将合格的部分加入到知识库中，以确保知识库的质量。

![](../picture/1/205.png)

信息抽取是一种自动化地从半结构化和无结构数据中抽取实体、关系以及实体属性等结构化信息的技术。实体抽取，也称为命名实体识别（named entity recognition，NER），是指从文本数据集中自动识别出命名实体。关系抽取，从相关语料中提取出实体之间的关联关系，通过关系将实体联系起来，才能够形成网状的知识结构。属性抽取，从不同信息源中采集特定实体的属性信息，如针对某个公众人物，可以从网络公开信息中得到其昵称、生日、国籍、教育背景等信息。

知识融合：实体链接是指对于从文本中抽取得到的实体对象，将其链接到知识库中对应的正确实体对象的操作。其基本思想是首先根据给定的实体指称项，从知识库中选出一组候选实体对象，然后通过相似度计算将指称项链接到正确的实体对象。实体链接的流程：从文本中通过实体抽取得到实体指称项；进行实体消歧和共指消解，判断知识库中的同名实体与之是否代表不同的含义以及知识库中是否存在其他命名实体与之表示相同的含义；在确认知识库中对应的正确实体对象之后，将该实体指称项链接到知识库中对应实体。

知识加工：通过信息抽取，从原始语料中提取出了实体、关系与属性等知识要素，并且经过知识融合，消除实体指称项与实体对象之间的歧义，得到一系列基本的事实表达。然而事实本身并不等于知识。要想最终获得结构化，网络化的知识体系，还需要经历知识加工的过程。

本体：是指人工的概念集合、概念框架。本体可以采用人工编辑的方式手动构建，也可以以数据驱动的自动化方式构建本体。因为人工方式工作量巨大，且很难找到符合要求的专家，因此当前主流的全局本体库产品，都是从一些面向特定领域的现有本体库出发，采用自动构建技术逐步扩展得到的。

自动化本体构建过程包含三个阶段：实体并列关系相似度计算、实体上下位关系抽取、本体的生成

当知识图谱刚得到“阿里巴巴”、“腾讯”、“手机”这三个实体的时候，可能会认为它们三个之间并没有什么差别，但当它去计算三个实体之间的相似度后，就会发现，阿里巴巴和腾讯之间可能更相似，和手机差别更大一些。这就是第一步的作用，但这样下来，知识图谱实际上还是没有一个上下层的概念，它还是不知道，阿里巴巴和手机，根本就不隶属于一个类型，无法比较。因此我们在实体上下位关系抽取这一步，就需要去完成这样的工作，从而生成第三步的本体。当三步结束后，这个知识图谱可能就会明白，“阿里巴巴和腾讯，其实都是公司这样一个实体下的细分实体。它们和手机并不是一类。”

知识推理：在我们完成了本体构建这一步之后，一个知识图谱的雏形便已经搭建好了。但可能在这个时候，知识图谱之间大多数关系都是残缺的，缺失值非常严重，那么这个时候，我们就可以使用知识推理技术，去完成进一步的知识发现。

当然知识推理的对象也并不局限于实体间的关系，也可以是实体的属性值，本体的概念层次关系等。这一块的算法主要可以分为3大类，基于逻辑的推理、基于图的推理和基于深度学习的推理。

![](../picture/1/206.png)

知识更新：从逻辑上看，知识库的更新包括概念层的更新和数据层的更新。概念层的更新是指新增数据后获得了新的概念，需要自动将新的概念添加到知识库的概念层中。数据层的更新主要是新增或更新实体、关系、属性值，对数据层进行更新需要考虑数据源的可靠性、数据的一致性等可靠数据源，并选择在各数据源中出现频率高的事实和属性加入知识库。

知识图谱的内容更新有两种方式：全面更新：指以更新后的全部数据为输入，从零开始构建知识图谱。这种方法比较简单，但资源消耗大，而且需要耗费大量人力资源进行系统维护；增量更新：以当前新增数据为输入，向现有知识图谱中添加新增知识。这种方式资源消耗小，但目前仍需要大量人工干预（定义规则等），因此实施起来十分困难。

#### `CTR`预估模型

在 `cost-per-click:CPC` 广告中广告主按点击付费。为了最大化平台收入和用户体验，广告平台必须预测广告的 `CTR` ，称作 `predict CTR: pCTR` 。对每个用户的每次搜索`query`，有多个满足条件的广告同时参与竞争。只有 `pCTR x bid price` 最大的广告才能竞争获胜，从而最大化 `eCPM` ：$eCPM=pCTR \times \text{bid price}$基于最大似然准则可以通过广告的历史表现得统计来计算 `pCTR` 。假设广告曝光了100次，其中发生点击5次，则 `pCTR = 5%`。其背后的假设是：忽略表现出周期性行为或者不一致行为的广告，随着广告的不断曝光每个广告都会收敛到一个潜在的真实点击率 。这种计算 `pCTR` 的方式对于新广告或者刚刚投放的广告问题较大：新广告没有历史投放信息，其曝光和点击的次数均为 0 。刚刚投放的广告，曝光次数和点击次数都很低，因此这种方式计算的 `pCTR` 波动非常大。

从经验上来看：广告在页面上的位置越靠后，用户浏览它的概率越低。因此广告被点击的概率取决于两个因素：广告被浏览的概率、广告浏览后被点击的概率。因此有：
$$
p(click|ad,pos) = p(click|ad,pos,seen)\times p(seen|add,pos)
$$
假设：在广告被浏览到的情况下，广告被点击的概率与其位置无关，仅与广告内容有关。广告被浏览的概率与广告内容无关，仅与广告位置有关。则有：
$$
p(click|ad,pos) = p(click|add,seen)\times p(seen|pos)
$$
第一项$p(click|add,seen)$就是我们关注和预测的 `CTR` 。第二项与广告无关，是广告位置的固有属性。可以通过经验来估计这一项：统计该广告位的总拉取次数$impress(poss)$，以及总曝光次数$seen(pos)$，则：
$$
p(seen|pos) = \frac{seen(pos)}{impress(poss)}
$$
这也称作广告位的曝光拉取比。





推荐系统，如果粗分的化，经常讲的有两个阶段。首先是召回，主要根据用户部分特征，从海量的物品库里，快速找回一小部分用户潜在感兴趣的物品，然后交给排序环节，排序环节可以融入较多特征，使用复杂模型，来精准地做个性化推荐。召回强调快，排序强调准。
如果我们更细致地看实用的推荐系统，一般会有四个环节，四个环节分别是：召回、粗排、精排和重排。召回目的如上所述；有时候因为每个用户召回环节返回的物品数量还是太多，怕排序环节速度跟不上，所以可以在召回和精排之间加入一个粗排环节，通过少量用户和物品特征，简单模型，来对召回的结果进行个粗略的排序，在保证一定精准的前提下，进一步减少往后传送的物品数量，粗排往往是可选的，可用可不同，跟场景有关。之后，是精排环节，使用你能想到的任何特征，可以上你能承受速度极限的复杂模型，尽量精准地对物品进行个性化排序。排序完成后，传给重排环节，传统地看，这里往往会上各种技术及业务策略，比如去已读、去重、打散、多样性保证、固定类型物品插入等等，主要是技术产品策略主导或者为了改进用户体验的

内容分析的结果主要有两类：一个是用户画像和物品画像的结构化内容库，另一个是分析过程中可能得到的模型，如主题模型、分类器模型、实体识别模型、嵌入模型等，这些模型主要用于实时推荐刚刚加入的新物品，通过对物品内容的实时分析，提取结构化内容，再用于用户画像匹配。
基于内容的推荐，最简单的算法就是计算相似性，可以把用户画像和物品画像表示成稀疏的向量，两者之间计算余弦相似度，根据相似度对推荐物品排序，也可以使用信息检索中的相关性计算

此处我们给出可疑样本的定义。

假设我们存在$N$个样本$(x_1,y_1),(x_2,y_2),...,(x_N,y_N)$,$x_i$为第$i$个样本的特征,$y_i$为第$i$个样本对应的标签,$y_i \in \{1,2,3...,K\}$,$K \ge 3$为类的个数,我们采用已经训练好的模型$Model$对$N$个样本进行预测,得到一个$N*K$的概率矩阵,我们用$p_{ij}$表示为$Model$把第$i$个样本预测为第$j$类的概率,并且将每一个样本中概率最大的值对应的类作为我们最终的预测结果.即$argmax_j ~ p_{ij}, j \in K$为第$i$个样本的预测结果.  

**可疑样本定义:** 对于每一个样本$x_i $, 令$ q_i = max ~ p_{ij},~ j \in \{1,2,...,K\}, i \in \{1,2,...,N\}$,我们将所有 $q_i \le threshold,i \in \{1,2,...,N\} $的样本定义为可疑样本,表示模型对该类样本的预测没有较强把握.

#### 算法步骤

**1.输入**: 训练数据$Train$,$\{(x_1,y_1),(x_2,y_2),...,(x_{N_1},y_{N_1}) \}, x_i \in R^d, y_i \in \{1,2,..., M\}$, 测试集$Test$,$\{(x_1,y_1),(x_2,y_2),...,(x_{N_2},y_{N_2}) \}$.可疑样本的$Threshold$. $KNN$的$K$以及采用的距离函数。 

**2.模型训练**: 对数据集Train进行训练获得模型$Model$。 

**3.模型预测:**使用模型$Model$分别对训练集和测试集进行预测得到训练集的预测概率矩阵$Matrix\_Tr \in R^{N_1 * M}$以及测试集的概率矩阵$Matrix\_Te \in R^{N_2 * M}$。 

**4.KNN纠正**: 将测试集中预测结果概率低于$Threshold$的样本的预测数据提取出来形成新的测试集$Test'$,将训练集的预测矩阵作为新的训练集的特征并使用$KNN$进行训练获得KNN模型,使用$KNN$对$Test'$进行预测,并将新的预测结果替代原先的预测结果。 

**5.输出:**将纠正后的预测结果作为最终结果进行输出。 

####  算法步骤

**1.输入**: 训练数据$Train$,$\{(x_1,y_1),(x_2,y_2),...,(x_{N_1},y_{N_1}) \}, x_i \in R^d, y_i \in \{1,2,..., K\}$, 测试集$Test$,$\{(x_1,y_1),(x_2,y_2),...,(x_{N_2},y_{N_2}) \}$.训练集可疑样本的$Threshold\_Tr$.测试集可疑样本的$Threshold\_Te$.$KNN$的$K$以及采用的距离函数。
**2.模型训练:** 对数据集$Train$进行训练获得模型$Model$。
**3.模型预测:****使用模型$Model$分别对训练集和测试集进行预测得到训练集的预测概率矩阵$Matrix\_Tr \in R^{N_1 * K}$以及测试集的概率矩阵$Matrix\_Te \in R^{N_2 * K}$。
**4.KNN纠正:** 将测试集中预测结果概率低于$Threshold\_Te$的样本的预测数据提取出来形成新的测试集$Test'$,将训练集的预测矩阵高于$Threshold\_Tr$作为过滤之后的训练集的特征并使用$KNN$进行训练获得$KNN$模型,使用$KNN$对$Test'$进行预测,并将新的预测结果替代原先的预测结果。 
**5.输出:**将纠正后的预测结果作为最终结果进行输出。