协同过滤包括协同和过滤两个操作。协同就是汇集所有用户的反馈、评价等。而过滤，通过协同得到的信息，从海量物品进行过滤，筛选出用户感兴趣的物品。协同过滤模型的局限性，无法加入用户、物品属性、上下文特征等边信息，这是的丧失了很多有效信息，无法进行有效的推荐。

假设有$m$个用户$\mathbb{U}=\{u_1,\cdots,u_m\}$以及$n$个 `item`$\mathbb{I}=\{i_1,\cdots,i_n\}$。每个用户$u$有一个 `item` 评分列表$\mathbb{I}_u$，这个列表上用户有过行为，其中$\mathbb{I}_u\sub \mathbb{I}$且有可能为空。有两种方式构建`user-item`交互矩阵$Y\in\mathbb{R}^{m\times n}$
$$
\begin{equation}Y_{ui}=\left\{\begin{array}{ll}
1, & \text { if } i \in\mathbb{I}_u \\
0, & \text { otherwise }
\end{array}\right.\end{equation}
$$

$$
\begin{equation}Y_{ui}=\left\{\begin{array}{ll}
R_{ui}, & \text { if } i\in \mathbb{I}_u \\
0, & \text { otherwise }
\end{array}\right.\end{equation}
$$

基于邻域的方法根据计算用户或物品的相似性的不同又细分为两种：基于用户的协同过滤和基于物品的协同过滤。

两个向量之间的相似度计算方法主要有如下几种：

- `Jaccard`系数：$J(\mathbf{X},\mathbf{Y})=\frac{\mathbf{X}\cap\mathbf{Y}}{\mathbf{X}\cup\mathbf{Y}}$
- `Cosine`相似度、`Pearson`相关系数

##### `UserBased`协同过滤

`UserBased CF` 的基本思想是根据其它志趣相投用户的意见来推荐。根据`user-item`交互矩阵计算用户兴趣之间的相似性。给定用户$u$和$v$，定义他们共同评分的`item`集合为：
$$
\mathbb{I}_{u,v} = \{j|r_{u,j}>0 \and r_{v,j}>0\}
$$
其中$r_{i,j}$表示用户$i$对于`item`$j$的评分，该评分可能是已知的，也可能是未知的。然后计算用户$u,v$在这些共同评分`item`上的均值、方差、以及协方差，用户$u$和$v$的评分集合的相关系数：
$$
s_{u,v}=\frac{\text{cov}(u,v)}{\sigma_u\sigma_v}
$$
预测用户$u$在未评分`item`$j^*$上的评分时，首先找出在$j^*$上存在评分的用户：$\mathbb{U}_{j^*}=\{i|r_{i,j^*}>0\}$。然后我们基于用户$u$和集合$\mathbb{U}$中用户的相似性来预测：
$$
w_v=\frac{s_{u,v}}{\sum_{v\in\mathbb{U}_{j^*}}s_{u,v}}\\
r_{u,j^*} = \overline{r}_u+\sum_{v\in \mathbb{U}_{j^*}}w_v(r_{v,j^*}-\overline{r}_v)
$$

##### `ItemBased`协同过滤

`ItemBased CF` 的基本思想是根据用户之前喜欢过的 `item` 来推荐类似的`item` 。首先探索`item` 之间的相似性；然后向用户推荐她/他喜欢的 `item` 类似的 `item` 。因为`item` 之间的关系是相对静态的，所以基于 `item` 的算法可以预计算`item-item` 相似性，从而减少在线计算的数量，同时保持较高的推荐质量。

假设有$m$个用户$\mathbb{U}=\{u_1,\cdots,u_m\}$以及$n$个 `item`$\mathbb{I}=\{i_1,\cdots,i_n\}$。每个用户$u$有一个 `item` 评分列表$\mathbb{I}_u$，这个列表上用户有过行为，其中$\mathbb{I}_u\sub \mathbb{I}$且有可能为空。选择目标用户$u_a$已经评分的`item` 集合$\mathbb{I}_{u_a}$，然后计算评分集合中的每个 `item` 和未评分集合$\mathbb{I}-\mathbb{I}_{u_a}$中每个 `item`$i_j$的相似度，然后选择$k$个最相似的、未评分的 `item`$\{i_1^a,\cdots,i_k^a\}$，并记录对应的相似度。

计算`item` 之间相似度的基本思想是：首先挑选既对$i$打分、又对$j$打分的用户$\mathbb{U}_{ij}$，然后基于这些用户的打分来计算相似度 。基于余弦的相似度：
$$
sim(i,j) = \frac{\sum_{a\in\mathbb{U}_{ij}}r_{a,j}\times r_{a,j}}{\sqrt{\sum_{a\in\mathbb{U}_{ij}}r_{a,i}^2}\sqrt{\sum_{a\in\mathbb{U}_{ij}}r_{a,j}^2}}
$$
一旦我们根据相似性得到了目标`item` 最相似的一组`item`，则下一步是为用户执行打分预测。这里我们考虑两种技术：

- 加权和 `weighted sum`：该方法通过用户已经评分的 `item` 中，根据和$i$的相似度进行加权得到预测结果。假设用户$a$已经评分，且与$i$相似的 `item` 集合为$\mathbb{S}_{i,a}$，则有

$$
P_{a,i} =\sum_{j\in\mathbb{S}_{i,a}}\omega_{ij}\times r_{a,j}\\
\omega_{i,j} = \frac{s_{i,j}}{\sum_{\mathbb{S}_{i,a}}s_{i,j}}
$$

- 回归`Regression`：采用加权和相同的公式，但是不使用原始打分$r_{a,j}$，而是使用基于线性回归的近似值$r_{a,j}^{\prime}$。假设目标 `item`$i$的打分向量为$\vec{\mathbf{r}}_{\cdot,i}$，相似 `item`$j$的修正打分为：$\vec{\mathbf{r}}_{\cdot,j}^{\prime}=\alpha_{i,j}\vec{\mathbf{r}}_{\cdot,i}+\beta_{i,j}$。然后根据最小化$\arg\min_{\alpha_{i,j},\beta_{i,j}}||\vec{\mathbf{r}}_{\cdot,j}^{\prime}-\vec{\mathbf{r}}_{\cdot,j}||^2$来求解参数$\alpha_{i,j},\beta_{i,j}$。最终有：

$$
P_{a,i} =\sum_{j\in\mathbb{S}_{i,a}}\omega_{ij}\times (\alpha_{i,j}\times r_{a,j}+\beta_{i,j})\\
\omega_{i,j} = \frac{s_{i,j}}{\sum_{\mathbb{S}_{i,a}}s_{i,j}}
$$

基于用户的协同过滤适合时效性较强，用户的个性化兴趣不太明显的领域，如新闻领域；而基于物品的协同过滤适合兴趣变化较为稳定的应用，比如电商场景、视频推荐等。对于基于邻近的方法，虽然其解释性较强，但是它并不具有较强的泛化能力。处理稀疏向量的能力弱。

##### `I-2-I CF`

`Item-to-Item CF` 根据用户购买/评分的每个商品匹配到最相似的商品，然后将这些相似的商品向该用户推荐。为了确定商品的最佳匹配，算法首先需要构建商品之间的相似度矩阵。

考虑到很多 `item pair` 对之间没有共同用户，因此该方法在计算复杂度和空间复杂度上的效率较低。`Item-to-Item CF` 提出了一个更好的方法来计算所有商品`pair` 对之间的相似度：

`for` 商品集合的每个商品 ：

`for` 购买商品 的每个用户 ：

`for` 用户 购买的每个商品 ：记录用户 同时购买了商品 和 

`for` 每个商品 ：计算 和 之间的相似度

有多种方式来计算商品之间的相似度，最简单的方式是余弦相似度，其中每个向量对应一个商品，向量的维度为购买该商品的用户数量。

##### Slope one Rating Based CF

`Slope One` 算法的基本思想是：不同商品之间的评分差异 。我们以 `pair` 对的方式来决定商品$j$比商品$i$要好多少，从而计算评分差异。一种简单的计算方式是：用商品$i$的评分减去商品$j$的评分。反之，如果已知商品$i$的评分，以及$j$和$i$的热度差异，那么商品$j$的评分就可以计算到。

给定用户$u$，定义他/她的评分 `array` 记作：$\vec{\mathbf{r}}_u=(r_{u,1},\cdots,r_{u,n})^T$。其中第$i$个元素$r_{u,i}$对应于商品$i$的评分。由于存在大量的未评分商品，因此这个向量是不全的 `incomplete` 。定义用户$u$评分的所有商品为$\mathbb{I}_u$，用户$u$的平均打分为$\overline{r}_u$：
$$
\mathbb{I}_u=\{i|r_{u,i}>0\},\overline{r}_u=\frac{1}{|\mathbb{I}_u|}\sum_{i\in\mathbb{I}_u}r_{u,i}
$$
定义训练集的所有评分 `array` 为$\mathbb{X}$：$\mathbb{X}=\{\vec{\mathbf{r}}_u|u\in\mathbb{U}\}$，其中$\mathbb{U}$为所有用户。定义$\mathbb{U}_i$为包含商品$i$的用户集合 ：$\mathbb{U}_i=\{u|u\in\mathbb{U},r_{u,i}>0\}$。定义同时包含商品$i,j$的用户集合为：$\mathbb{U}_{i,j}=\{u|u\in\mathbb{U},r_{u,i}>0, r_{u,j}>0\}$。定义用户$u,v$共同评分的商品集合为：$\mathbb{I}_{u,v}=\{i|i\in\mathbb{I},r_{u,i}>0,r_{v,i}>0\}$。定义预测$\vec{\mathbf{p}}_u=\{p_{u,1},\cdots,p_{u,n}\}^T$，其中每个元素代表一个预测结果。

`RatingBasec CF` 在线预测时， 首先提供一个评分 `array` ， 它包含用户的所有评分商品；模型返回一个预测`array`，其中包含用户尚未评分的商品及其预估的评分。

最简单的 `baseline` 为 `PER USER AVERAGE`：
$$
p_{u,i}=\overline{r}_u, i\not\in\mathbb{I}_u
$$
即：预测用户的所有未评分商品的评分为该用户的评分均值。

针对`PER USER AVERAGE` 的一种改进方式为 `BIAS FROM MEAN`，其预测结果为：
$$
p_{u,i}=\overline{r}_u+\frac{1}{|\mathbb{U}_i|}\sum_{v\in\mathbb{U}_i}(r_{v,i}-\overline{r}_v)
$$
它考虑了用户$u$的评分均值，以及所有其它用户在该商品上的评分和其它用户在该商品上的均值的差异。

基于`MemoryBased CF` 的一个经典实现是 `PEARSON` 方案：
$$
p_{u,i}=\overline{r}_u+\frac{\sum_{v\in\mathbb{U}_i}\gamma(u,v)(r_{v,i}-\overline{r}_v)}{\sum_{v\in\mathbb{U}_i}|\gamma(u,v)|}
$$
它在 `BIAS FROM MEAN` 的基础上考虑了用户$u,v$之间的相似性。其中$\gamma$为`Pearson` 相关系数，它刻画了用户之间的相似性：
$$
\text{corr}(u,v)=\frac{\sum_{i\in\mathbb{I}_{u,v}}(r_{u,i}-\overline{r}_u)(r_{v,i}-\overline{r}_v)}{\sqrt{\sum_{i\in\mathbb{I}_{u,v}}(r_{u,i}-\overline{r}_u)^2\sum_{i\in\mathbb{I}_{u,v}}(r_{v,i}-\overline{r}_v)^2}}\\
\gamma(u,v)=\text{corr}(u,v)|\text{corr}(u,v)|^{\rho-1}
$$
其中$\rho=2.5$为 `Case Amplification` 系数，它降低了数据中的噪音。

采用 `adjusted cosine` 相似度的 `ItemBased CF` ：给定商品$i$和$j$，定义相似度为：
$$
\text{sim}(i,j)=\frac{\sum_{u\in\mathbb{U}_{i,j}}(r_{u,i}-\overline{r}_u)(r_{u,j}-\overline{r}_u)}{\sqrt{\sum_{u\in\mathbb{U}_{i,j}}(r_{u,i}-\overline{r}_u)^2\sum_{u\in\mathbb{U}_{i,j}}(r_{v,j}-\overline{r}_u)^2}}
$$
使用基于回归`Regression` 的预测为：
$$
p_{u,i}=\sum_{j\in\mathbb{I}_{u}}w_{i,j}(\alpha_{i,j}r_{u,j}+\beta_{i,j}), i\not\in\mathbb{I}_u
\\w_{i,j}=\frac{\text{sim}(i,j)}{\sum_{k\in\mathbb{I}_{u}}\text{sim}(i,k)}
$$
其中$\alpha_{i,j}, \beta_{i,j}$为回归系数，它根据最小化目标来求得：
$$
\arg\min_{\alpha_{i,j}, \beta_{i,j}}(\alpha_{i,j}r_{u,j}+\beta_{i,j}-r_{u,i})^2
$$
`slope one` 方法同时考虑了来自相同商品的其它用户的评分、来自相同用户的其它商品的评分，除此之外`slope one` 方法还依赖于既不是相同商品、也不是相同用户的那些评分。因为这些评分数据都有助于我们进行预测。`slope one` 方法的大部分优势都来自于 `ItemBasec CF`、`MemoryBased CF` 未考虑的数据。

给定用户$u,v$，我们寻找最佳的预测器 `predictor` 来从$u$的评分中预测$v$的评分。`slope one` 方法选择的 `predictor` 为斜率为`1` 的线性函数，这就是名字 `slope one` 的由来。 具体而言，我们需要拟合方程：
$$
r^{\prime}_{v,i}=r_{u,i}+b
$$
我们通过最小化残差：
$$
\arg\min_{b}=\sum_{i\in\mathbb{I}_{u,v}}(r_{v,i}-r^{\prime}_{v,i})^2
$$
通过残差的偏导数为`0`，我们得到：
$$
b=\frac{\sum_{i\in\mathbb{I}_{u,v}}(r_{v,i}-r_{u,i})}{|\mathbb{I}_{u,v}|}
$$
因此$b$是用户$u$和$v$的评分差距的均值。类似的，我们可以通过利用商品$i$的评分来预测商品$j$的评分。同样的推导过程，我们有：
$$
b=\frac{\sum_{u\in\mathbb{U}_{i,j}}(r_{u,j}-r_{u,i})}{|\mathbb{U}_{i,j}|}
$$
给定训练集$\mathbb{X}$，以及任意两个商品$i,j$，我们定义商品$i$到商品$j$的平均偏移为：
$$
\text{dev}_{j,i}=\frac{1}{|\mathbb{U}_{i,j}|}\sum_{u\in\mathbb{U}_{i,j}}(r_{u,j}-r_{u,i})
$$
因此在给定$r_{u,i}$的条件下，$r_{u,j}$的预测值为：
$$
r^{\prime}_{u,j}=\text{dev}_{j,i}+r_{u,i}
$$
考虑所有这样的$r_{u,i}$，因此用户$u$在商品$i$上的 `predictor` 定义为：
$$
p_{u,j}=\frac{1}{|\mathbb{S}_{u,j}|}\sum_{i\in\mathbb{S}_{u,j}}(\text{dev}_{j,i}+r_{u,i})
$$
其中$\mathbb{S}_{u,j}=\{i|i\in\mathbb{I}_{u},i\ne j,\mathbb{U}_{i,j}\ne\Phi\}$，即：用户$u$同时评分的、且与$j$有共同评分用户的商品的集合。当数据足够稠密，即几乎所有商品 `pair` 对之间都有评分时，有：$\mathbb{S}_{u,j}=\mathbb{I}_{u}$。因此有：
$$
p_{u,j}=\overline{r}_u\frac{1}{|\mathbb{I}_{u}|}\sum_{i\in\mathbb{I}_{u}}\text{dev}_{j,i}
$$
可以看到：`slope one` 方法不依赖于用户对具体商品的评分，而依赖于用户的平均评分，以及用户对哪些商品进行评分。`slop one` 方法的关键数据是商品之间的偏移矩阵

`slope one` 方法的一个缺点是：未考虑评分数量。因此定义 `weighted slope one` 预测为：
$$
p_{u,j}=\frac{\sum_{i\in\mathbb{S}_{u,j}}(\text{dev}_{j,i}+r_{u,i})\times |\mathbb{U}_{i,j}|}{\sum_{i\in\mathbb{S}_{u,j}}|\mathbb{U}_{i,j}|}
$$

##### Bipartite Network Projection



##### Implicit Feedback CF

从广义上看，推荐系统主要分为两种不同的策略：

- 基于内容的策略：为每个用户或者 `item` 创建一个描述其性质的画像。我们可以通过用户画像和`item` 画像进行匹配从而执行基于内容的推荐。
- 基于协同过滤的策略：根据用户历史的行为，从而分析用户之间的相关性或`item` 之间的相关性，从而预测新的 `user-item` 关联。协同过滤的一个主要优势是：协同过滤是 `domain free` 的，它适用于任何领域并且无需领域内的专家知识，甚至有时候这些领域很难构建画像系统，也就无法使用基于内容的策略。协同过滤的一个缺点是冷启动问题 `cold start problem`，此时使用基于内容的策略可能更加合适。

推荐系统依赖于不同类型的输入。

- 质量最高的输入是显式反馈`explicit feedback` 数据，它包含用户对 `item` 的显式评分，但是显式反馈并非总能得到。
- 数量最多的是隐式反馈`implicit feedback` 数据，这些隐式反馈数据包括：用户的历史购买记录、历史浏览记录、历史搜索记录、甚至历史鼠标移动的记录。从这些数据我们无法得到用户对 `item` 的评分信息，但是它们能够间接的获得用户偏好。

和显式反馈数据不同，隐式反馈数据有它的特点：

- 没有负反馈：通过观察用户的行为我们可以推断出用户可能会喜欢的 `item`，但是难以推断出用户不喜欢的 `item` 。
- 包含大量噪音：当跟踪用户行为时，我们只能猜测他们的偏好和真实的动机。
- 显式反馈的数值代表偏好，隐式反馈的数值表示置信度。而基于隐式反馈的数值描述了行为的频次，如：用户观看某个节目的时间、用户购买某个 `item` 的次数。较大的数值不一定代表较高的偏好。但是隐式反馈的数值绝对有价值，因为它告诉我们有关某种观察结果的置信度 `confidence` 。单次事件的发生可能是由于和用户偏好无关的偶然因素引起，但是重复事件的发生一定可以反应用户的某种意图。
- 隐式反馈推荐的评估需要采取合适的指标。

给定用户$u$和 `item`$i$，我们称$r_{u,i}$为观测值 `observation` 。

- 对于显式反馈数据，$r_{u,i}$代表用户$u$对 `item`$i$的偏好评分，其中：评分越高代表越喜欢、评分越低代表越不喜欢。
- 对于隐式反馈数据，$r_{u,i}$代表用户的行为频次

对于绝大多数 `user-item` ，显式评分都是未知的，因此基于现实反馈数据的推荐算法使用相对较少的已知评分数据，忽略 `missing data` 数据。但是在隐式反馈数据中，所有的 `user-item` 的行为次数都是已知的：要么发生了行为，即$r_{u,i}>0$；要么未发生行为，即$r_{u,i}=0$，这表示零购买记录或者零观看时长。

`ItemBased CF` 的可解性比 `UserBased CF` 更好。`ItemBased CF` 可以解释为：因为用户过去喜欢 `item A` ，所以向用户推荐相似的 `item B` 。因为用户熟悉`item A` 所以这种推荐可解释性更好，并且理由也容易被用户所接受。

但是基于显式反馈数据的 `ItemBased CF` 难以应用到隐式反馈数据中，有两个原因：

- 在隐式反馈数据中，$r_{u,i}$取值范围很广，取值相差很大。相比之下显式反馈数据中的 取值在固定的几个评分 `level`，并且相差不大。
- 尚不清楚如何计算隐式反馈数据的相似度。

因此所有 `ItemBased CF` 模型在隐式反馈数据上都有一个缺点：无法灵活的区分用户的偏好，以及我们对这些偏好的信心。

`Latent factor model` 潜在因子模型是协同过滤的替代方法，它的目标是揭示观测值的潜在特征。每个用户$u$对应一个用户因子向量$\vec{\mathbf{x}}_u\in\mathbb{R}^f$，每个`item`$i$对应一个`item` 因子向量$\vec{\mathbf{y}}_i\in\mathbb{R}^f$，$f$为潜在因子的数量。最终预测结果为两个向量的内积：
$$
\hat{r}_{u,i}=\vec{\mathbf{x}}_u\cdot\vec{\mathbf{y}}_i
$$
应用于显式反馈数据的很多论文都建议直接对观测值进行建模，同时采用正则化来缓解过拟合，如：
$$
\min_{\mathbf{X},\mathbf{Y}}\sum_{(u,i)\in\mathbb{D}^*}(r_{u,i}-\vec{\mathbf{x}}_u\cdot\vec{\mathbf{y}}_i)^2+\lambda(||\vec{\mathbf{x}}_u||^2+||\vec{\mathbf{y}}_i||^2)
$$
其中：$\mathbb{D}^*$为数据集中存在观测值的部分。$\mathbf{X}\in\mathbb{R}^{m\times f}$为用户因子矩阵，每一行代表一个用户的因子向量；$\mathbf{Y}\in\mathbb{R}^{n\times f}$为`item` 因子矩阵，每一行代表一个`item` 的因子向量。

定义二元变量$p_{u,i}$来指示用户$u$是否喜欢 `item`$i$：
$$
\begin{equation}p_{u,i}=\left\{\begin{array}{ll}
1, & r_{u,i}>0\\
0, & r_{u,i}=0
\end{array}\right.\end{equation}
$$
如果用户$u$购买了 `item`$i$，则认为用户$u$喜欢 `item`$i$；如果用户$u$从未购买 `item`$i$，则认为用户$u$不喜欢 `item`$i$。我们认为：随着$r_{u,i}$的增长，越能够表明用户确实喜欢该商品。因此我们引入一组变量$c_{u,i}$用于表明$p_{u,i}$的置信度水平。$c_{u,i}$的一个合理选择是：
$$
c_{u,i}=1+\alpha r_{u,i}
$$
其中：超参数$\alpha$为置信度增长率，通过实验表明$\alpha=40$可以得到一个很好的结果。常数 `1` 是为了对所有的$r_{u,i}$取值范围都能得到一个非零的置信度。

每个用户$u$对应一个用户因子向量$\vec{\mathbf{x}}_u\in\mathbb{R}^f$，每个`item`$i$对应一个`item` 因子向量$\vec{\mathbf{y}}_i\in\mathbb{R}^f$，$f$为潜在因子的数量。我们建模用户偏好为两个向量的内积：
$$
\hat{p}_{u,i}=\vec{\mathbf{x}}_u\cdot\vec{\mathbf{y}}_i
$$
然后通过最小化代价函数来求解参数：
$$
\min_{\mathbf{X},\mathbf{Y}}\left(\sum_{u,i}c_{u,i}(p_{u,i}-\vec{\mathbf{x}}_u\cdot\vec{\mathbf{y}}_i)^2\right)+\lambda\left(\sum_u||\vec{\mathbf{x}}_u||^2+\sum_i||\vec{\mathbf{y}}_i||^2\right)
$$
跟显式反馈数据中的矩阵分解有两个重要区别：需要考虑置信度$c_{u,i}$。需要考虑所有的 `user-item` ，而不仅仅是观测数据对应的

事实上我们可以修改偏好$p_{u,i}$和$r_{u,i}$的关系，如增加阈值$\eta$，使得：
$$
\begin{equation}p_{u,i}=\left\{\begin{array}{ll}
1, & r_{u,i}>\eta\\
0, & r_{u,i}\le\eta
\end{array}\right.\end{equation}
$$
类似地，我们也可以修改置信度$c_{u,i}$和$r_{u,i}$的关系：$c_{u,i}=1+\log(1+r_{u,i}/\epsilon)$

##### `PMF`

低维因子模型`low-dimensional factor model` 是最流行的协同过滤方法之一，该模型背后的思想是：用户偏好是由少量未观察到的因子`unobserved factor` 决定的。

概率矩阵分解 `Probabilistic Matrix Factorization:PMF` 模型可以轻松的处理非常大的数据，并且也可以处理评分数量稀少的用户。

假设有$m$个用户、$n$个 `item` 。假设评分为：从整数$1,2,\cdots,K$，$r_{i,j}\in\{1,2,\cdots,K\}$为用户$i$对 `item`$j$的评分，其中对于缺失值我们定义$r_{i,j}=0$。定义$\mathbf{U}\in\mathbb{R}^{d\times m}$为用户因子矩阵，第$i$列$\vec{\mathbf{u}}_i$代表用户$i$的因子向量。定义$\mathbf{V}\in\mathbb{R}^{d\times n}$为 `item` 因子矩阵，第$j$列$\vec{\mathbf{v}}_j$代表`item`$j$的因子向量。定义观测值的条件分布为：
$$
p(\mathbf{R}|\mathbf{U},\mathbf{V},\sigma^2)=\prod_{i=1}^m\prod_{j=1}^n\left[\mathcal{N}(r_{i,j}|\vec{\mathbf{u}}_i,\vec{\mathbf{v}}_j,\sigma^2)\right]^{I(i,j)}
$$
其中：$\mathcal{N}(\mu,\sigma^2)$为均值为$\mu$、方差为$\sigma^2$高斯分布的概率密度函数。$I(i,j)$为示性函数：
$$
\begin{equation}p_{u,i}=\left\{\begin{array}{ll}
1, & r_{u,i}>0\\
0, & r_{u,i}=0
\end{array}\right.\end{equation}
$$
进一步的，我们假设用户因子向量和 `item` 因子向量采用零均值的球形高斯先验分布 `spherical Gaussian` ：
$$
p(\mathbf{U}|\sigma^2_U)=\prod_{i=1}^m\mathcal{N}(\vec{\mathbf{u}}_i|\vec{\mathbf{0}},\sigma_U^2\mathbb{I})\\
p(\mathbf{V}|\sigma^2_V)=\prod_{j=1}^n\mathcal{N}(\vec{\mathbf{V}}_j|\vec{\mathbf{0}},\sigma_V^2\mathbb{I})
$$
其中$\sigma_U^2,\sigma_V^2$为先验方差。则后验概率分布的对数为：
$$
\log p(\mathbf{U},\mathbf{V}|\mathbf{R},\sigma^2,\sigma_U^2,\sigma_V^2)=-\frac{1}{2\sigma^2}\sum_{i=1}^m\sum_{j=1}^nI(i,j)(r_{i,j}-\vec{\mathbf{u}}_i\cdot\vec{\mathbf{v}}_j)^2-\frac{1}{2\sigma^2_U}\sum_{i=1}^m\vec{\mathbf{u}}_i\cdot\vec{\mathbf{u}}_i\\
-\frac{1}{2\sigma^2_V}\sum_{i=1}^n\vec{\mathbf{v}}_j\cdot\vec{\mathbf{v}}_j-\frac{1}{2}\left(\left(\sum_{i=1}^m\sum_{j=1}^nI(i,j)\right)\log\sigma^2+md\log\sigma^2_U+nd\log\sigma^2_V\right)+C
$$
其中$C$为不依赖于任何参数的常数。当固定$\sigma^2,\sigma_U^2,\sigma_V^2$时，最大化后验分布等价于最小化带正则化项的误差平方和：
$$
\mathcal{L}=\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^nI(i,j)(r_{i,j}-\vec{\mathbf{u}}_i\cdot\vec{\mathbf{v}}_j)^2+\frac{\lambda_U}{2}\sum_{i=1}^m||\vec{\mathbf{u}}_i||_{\text{Fro}}+\frac{\lambda_V}{2}\sum_{i=1}^n||\vec{\mathbf{v}}_j||_{\text{Fro}}
$$
其中：$\lambda_U=\frac{\sigma^2}{\sigma_U^2},\lambda_V=\frac{\sigma^2}{\sigma_V^2}$为正则化系数。$||\cdot||_{\text{Fro}}$为 `Frobenius` 范数。

我们可以通过对$\mathcal{L}$进行梯度下降从而求解参数$\mathbf{U},\mathbf{V}$。

`PMF` 模型可以视为 `SVD` 模型的概率扩展。当我们能够观察到所有的`user-item` 评分时，在先验方差$\sigma_U^2,\sigma_V^2$无穷大的限制下，`PMF` 模型退化为 `SVD` 模型。事实上，上述推导过程存在一个问题：预测结果$\vec{\mathbf{u}}_i\cdot\vec{\mathbf{v}}_j$容易超出评分范围。因此 `PMF` 使用 `logistic` 函数来限定评分范围：
$$
g(x)=\frac{1}{1+\exp(-x)}\\
p(\mathbf{R}|\mathbf{U},\mathbf{V},\sigma^2)=\prod_{i=1}^m\prod_{j=1}^n\left[\mathcal{N}(r_{i,j}|g(\vec{\mathbf{u}}_i\cdot\vec{\mathbf{v}}_j),\sigma^2)\right]^{I(i,j)}
$$
在训练过程中我们将评分$1,2,\cdots,K$使用函数$f(x)=\frac{x-1}{K-1}$映射到区间 `[0,1]`；在预测过程中我们使用$(K-1)\times(\vec{\mathbf{u}}_i\cdot\vec{\mathbf{v}}_j)+1$将结果映射回评分。

模型容量对于 `PMF` 模型的泛化至关重要。

- 超参数 可以控制模型容量，当 足够大时 `PMF` 模型能够逼近任何给定的矩阵。因此，控制 `PMF` 模型容量的最简单直接的方法是限制$d$的大小。
- 另一种方式是采用正则化来控制模型容量，如$\lambda_U,\lambda_V$。

论文提出了一个自动确定 `PMF` 正则化系数的变种，称作自适应 `PMF` 。这种方式可以自动选择合适的正则化系数，并且不会显著影响模型训练时间。其基本原理是：引入超参数的先验分布，并最大化模型在参数$\mathbf{U},\mathbf{V}$和超参数$\sigma_U^2,\sigma_V^2$上的对数后验分布：
$$
\log p(\mathbf{U},\mathbf{V},\sigma^2,\Theta_U,\Theta_V|\mathbf{R})=\log p(\mathbf{R}|\mathbf{U},\mathbf{V},\sigma^2)+\log p(\mathbf{U}|\Theta_U)+p(\mathbf{V}|\Theta_V)\\
+\log p(\Theta_U)+\log p(\Theta_V)+ C
$$
其中：$C$是和任何参数无关的常数。$\Theta_U,\Theta_V$分别为针对用户因子向量 、`item` 因子向量的先验分布的超参数。当先验分布$p(\mathbf{U}|\Theta_U),p(\mathbf{V}|\Theta_V)$为球形高斯分布时，这会得到一个常规模型并能够自动选择$\lambda_U$和$\lambda_V$。

上述 `PMF` 模型存在一个问题：对于评分非常少的用户，他们的用户因子向量将趋近于先验均值，或者说用户因子向量的均值，因此这些用户的预测评分将接近所有评分的均值。论文提出了一种约束用户因子向量的方法，这种方法对于评分稀少的用户具有很强的效果。定义$\mathbf{W}\in\mathbb{R}^{d\times n}$为一个潜在的相似约束矩阵，定义用户$i$的因子向量为：
$$
\vec{\mathbf{u}}_i=\vec{\mathbf{y}}_i+\sum_{k=1}^ns_{i,k}\vec{\mathbf{w}}_k\\
s_{i,k}=\frac{I(i,k)}{\sum{j=1}^nI(j,k)}
$$
我们定义观察值的条件分布为：
$$
p(\mathbf{R}|\mathbf{Y},\mathbf{V},\mathbf{W},\sigma^2)=\prod_{i=1}^m\prod_{j=1}^n\left[\mathcal{N}\left(r_{i,j}|g\left(\left(\vec{\mathbf{y}}_i+\sum_{k=1}^ns_{i,k}\vec{\mathbf{w}}_k\right)\cdot\vec{\mathbf{v}}_j\right),\sigma^2\right)\right]^{I(i,j)}
$$
假设$\mathbf{W}$服从一个零均值的球形高斯分布。则有：最大化对数后验概率，等价于最小化带正则化项的误差平方和：
$$
\mathcal{L}=\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^nI(i,j)\left(r_{i,j}-g\left(\left(\vec{\mathbf{y}}_i+\sum_{k=1}^ns_{i,k}\vec{\mathbf{w}}_k\right)\cdot\vec{\mathbf{v}}_j\right)\right)^2\\+\frac{\lambda_Y}{2}\sum_{i=1}^m||\vec{\mathbf{y}}_i||_{\text{Fro}}+\frac{\lambda_V}{2}\sum_{i=1}^n||\vec{\mathbf{v}}_j||_{\text{Fro}}+\frac{\lambda_W}{2}\sum_{i=1}^k||\vec{\mathbf{w}}_k||_{\text{Fro}}
$$
我们可以对$\mathcal{L}$执行梯度下降来求解参数$\mathbf{Y},\mathbf{V},\mathbf{W}$，训练时间和观察值的数量成线性比例。实验表明，这种方式的效果比简单的无约束 `PMF` 模型效果好得多，尤其是针对评分数量稀少的用户。

##### `SVD++`

`CF` 系统需要比较本质上不同的两种对象`user` 和 `item` ，主要有两类方法可以执行这种比较。这两种方法构成了`CF` 的两个主要流派`discipline`：

- 邻域方法 `neighborhood approach`：邻域方法的核心是计算 `item` 之间的相似性或者 `user` 之间的相似性。

- 潜在因子模型`latent factor model`：诸如奇异值分解`SVD` 之类的潜在因子模型通过将 `user` 和 `item` 分别映射到同一个潜在因子空间，从而使得它们可以直接进行比较。


这两种方法处理的是数据种不同层次`level` 的结构，因此它们都不是最优的。

- 邻域模型在检测局部关系最为有效，它依赖于少数几个重要的邻域关系，从而忽略了用户的其它绝大多数评分。因此该方法无法捕获用户所有评分种包含的全部弱信号。
- 潜在因子模型通常有效地估计与所有 `item` 有关的整体结构。但是它在检测少数紧密相关的`item` 之间的局部强相关性表现不佳。

`SVD ++` 模型来融合了这两种方法，从而同时利用邻域方法和潜在因子方法的优势来提高预测准确性，`SVD ++` 同时利用了用户的显式反馈和隐式反馈，从而进一步提高准确性。

令$r_{u,i}$表示用户$u$在 `item`$i$上的评分，评分越高表示用户$u$越喜欢 `item`$i$；令$\hat{r}_{u,i}$表示模型预估的用户$u$对 `item`$i$的评分。定义$\mathcal{K}=\{(u,i)|r_{u,i}\text{ is known}\}$为评分已知的 `user-item pair` 对；定义$\mathbb{U}$为所有用户集合，$\mathbb{I}$为所有 `item` 集合；定义$\mathbb{U}_i$为对 `item`$i$评分的用户集合，$\mathbb{I}_u$为用户$u$评分的`item` 集合：
$$
\mathbb{U}_i=\{u|(u,i)\in\mathcal{K}\},\mathbb{I}_u=\{i|(u,i)\in\mathcal{K}\}
$$
最简单的预估模型为：$\hat{r}_{u,i}=\mu$，其中$\mu$为所有 `user-item` 的均值：
$$
\mu=\frac{\sum_{(u,i)\in\mathcal{K}}r_{u,i}}{|\mathcal{K}|}
$$
但是考虑到用户效应或者 `item` 效应：某些用户相对于其它用户始终会给一个较高的评分、某些`item` 相对于其它`item` 始终会收到一个较高的评分，那么我们的 `Baseline` 模型为：$b_{u,i}=\mu+b_u+b_i$。其中：$b_u$为用户$u$和均值的偏差、$b_i$为`item`$i$和均值的偏差，它们是模型的参数。

大多数`ItemBased CF` 方法的核心是计算 `item` 之间的相似性。通常采用基于 `Pearson` 相关系数$\rho_{i,j}$作为相似性的度量，它衡量了所有用户在 `item`$i$和 `item`$j$上评分的相似性。考虑到评分是稀疏的，因此很多 `item` 之间仅共享非常少的几个评分用户，而相关系数的计算仅仅在这些很少的、共同的评分用户上进行。因此，当共享的评分用户越少，计算到的相关系数越不可靠。因此我们调整相关系数为：
$$
s_{i,j}=\frac{n_{i,j}}{n_{i,j}+\lambda_2}\rho_{i,j}
$$
其中$n_{i,j}$为 `item`$i$和 `item`$j$之间共同评分的用户数量，$\lambda_2$为平滑系数，典型的值为 `100` 

给定 `item`$i$和用户$u$，我们定义用户$u$已经评分过的、和 `item`$i$最相似的 `top k` 个 `item` 为$\mathcal{S}^k(i;u)$。用户$u$对 `item`$i$的预估评分看作是这些相似 `item` 的评分的加权均值，同时考虑了 `user` 效应和 `item` 效应：
$$
\hat{r}_{u,i}=b_{u,i}+\sum_{j \in\mathcal{S}^k(i;u)}w_{i,j}^u(r_{u,j}-b_{u,j})\\
w_{i,j}^u=\frac{s_{i,j}}{\sum_{k \in\mathcal{S}^k(i;u)}s_{i,k}}\\
b_{u,i}=\mu+b_u+b_i
$$
这里$w_{i,j}^u$表示 `item` 权重不仅和 `item`$i,j$的相似度有关，还和用户$u$有关。

提出了一个更准确的邻域模型：给定邻域集合$\mathcal{S}^k(i;u)$，我们计算插值权重$\{\theta_{i,j}^u|j\in\mathcal{S}^k(i;u)\}$，从而实现预测：
$$
\hat{r}_{u,i}=b_{u,i}+\sum_{j \in\mathcal{S}^k(i;u)}\theta_{i,j}^u(r_{u,j}-b_{u,j})
$$
`NSVD` 模型避免显式地参数化每个用户的参数，而是根据他们已经评分的`item` 来对用户进行建模。因此，每个 `item` 关联两个因子向量$\vec{\mathbf{q}}_i$和$\vec{\mathbf{x}}_i$。用户 的 `representation` 为：
$$
\frac{1}{\sqrt{|\mathbb{I}_u|}}\sum_{j\in\mathbb{I}_u}\vec{\mathbf{x}}_j
$$
因此有：
$$
\hat{r}_{u,i}=b_{u,i}+\left(\frac{1}{\sqrt{|\mathbb{I}_u|}}\sum_{j\in\mathbb{I}_u}\vec{\mathbf{x}}_j\right)^T\vec{\mathbf{q}}_i
$$
每个用户$u$和两组 `item` 关联：一组`item` 用$\mathbb{I}_u$表示，它表示显式反馈的 `item` 集合；另一组 `item` 用$\mathbb{N}_u$表示，它表示隐式反馈的 `item` 集合。定义 `item`$i$相对于 `item`$j$的权重为$w_{i,j}$，模型的初始版本为：
$$
\hat{r}_{u,i}=b_{u,i}+\sum_{j\in\mathbb{I}_u}(r_{u,j}-b_{u,j})w_{i,j}
$$
其中$w_{i,j}$为模型参数，它从训练数据中学习得到。

通常邻域模型中的权重代表了未知评分与已知评分相关的插值系数，但是这里我们采用不同的观点：权重$w_{i,j}$代表了和 `baseline` 的偏移量，残差$r_{u,j}-b_{u,j}$代表了这些偏移量施加的系数。即我们在$u$对$i$的评分 `baseline` 上增加了$(r_{u,j}-b_{u,j})w_{i,j}$：对于两个相关的 `item`$i,j$，我们预计$w_{i,j}$会很高；如果$u$在$j$上的评分超过预期，即$r_{u,j}-b_{u,j}$很大，则我们预计$u$对$i$的评分会更高。这一观点带来几个改进：

- 首先我们可以使用隐式反馈，它提供了另一种方式来了解用户偏好。因此我们修改模型为：
  $$
  \hat{r}_{u,i}=b_{u,i}+\sum_{j\in\mathbb{I}_u}(r_{u,j}-b_{u,j})w_{i,j}+\sum_{j\in\mathbb{N}_u}c_{i,j}
  $$
  对于两个`item`$i,j$，用于$u$在 `item`$j$上的隐式偏好使得我们可以通过$c_{i,j}$来影响$r_{u,i}$。

- 将权重视为全局偏移量，而不是`user-specific` 的插值系数，可以降低评分缺失的影响，即：用户的偏好不仅取决于他已评分的`item`，还取决于他未评分的 `item` 。因为如果$w_{i,j}$较大，但是$j$不在$\mathbb{I}_u$中，则预估结果相对于评分未缺失的情况更低。

- 在邻域模型中，因为$\hat{r}_{u,i}$是通过对$\{r_{u,j}-b_{u,j}|j\in\mathcal{S}^k(i;u)\}$进行插值得到，这里不再使用插值的解释，因此可以解耦$b_{u,i}$和$b_{u,j}$的定义。一个更通用的做法是：
  $$
  \hat{r}_{u,i}=\tilde{b}_{u,i}+\sum_{j\in\mathbb{I}_u}(r_{u,j}-b_{u,j})w_{i,j}+\sum_{j\in\mathbb{N}_u}c_{i,j}
  $$
  其中$\tilde{b}_{u,i}$为其它方法，如潜在因子模型预估的结果。

当且方案的一个特点是：对于显式评分很多或者隐式反馈很多 的用户，预估评分更大。

通常这也是推荐系统预期的：

- 对于更活跃的用户(显式反馈更多或隐式反馈更多)，我们掌握的信息更多，则我们的推荐更激进，我们预估的评分比 `baseline` 有一个很大的偏差。
- 对于不活跃的用户（显式反馈更多或隐式反馈更少），我们掌握的信息非常少，则我们的推荐更保守，这种情况下我们希望保持接近 `baseline` 的安全估计。

但是我们的经验表明，模型在某种程度上过分强调了活跃用户和不活跃用户。因此我们通过调整预测模型，从而缓解这个现象：
$$
\hat{r}_{u,i}=\tilde{b}_{u,i}+|\mathbb{I}_u|^{-1/2}\sum_{j\in\mathbb{I}_u}(r_{u,j}-b_{u,j})w_{i,j}+|\mathbb{N}_u|^{-1/2}\sum_{j\in\mathbb{N}_u}c_{i,j}
$$
进一步的，我们可以通过移除不太相似的 `item` 从而减少参数来降低模型复杂度。定义$\mathcal{S}^k(i)$为和 `item`$i$最相似的$k$个 `item`，定义$\mathbb{I}_u^k(i)=\mathbb{I}_u\cap\mathcal{S}^k(i),\mathbb{N}_u^k(i)=\mathbb{N}_u\cap\mathcal{S}^k(i)$。我们认为：最具影响力的权重与 `item` 最相关的 `item` 关联，则有：
$$
\hat{r}_{u,i}=\tilde{b}_{u,i}+|\mathbb{I}^k_u|^{-1/2}\sum_{j\in\mathbb{I}^k_u}(r_{u,j}-b_{u,j})w_{i,j}+|\mathbb{N}^k_u|^{-1/2}\sum_{j\in\mathbb{N}^k_u}c_{i,j}
$$
我们在预处理阶段来估计参数，因此预处理阶段包含了最大的计算量。我们最小化损失函数：
$$
\min_{\mathbf{b},\mathbf{w},\mathbf{c}}\sum_{(u,i)\in\mathcal{K}}(r_{u,i}-\hat{r}_{u,i})^2+\lambda\left(\sum_{u\in\mathbb{U}}b_u^2+\sum_{i\in\mathbb{I}}b_i^2+\sum_{i,j\in\mathbb{I}}w_{i,j}^2+\sum_{i,j\in\mathbb{I}}c_{i,j}^2\right)
$$
该问题是一个凸优化问题，可以通过最小二乘求解器来求解。但是，我们发现基于梯度下降的方法来求解时，求解速度更快。

基础的 `SVD` 模型为：
$$
\hat{r}_{u,i}=b_{u,i}+\vec{\mathbf{p}}_u^T\vec{\mathbf{q}}_i
$$
我们希望通过考虑隐式信息来扩展该模型，我们认为每个 `item`$i$关联三个因子向量：$\vec{\mathbf{q}}_i,\vec{\mathbf{x}}_i,\vec{\mathbf{y}}_i\in\mathbb{R}^f$，其中用户$u$的表达通过该用户显式反馈的 `item` 因子向量$\vec{\mathbf{x}}_i$和隐式反馈的 `item` 因子向量$\vec{\mathbf{y}}_i$来表示，即：
$$
\vec{\mathbf{p}}_u=\left(|\mathbb{I}_u|^{-1/2}\sum_{j\in\mathbb{I}_u}(r_{u,j}-b_{u,j})\vec{\mathbf{x}}_j+|\mathbb{N}_u|^{-1/2}\sum_{j\in\mathbb{N}_u}\vec{\mathbf{y}}_j\right)
$$
因此模型调整为：
$$
\hat{r}_{u,i}=b_{u,i}+\vec{\mathbf{q}}_i^T\left(|\mathbb{I}_u|^{-1/2}\sum_{j\in\mathbb{I}_u}(r_{u,j}-b_{u,j})\vec{\mathbf{x}}_j+|\mathbb{N}_u|^{-1/2}\sum_{j\in\mathbb{N}_u}\vec{\mathbf{y}}_j\right)
$$
这个新模型我们命名为非对称`SVD` （`Asymmetric-SVD`），非对称`SVD` 的最小化损失函数：
$$
\min_{\mathbf{Q},\mathbf{X},\mathbf{Y},\mathbf{b}}\sum_{(u,i)\in\mathcal{K}}(r_{u,i}-\hat{r}_{u,i})^2+\lambda\left(\sum_{u\in\mathbb{U}}b_u^2+\sum_{i\in\mathbb{I}}b_i^2+\sum_{i\in\mathbb{I}}||\vec{\mathbf{q}}_i||+\sum_{i\in\mathbb{I}}||\vec{\mathbf{x}}_i||+\sum_{i\in\mathbb{I}}||\vec{\mathbf{y}}_i||\right)
$$
如果仅仅融合隐式反馈数据，则我们可以得到更准确的结果。我们认为每个 `item`$i$关联两个因子向量：$\vec{\mathbf{q}}_i,\vec{\mathbf{y}}_i\in\mathbb{R}^f$，每个用户$u$关联一个因子向量$\vec{\mathbf{p}}_u$。最终用户$u$通过$\vec{\mathbf{p}}_u+|\mathbb{N}_u|^{-1/2}\sum_{j\in\mathbb{N}_u}\vec{\mathbf{y}}_j$来建模。因此`SVD` 模型调整为：
$$
\hat{r}_{u,i}=b_{u,i}+\vec{\mathbf{q}}_i^T\left(\vec{\mathbf{p}}_u+|\mathbb{N}_u|^{-1/2}\sum_{j\in\mathbb{N}_u}\vec{\mathbf{y}}_j\right)
$$
我们称这个模型为 `SVD++` ，其中参数可以通过梯度下降来最小化损失函数得到。`SVD++` 没有非对称`SVD` 涉及的诸多好处，这是因为 `SVD++` 采用了用户因子向量来抽象每个用户。但是上表可以看到，就预测准确性而言 `SVD++` 显然更具有优势。

潜在因子模型和邻域模型可以很好的互补，这里我们将邻域模型和 `SVD++` 模型整合在一起，最终得到模型：
$$
\hat{r}_{u,i}=\mu+b_u+b_i+\vec{\mathbf{q}}_i^T\left(\vec{\mathbf{p}}_u+|\mathbb{N}_u|^{-1/2}\sum_{j\in\mathbb{N}_u}\vec{\mathbf{y}}_j\right)+|\mathbb{I}^k_u|^{-1/2}\sum_{j\in\mathbb{I}^k_u}(r_{u,j}-b_{u,j})w_{i,j}+|\mathbb{N}^k_u|^{-1/2}\sum_{j\in\mathbb{N}^k_u}c_{i,j}
$$
从某种意义上讲，该公式提供了三层模型：

- 第一层：$\mu+b_u+b_i$描述了 `item` 和 `user` 的一般属性，未涉及任何 `user-item` 交互行为。
- 第二层：$\vec{\mathbf{q}}_i^T\left(\vec{\mathbf{p}}_u+|\mathbb{N}_u|^{-1/2}\sum_{j\in\mathbb{N}_u}\vec{\mathbf{y}}_j\right)$提供了用户和 `item` 之间的交互。
- 第三层：邻域评分有助于进一步的精细化调整

##### `MMMF`拓展



##### `OCCF`

协同过滤中的很多应用，如新闻推荐和商品推荐，很自然的是 `One-Class Collaborative Filtering:OCCF` 问题。在该问题中，训练数据通常是反应用户有没有行为的二元`binary` 数据，如：用户是否阅读新闻。

在 `OCCF` 问题中有两个挑战：

- 通常只有非常少的正样本，导致数据非常稀疏。
- 缺失的数据是负样本和潜在正样本的混合体，并且无法区分。

有几种简单的策略用于解决 `OCCF` 问题：

- 一种策略是想办法标记缺失数据，从而将 `OCCF` 转变为经典的协同过滤问题。但是，这需要用户的密切配合来标记数据，代价太大甚至难以进行，因为用户通常不愿意承担这种成本。
- 另一种策略是将所有缺失数据视为负样本，称作 `All Missing As Negative:AMAN` 。经验表明，这种策略的效果很好。但是，由于某些缺失数据可能是正样本，因此推荐的结果是有偏的。
- 还有一种策略是将所有缺失值视为未知的，即忽略所有缺失的样本而仅使用正样本，称作 `All Missing As Unkown:AMAU` 。在使用过程中，我们将这些非缺失值灌入针对非缺失值建模的协同过滤算法。但是该方法存在一个平凡解`trivial solution`：将所有缺失值预估为正样本。

第一种方案是基于加权的低秩近似，基本思想是为目标函数中的正样本误差和负样本误差赋予不同的权重。

第二种方案是基于负样本的采样，基本思想是利用某些采样策略对一些缺失值进行采样从而得到负样本。

它们都充分利用了缺失值中包含的信息，并纠正了将其视为负样本的 `bias` 。第一种方案可以得到理论上的最优解，第二种方案拥有更好的`scalability` 从而扩展到大型稀疏数据集。



##### `BPR`