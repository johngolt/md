##### `MIND`

工业推荐系统通常包含 `matching` 阶段和 `ranking` 阶段，从而处理数十亿规模的用户和 `item` 。`matching` 阶段负责检索与用户兴趣相关的数千个候选 `item`。此后，`ranking` 阶段将预测用户和这些候选`item` 进行交互的精确的概率。

对于这两个阶段，为用户兴趣建模并找到捕获用户兴趣的用户 `representation` 至关重要，以便支持有效检索满足用户兴趣的 `item`。

现有的推荐算法以不同方式建模并代表用户兴趣：

- 基于协同过滤的方法通过历史交互`item` 或者潜在因子来代表用户兴趣。这些遭受数据稀疏问题或面临计算复杂度高的问题。
- 基于深度学习的方法通常使用低维 `embedding` 向量来表示用户兴趣。这可能是建模多样化兴趣的瓶颈，因为固定长度向量的维度必须一定要很大。
- `DIN` 通过注意力机制来捕获用户兴趣的多样性，从而使得用户`representation` 在不同`item` 上有所不同。但是，由于采用了注意力机制，其计算规模比较大，使得 `DIN` 仅适用于 `ranking` 阶段。

`MIND` 为了推断用户 `representation` 向量，设计了一个称为多兴趣抽取器层`multi-interest extractor layer`，它利用动态路由将用户的历史行为自适应地聚合到用户 `representation` 中。

- 动态路由的过程可以视作软聚类 `soft-clustering` ，历史行为的每个簇`cluster` 进一步用于推断与一个特定兴趣相对应的用户 `representation` 向量。这样对于特定用户，`MIND` 输出多个`representation` 向量，这些向量共同表示用户的多样化兴趣。
- 用户 `representation` 向量仅需要计算一次，并且可以在 `matching` 阶段用于从十亿规模的 `item` 中检索相关 `item`。

另外，`MIND`还开发了一种称作标签感知注意力的技术，从而帮助学习具有多向量的用户 `representation` 。

工业推荐系统 `matching` 阶段的目标是为每个用户$u\in\mathcal{U}$从十亿规模的 `item` 库$\mathcal{I}$中检索仅包含数千个`item` 的`item` 子集，其中该子集中每个 `item` 都和用户的兴趣相关。为了实现该目标，我们收集用户历史行为数据从而构建 `matching` 模型。具体而言，每个样本都可以用一个元组$(\mathcal{I}_u,\mathcal{P}_u,\mathcal{F}_i)$，其中：

- $\mathcal{I}_u$表示用户$u$交互的 `item` 集合，称作用户行为。
- $\mathcal{P}_u$为用户$u$的基础画像，如性别。
- $\mathcal{F}_i$为`target item`$i$的特征，如 `item id` 。

`MIND` 的核心任务是学习将原始特征映射到用户`representation` 的函数，即：
$$
\mathcal{V}_u=f_{\text{user}}(\mathcal{I}_u,\mathcal{P}_u)
$$
其中$\mathcal{V}_u=\{\vec{\mathbf{v}}_u^1,\cdots,\vec{\mathbf{v}}_u^K\}$为用户$u$的$K$个 `representation` 向量，向量维度为$d$。此外，通过 `embedding` 函数获得 `target item`$i$的`representation` 向量为：
$$
\vec{\mathbf{e}}_i=f_{\text{item}}(\mathcal{F}_i)
$$
当学习了用户 `representation` 向量、 `item representation` 向量之后，在线 `serving` 时根据评分函数检索 `top N` 候选`item`：
$$
f_{\text{score}}(\mathcal{V}_u,\vec{\mathbf{e}}_i)=\max_{1\le k\le K}\vec{\mathbf{e}}_i^T\vec{\mathbf{v}}_u^k
$$
其中$N$是在 `matching` 阶段要检索的、预定义的`item` 数。注意：$f_{\text{score}}$仅用于`serving` 阶段，而不用于训练阶段。

`MIND` 主要由以下部分组成：

- `Embedding&Pooling Layer`：来自输入层的 `id` 特征通过 `embedding` 层转换为 `embedding` ，然后每个 `item` 的各种`id embedding` 由池化层进一步取平均。
- `Multi-Interest Extractor Layer`：用户行为 `embedding` 被馈入多兴趣抽取器层从而产生兴趣胶囊。通过将兴趣胶囊和用户画像 `embedding` 拼接，然后经过几个 `ReLU` 的全连接层进行转换，可以得到用户 `representation` 向量。
- `Label-aware Attention Layer`：在训练过程中引入一个额外的标签感知注意力层，从而指导训练过程。

最后在`serving` 过程中，用户的多个 `representation` 向量用于通过最近邻检索来检索`item` 。

###### `Embeding&Pooling Layer`

`MIND` 的输入包含三组：用户画像$\mathcal{P}_u$、用户行为$\mathcal{I}_u$、`label item`$\mathcal{F}_i$，每组输入包含几个具有极高维数的 `categorical id` 特征。因此我们采用了广泛使用的 `embedding` 技术将这些 `ID` 特征嵌入到低维稠密向量中，从而显著减少了参数数量并简化了学习过程。

- 对于来自用户画像$\mathcal{P}_u$的 `id` 特征，对相应的 `embedding` 进行拼接从而构成用户画像 `embedding`$\vec{\mathbf{p}}_u$。
- 对于 `item` 的`item id` 以及其它 `categorical id`，这些 `id` 被证明有助于 `label item` 的冷启动，相应的 `embedding` 会进一步通过均值池化层从而形成 `label item embedding`$\vec{\mathbf{e}}_i$，即$f_{\text{item}}$函数。
- 对于来自用户行为$\mathcal{I}_u$​的 `item`，收集相应的 `item embedding` 从而形成用户行为 `embedding`${\Large\varepsilon}=\{\vec{\mathbf{e}}_i|i\in\mathcal{I}_u\}$​​，这些 `embedding` 构成了用户行为 `embedding` 矩阵$\mathbf{E}_u$​。

###### `Multi-Interest Extrator Layer`

我们认为，用一个 `representation` 向量表示用户兴趣可能是捕获用户的多样化兴趣的瓶颈，因为我们必须将与用户的多样化兴趣相关的所有信息压缩到一个`representation` 向量中。相反，我们采用多个`representation` 向量分别表达用户的不同兴趣。通过这种方式，我们可以在 `matching` 阶段分别考虑用户的多样化兴趣，从而可以更准确地检索各个方面的兴趣。为了学习多个 `representation` 向量，我们利用聚类过程将用户的历史行为分组为几个簇`cluster`。我们预期来自同一个簇的 `item` 将密切相关，并且共同代表了用户在某个特定方面的兴趣。

假设我们有两层胶囊，分别将第一层胶囊和第二层胶囊称作低层胶囊`low-level capsule` 、高层胶囊`high-level capsule` 。动态路由的目标是以迭代的方式在给定低层胶囊值的情况下计算高层胶囊值。

在每次迭代中，给定低层胶囊$i\in\{1,\cdots,m\}$​对应的值$\{\vec{\mathbf{c}}_1^l,\cdots,\vec{\mathbf{c}}_m^l\}$​、以及高层胶囊$j\in\{1,\cdots,n\}$​对应的值$\{\vec{\mathbf{c}}_1^h,\cdots,\vec{\mathbf{c}}_n^h\}$​，其中$\vec{\mathbf{c}}_i^l\in\mathbb{R}^{N_l},\vec{\mathbf{c}}_j^h\in\mathbb{R}^{N_h}$​。则低层胶囊$i$和高层胶囊$j$之间的 `routing logit`$b_{i,j}$为：
$$
b_{i,j}=(\vec{\mathbf{c}}_j^h)^T\mathbf{S}_{i,j}\vec{\mathbf{c}}_i^l
$$
其中$\mathbf{S}_{i,j}\in\mathbb{R}^{N_h\times N_l}$为待学习的双线性映射矩阵。当计算好`routing logit`之后，高层胶囊 的 `value vector` 更新为：
$$
\begin{array}{cccc}\large\vec{\mathbf{z}}_j^h=\sum_{i=1}^m\omega_{i,j}\mathbf{S}_{i,j}\vec{\mathbf{c}}_i^l,\quad\omega_{i,j}=\frac{\exp(b_{i,j})}{\sum_{k=1}^m\exp(b_{i,k})}\\
\large\vec{\mathbf{c}}_j^h=\text{squash}(\vec{\mathbf{z}}_j^h)=\frac{||\vec{\mathbf{z}}_j^h||^2\vec{\mathbf{z}}_j^h}{1+||\vec{\mathbf{z}}_j^h||^2\vec{\mathbf{z}}_j^h}
\end{array}
$$
另外，$b_{i,j}$的值将被初始化为零。整个路由过程通常需要 `3` 轮迭代才会收敛。路由结束后，高层胶囊的值向量$\vec{\mathbf{c}}_j^h$​通常会固定不变，并且可以用于下一层 `layer` 的输入。

针对图像数据提出的原始路由算法并不能用于直接处理用户行为数据。因此，我们提出了 `Behavior-to-Interest:B2I` 动态路由，用于将用户的行为自适应地聚合到兴趣`representation` 向量中，这和原始路由算法在三个方面有所不同：

- 共享双线性映射矩阵：基于两方面的考虑，我们将每对低层胶囊和高层胶囊 `pair` 对之间使用固定的双线性映射矩阵$\mathbf{S}$，而不是在原始动态路由中独立的双线性映射矩阵。因此，`routing logit` 计算为：
  $$
  b_{i,j}=\vec{\mathbf{u}}_j^T\mathbf{S}\vec{\mathbf{e}}_i,\quad i\in\mathcal{I}_u, j\in\{1,\cdots,K\}
  $$
  其中：$\vec{\mathbf{e}}_i$为`behavior item` 的 `embedding`。$\vec{\mathbf{u}}_j$为 `interest capsule`$j$的向量，一共有$K$个兴趣。双线性映射矩阵$\mathbf{S}\in\mathbb{R}^{d\times d}$​在每对行为胶囊和兴趣胶囊`pair` 对之间共享。

- 随机初始化 `routing logit` ：由于使用了共享的双线性映射矩阵 ，将 `routing logit` 初始化为零导致所有用户具有相同的初始兴趣胶囊。然后在随后的每一轮迭代中，不同用户之间在当前轮次具有相同的兴趣胶囊。为了缓解这种现象，我们从高斯分布$\mathcal{N}(0,\sigma^2)$​中抽样一个随机矩阵作为初始 `routing logit` ，使得初始兴趣胶囊彼此不同。

- 动态兴趣数量：由于不同用户的兴趣数量可能不同，因此我们引入了一种启发式规则，用于针对不同用户自适应地调整$K$的值。用户$u$的$K$​值通过以下公式计算：

$$
K^{\prime}_u=\max(1,\min(K,\log_2(|\mathcal{I}|_u)))
$$

###### `Label-aware Attention Layer`

通过多兴趣抽取层，我们从用户的行为 `embedding` 中生成了多个兴趣胶囊。不同的兴趣胶囊代表了用户兴趣的不同方面，而且相关的兴趣胶囊用于评估用户对特定 `item` 的偏好。因此，在训练过程中我们基于 `scaled dot-product attention` 设计了标签感知注意力层。具体而言，对于一个目标 `item`：

- 首先，我们计算每个兴趣胶囊和目标`item embedding` 之间的相似性。
- 然后，我们计算兴趣胶囊的加权和作为针对目标 `item` 的用户 `representation` 向量，其中每个兴趣胶囊的权重由相应的相似性来确定。

在标签感知注意力层中，`label` 是 `query`，兴趣胶囊同时作为 `key` 和 `value`。用户$u$关于 `item`$i$的 `representation` 为：
$$
\vec{\mathbf{v}}_u(i)=\text{attention}(\vec{\mathbf{e}}_i,\mathbf{V}_u\,\mathbf{V}_u)=\mathbf{V}_u\text{softmax}(\text{pow}(\mathbf{V}_u^T\vec{\mathbf{e}}_i,p))
$$
其中：`pow()` 函数表示逐元素的指数函数。`p` 是一个超参数作为指数函数的指数项

`Training`：得到用户 `representation` 向量$\vec{\mathbf{v}}_u(i)$以及 `label item embedding`$\vec{\mathbf{e}}_i$之后，我们计算用户 和 `label item` 交互的概率为：
$$
P(i|u)=P(\vec{\mathbf{e}}_i|\vec{\mathbf{v}}_u(i))=\frac{\exp(\vec{\mathbf{v}}_u(i)^T\vec{\mathbf{e}}_i)}{\sum_{j\in\mathcal{I}}\exp(\vec{\mathbf{v}}_u(i)^T\vec{\mathbf{e}}_j)}
$$
训练 `MIND` 的目标函数为：
$$
\mathcal{L}=\sum_{(u,i)\in\mathcal{D}}\log P(i|u)
$$
其中$\mathcal{D}$是包含所有 `user-item` 交互的训练数据的集合。

> 注：这里没有负样本。没有负样本的情况下，存在一个解：将所有样本预估为正样本，此时损失函数最小。所以应该将有曝光、无交互的训练数据作为负样本。

由于 `item` 规模在数十亿级，因此 的分母计算量太大导致无法实现，因此我们采用采样的 `softmax` 技术`sampled softmax technique` 。

`Serving`：除了标签感知注意力层之外的 `MIND` 网络即为用户 `representation` 映射函数$f_{\text{user}}$。在 `serving` 期间：

- 用户的行为序列和用户画像馈入$f_{\text{user}}$函数，从而为每个用户生成多个 `representation` 向量。
- 然后，我们使用这些 `representation` 向量通过最近邻方法检索 `top N` 个 `item`，从而构成推荐系统 `matching` 阶段的最终候选 `item` 集。

##### `DNN For YouTube`

我们的推荐系统由两个神经网络组成：一个用于候选生成`candidate generation` 、一个用于排序 `ranking` 。

- 候选生成网络：从用户的 `YouTube` 历史行为记录中获取事件 `event` 作为输入，并从大型视频库中检索一小部分视频。这些候选视频倾向于和用户高度相关。
- 排序网络：根据一个细粒度`fine-level` 的`representation` 来区分高召回率`recall` 的候选视频之间的相对重要性，从而提供一些 “最佳” 推荐最终构成推荐列表。

在开发过程中，我们广泛使用离线指标（精度`precision`、召回率`recall`、`ranking loss` 等）来指导系统的迭代改进。然后，为了最终确定算法或模型的有效性，我们依靠在线实验`live experiment` 进行 `A/B test`。

在在线实验中，我们可以衡量 `click-through rate: CTR`、观看时长`watch time` 、以及其它衡量用户互动`user engagement` 指标的细微变化。

###### `Candidate Generation`

