### 传统的协同过滤方法

协同过滤是基于用户行为设计的推荐算法，具体来说，是通过群体的行为来找到某种相似性（用户之间的相似性或者物品之间的相似性），通过相似性来为用户做决策和推荐。

协同过滤包括协同和过滤两个操作。协同就是汇集所有用户的反馈、评价等（与网站不断进行互动。而过滤，通过协同得到的信息，从海量物品进行过滤，筛选出用户感兴趣的物品。

| 名称     | 说明                                                         |
| -------- | ------------------------------------------------------------ |
| 显示行为 | 用户明确的表达了自己的喜好，例如点赞、分享、关注、评分等。   |
| 隐式行为 | 用户没有明确表达自己的喜好，用户会用实际行动，例如点击、停留时长等隐性的行为表达自己的喜好。 |
|          |                                                              |

协同过滤模型的局限性，无法加入用户、物品属性、上下文特征等边信息，这是的丧失了很多有效信息，无法进行有效的推荐。

#### 基于邻域的方法

基于邻域的方法根据计算用户或物品的相似性的不同又细分为两种：基于用户的协同过滤和基于物品的协同过滤。

假设有$m$个用户$\mathbb{U}=\{u_1,\cdots,u_m\}$以及$n$个 `item`$\mathbb{I}=\{i_1,\cdots,i_n\}$。每个用户$u$有一个 `item` 评分列表$\mathbb{I}_u$，这个列表上用户有过评分，其中$\mathbb{I}_u\sub \mathbb{I}$且有可能为空。我们可以根据每个用户$u$的$\mathbb{I}_u$构建用户和物品的评分矩阵$R$
$$
\begin{equation}Y_{u i}=\left\{\begin{array}{ll}
R_{ui}, & \text { if } i \in \mathbb{I}_u \\
0, & \text { otherwise }
\end{array}\right.\end{equation}
$$
给定用户$u_a\in\mathbb{U}$，协同过滤算法任务包含两种形式：预测：预测用户$u_a$对于`item`$i_j \notin\mathbb{I}_{u_a}$的评分$P_{a,j}$；推荐：为用户$u_a$推荐他/她可能最喜欢的由$N$个 `item`组成的列表$\mathbb{I}_r \sub \mathbb{I}$，且$\mathbb{I}_r \cap \mathbb{I}=\empty$。

两个向量之间的相似度计算方法主要有如下几种：

- `Jaccard`系数：$J(\mathbf{X},\mathbf{Y})=\frac{\mathbf{X}\cap\mathbf{Y}}{\mathbf{X}\cup\mathbf{Y}}$
- `Cosine`相似度、`Pearson`相关系数

##### 基于用户的协同过滤

首先计算用户兴趣之间的相似性。给定用户$u$和$v$，定义他们共同评分的`item`集合为：
$$
\mathbb{I}_{u,v} = \{j|r_{u,j}>0 \and r_{v,j}>0\}
$$
其中$r_{i,j}$表示用户$i$对于`item`$j$的评分，该评分可能是已知的，也可能是未知的。然后计算用户$u,v$在这些共同评分`item`上的均值、方差、以及协方差，用户$u$和$v$的评分集合的相关系数：$s_{u,v}=\frac{\text{cov}(u,v)}{\sigma_u\sigma_v}$ 

预测用户$u$在未评分`item`$j^*$上的评分时，首先找出在$j^*$上存在评分的用户：$\mathbb{U}_{j^*}=\{i|r_{i,j^*}>0\}$。然后我们基于用户$u$和集合$\mathbb{U}$中用户的相似性来预测：
$$
w_v=\frac{s_{u,v}}{\sum_{v\in\mathbb{U}_{j^*}}s_{u,v}}\\
r_{u,j^*} = \overline{r}_u+\sum_{v\in \mathbb{U}_{j^*}}w_v(r_{v,j^*}-\overline{r}_v)
$$

##### 基于物品的协同过滤

首先探索`item` 之间的相似性；然后向用户推荐她/他喜欢的 `item` 类似的 `item` 。因为`item` 之间的关系是相对静态的，所以基于 `item` 的算法可以预计算`item-item` 相似性，从而减少在线计算的数量，同时保持较高的推荐质量。

选择目标用户$u_a$已经评分的`item` 集合$\mathbb{I}_{u_a}$，然后计算评分集合中的每个 `item` 和未评分集合$\mathbb{I}-\mathbb{I}_{u_a}$中每个 `item`$i_j$的相似度，然后选择$k$个最相似的、未评分的 `item`$\{i_1^a,\cdots,i_k^a\}$，并记录对应的相似度。

计算`item` 之间相似度的基本思想是：首先挑选既对$i$打分、又对$j$打分的用户$\mathbb{U}_{ij}$，然后基于这些用户的打分来计算相似度 。基于余弦的相似度：$sim(i,j) = \frac{\sum_{a\in\mathbb{U}_{ij}}r_{a,j}\times r_{a,j}}{\sqrt{\sum_{a\in\mathbb{U}_{ij}}r_{a,i}^2}\sqrt{\sum_{a\in\mathbb{U}_{ij}}r_{a,j}^2}}$

根据相似性得到了目标`item` 最相似的一组`item`，则下一步是为用户执行打分预测。

加权和 `weighted sum`：该方法通过用户已经评分的 `item` 中，根据和$i$的相似度进行加权得到预测结果。假设用户$a$已经评分，且与$i$相似的 `item` 集合为$\mathbb{S}_{i,a}$，则有
$$
P_{a,i} =\sum_{j\in\mathbb{S}_{i,a}}\omega_{ij}\times r_{a,j}\\
\omega_{i,j} = \frac{s_{i,j}}{\sum_{\mathbb{S}_{i,a}}s_{i,j}}
$$
回归`Regression`：采用加权和相同的公式，但是不使用原始打分$r_{a,j}$，而是使用基于线性回归的近似值$r_{a,j}^{\prime}$。假设目标 `item`$i$的打分向量为$\vec{\mathbf{r}}_{\cdot,i}$，相似 `item`$j$的修正打分为：$\vec{\mathbf{r}}_{\cdot,j}=\alpha_{i,j}\vec{\mathbf{r}}_{\cdot,i}+\beta_{i,j}$。然后最小化来求解参数$\alpha_{i,j},\beta_{i,j}$。最终有：
$$
P_{a,i} =\sum_{j\in\mathbb{S}_{i,a}}\omega_{ij}\times (\alpha_{i,j}\times r_{a,j}+\beta_{i,j})\\
\omega_{i,j} = \frac{s_{i,j}}{\sum_{\mathbb{S}_{i,a}}s_{i,j}}
$$

基于用户的协同过滤适合时效性较强，用户的个性化兴趣不太明显的领域，如新闻领域；而基于物品的协同过滤适合兴趣变化较为稳定的应用，比如电商场景、视频推荐等。对于基于邻近的方法，虽然其解释性较强，但是它并不具有较强的泛化能力。处理稀疏向量的能力弱。

#### 隐语义模型

![](../../picture/1/233.png)

协同过滤的思路要解决的问题用数据形式表达就是用户-物品的交互矩阵的未知部分如何填充问题。已知的值是用户已经交互过的物品，如何基于这些已知值填充矩阵剩下的未知值，也就是去预测用户没有交互过的物品是矩阵填充要解决的问题。

##### `SVD`分解

矩阵填充可以用经典的`SVD`解决，一般来说`SVD`求解可以分为三步：对 M 矩阵的缺失值填充为0；求解`SVD`问题，得到`U`矩阵和`V`矩阵；利用`U`和`V`矩阵的低秩`k`维矩阵来估计。

对于第二中的`SVD`求解问题等价于以下的最优化问题
$$
\text{argmin}_{U,\Sigma, V}(Y-U\Sigma V^T)^2=\text{arg min}_{U,\Sigma,V}\sum_{i=1}^{m}\sum_{j=1}^{n}(y_{ij}-(U\Sigma V^T)_{ij})^2
$$


其中$y_{ij}$为用户$i$对物品$j$的真实评分，也就是label，$U$和$V$为模型预估值，求解矩阵$U$和$V$的过程就是最小化用户真实评分矩阵和预测矩阵误差的过程。

这种`SVD`求解方法存在以下问题：缺失数据和可观测数据权重一样；最小化过程没有正则化，容易产生过拟合。

##### `MF`模型（矩阵分解）

矩阵分解模型提出的模型如下：$\hat{y}_{ui} = \mathbf{v}_u^T\mathbf{v}_i$。

`MF`模型的核心思想可以分成两步：将用户$u$对物品$i$的打分分解成用户的隐向量$\mathbf{v}_u$，以及物品的隐向量$\mathbf{v}_i$；用户$u$和物品$i$的向量点积得到的值，可以用来代表用户$u$对物品$i$的喜好程度，分数越高代表该物品推荐给用户的概率就越大。同时，`MF`模型引入了$l_2$正则来解决过拟合问题。
$$
L=\sum_{u}\sum_{i}w_{ui}(y_{ui}-\hat{y}_{ui})^2+\lambda(\sum_u||\mathbf{v}_u||^2+\sum_i||\mathbf{v}_i||^2)
$$

##### `FISM`模型

将用户喜欢过的物品作为用户的表达来刻画用户，用数据公式表示如下：
$$
\hat{y}_{ui} = (\sum_{j \in \mathcal{R}_u}\mathbf{q}_j)^T\mathbf{v}_i
$$
其中$\mathcal{R}_u$是用户$u$交互过的商品的集合，对于每一个物品，都有两个嵌入向量$\mathbf{q}$和$\mathbf{v}$，$\mathbf{q}$是商品作为交互历史中的物品时的嵌入向量，$\mathbf{v}$时物品是预测的物品时的嵌入向量。

用户表达不再是独立的隐向量，而是用用户喜欢过的所有物品的累加求和得到作为用户的表达；而 物品本身的隐向量$\mathbf{v}_i$是另一套表示，两者最终同样用向量内积表示。

##### `SVD++`模型

`MF`模型可以看成是 user-based 的 CF 模型，直接将用户id映射成隐向量，而`FISM`模型可以看成是 item-based 的`CF`模型，将用户交户过的 item 的集合映射成隐向量。`SVD++`正是这两者的结合，数学表达如下：
$$
\hat{y}_{ui} = (\mathbf{v}_u+\sum_{j \in \mathcal{R}_u}\mathbf{q}_j)^T\mathbf{v}_i
$$
每个用户表达分成两个部分，左边$\mathbf{v}_u$表示用户 id 映射的隐向量，右边是用户交互过的 item 集合的求和。User 和 item 的相似度还是用向量点击来表达。

矩阵分解有很多优点：泛化能力强；空间复杂度低。不需要存储用户相似或物品相似矩阵，只需存储用户和物品的隐向量；更好的扩展性和灵活性。矩阵分解最后得到用户和物品隐向量，这其实与深度学习中的Embedding思想不谋而合，因此矩阵分解的觉果非常便于与其他特征进行组合和拼接。

#### 基于图的随机游走方法

### 基于深度学习的协同过滤方法

对于$M$个用户$\mathcal{U}=\{u_1,\cdots,u_M\}$，$N$个物品$\mathcal{V}=\{v_1,\cdots,v_N\}$，评分矩阵$R\in\mathbb{R}^{M\times N}$，有两种方式构建user-item交互矩阵$Y\in\mathbb{R}^{M\times N}$
$$
\begin{equation}Y_{i j}=\left\{\begin{array}{ll}
0, & \text { if } R_{i j}=u n k \\
1, & \text { otherwise }
\end{array}\right.\end{equation}
$$

$$
\begin{equation}Y_{i j}=\left\{\begin{array}{ll}
0, & \text { if } R_{i j}=u n k \\
R_{ij}, & \text { otherwise }
\end{array}\right.\end{equation}
$$

#### 基于表示学习的模型

分别学习用户的表示以及物品的表示，也就是用户和物品各自的 embedding 向量，然后通过定义 matching score 的函数，一般是简单的向量点击、或者 cosine 距离来得到两者的匹配分数。

![](../../picture/1/235.png)

##### `CF`模型

`CF`模型用户和物品的输入分别是`userid`, `itemid`的`one-hot`编码，分别学习用户和物品的`embedding`向量$\mathbf{p}_u,\mathbf{q}_i$，然后通过向量内积得到$\hat{y}_{ui}=(u,i|\mathbf{p}_u,\mathbf{q}_i)=\mathbf{p}_u^T\mathbf{q}_i$

![CF模型](../../picture/1/236.png)

##### `DMF`模型

`DMF`模型的用户输入为`user-item`交互矩阵中用户交互过的物品集合，即矩阵的行；物品的输入为`user-item`交互矩阵中使用过物品的用户的集合，即矩阵的列。将物品和用户的输入分别输入`MLP`网络，得到用户和物品的`embedding`向量$\mathbf{p}_u,\mathbf{q}_i$，然后通过用 cosine 点击表示匹配分数
$$
\hat{y}_{ui}=F(u_i,v_j|\Theta)= \cos(\mathbf{p}_u,\mathbf{q}_i) = \frac{\mathbf{p}_u^T\mathbf{q}_i}{||\mathbf{p}_u||||\mathbf{q}_i||}
$$
![DMF模型](../../picture/1/237.png)

##### `AutoRec`模型

`AutoRec`模型的用户输入为`user-item`交互矩阵中用户交互过的物品集合，即矩阵的行；物品的输入为`user-item`交互矩阵中使用过物品的用户的集合，即矩阵的列。

用$r_u$表示用户向量，$r_i$表示物品向量，通过`AutoEncoder`将$r_u$或者$r_i$投射到低维向量空间，然后再将其投射到正常空间，利用`AutoEncoder`中目标值和输入值相近的特性，从而重建出用户对于未交互过的物品的打分。损失函数为最小化预测的平方差以及$W$和$V$矩阵的$L_2$正则：
$$
\min_{\theta}\sum_{i=1}^{n}||\mathbf{r}^{(i)}-h(\mathbf{r}^{(i)};\theta)||_{\mathcal{O}}^2+\frac{\lambda}{2}(||W||_F^2+||V||_F^2)
$$
其中$||\cdot||_{\mathcal{O}}^2$表示只对观测到的数据去损失函数，即在评分矩阵中，没有打分的部分不管他，只让模型去拟合已有的打分部分，让这一部分充分拟合好，然后对于没有数据的部分，训练好的权重会给出一个非零值，这就是模型预测的结果。

![](../../picture/1/242.png)

##### `CDAE`模型

`CDAE`的输入为用户的`userid`的`one-hot`编码和用户交互过的物品集合，即`user-item`交互矩阵中的行，对于用户$u$学习一个与物品无关的$\mathbf{v}_u$表示，可以认为是用户本身的bias，隐藏层为$\mathbf{z}_u=h(\mathbf{W}^T\mathbf{y}_u+\mathbf{v}_u+b)$，输出层为$\hat{y}_{ui}=f(\mathbf{W}_i^{\prime T}\mathbf{z}_u+b_i^{\prime})$。使用向量点积作为匹配分数：$\hat{y}_{ui}=\mathbf{W}_i^{\prime T}\mathbf{v}_u$

![](../../picture/1/243.png)

总结：用户或者物品要么由本身id表达，要么由其历史交互过的行为来表达；用历史交互过的行为来作为user或者item的表达，比用id本身表达效果更好，但模型也变得更复杂； Auto-encoder本质上等同于MLP+MF，MLP用全连接网络做user和item的特征表达； 所有训练数据仅用到user-item的交互信息，完全没有引入user和item的side info信息

#### 基于匹配方法学习的模型

基于match function learning最大的特点是，不直接学习user和item的embedding，而是通过已有的各种输入，通过一个neural network框架，来直接拟合user和item的匹配分数

![](../../picture/1/238.png)

##### 基于`NCF`框架的方法

基于神经网络的学习方法对比传统的 CF 网络，在得到 user vector 和 item vector 后，连接了 MLP 网络后，最终拟合输出，得到一个 end-2-end 的 model。这套框架好处就是足够灵活，user 和 item 侧的双塔设计可以加入任意 side info 的特征，而 MLP 网络也可以灵活的设计。

![](../../picture/1/239.png)

##### `NeuMF`模型 Neural Matrix Factorization

利用了 MF 和神经网络 MLP 的能力来拟合 matching score；MF 利用向量内积学习 user 和 item 的关联，同时 MLP 部分捕捉两者的其他高阶信息。模型可以分为 GMF 和 MLP 两个部分来看

![](../../picture/1/248.png)

###### `GMF`部分

user和item都通过one-hot编码得到稀疏的输入向量，然后通过一个embedding层映射为user vector和item vector。这样就获得了user和item的隐向量，一般可以通过向量点积或者哈达马积得到交互，不过在NeuMF中多连接了一个连接层，也就是GMF layer
$$
\hat{y}_{ui} = \alpha_{o}(\mathbf{h}^T(\mathbf{p}_u \odot\mathbf{q}_i))
$$

###### MLP部分

输入和GMF部分一样，都是one-hot的稀疏编码，然后通过embedding层映射为user vector和item vector。注意到这里user和item的vector 和GMF部分是不一样的，原因是GMF和MLP两个网络结构对隐层维度要求不同，MLP部分会高一些
$$
\mathbf{z}_1 = \phi_1(\mathbf{p}_u,\mathbf{q}_i)=\left[\begin{array}{c} \mathbf{p}_u\\\mathbf{q}_i\end{array}\right]\\
\phi_2(\mathbf{z}_1) = a_2(\mathbf{W}_2^T\mathbf{z}_1+\mathbf{b}_2)\\
\cdot\\
\cdot\\
\hat{y}_{ui} = \sigma(\mathbf{h}^T\phi_L(\mathbf{z}_{L-1}))
$$

##### `NNCF`模型 Neighbor-based NCF

输入除了user和item的信息，还各自引入了user和item各自的neighbor信息。

##### `ONCF`模型 Outer-Product based NCF

基于NCF框架的方法基础原理是基于协同过滤，而协同过滤本质上又是在做user和item的矩阵分解，所以，基于NCF框架的方法本质上也是基于MF的方法。矩阵分解本质是尽可能将user和item的vector，通过各种方法去让user和item在映射后的空间中的向量尽可能接近

而另外一种思路，基于翻译的方法，也叫translation based model，认为user和item在新的空间中映射的vector可以有gap，这个gap用relation vector来表达，也就是让用户的向量加上relation vector的向量，尽可能和item vector接近。

![](../../picture/1/342.png)

##### `transRec`模型

要解决的是next item的推荐问题。基本思想是说用户本身的向量，加上用户上一个交互的item的向量，应该接近于用户下一个交互的item的向量，输入是(user, prev item, next item)，预测下个item被推荐的概率

##### `LRML`模型 Latent Relation Metric Learning

![](../../picture/1/343.png)

协同过滤只依赖于过去的用户行为，从最传统的基于邻近的方法，推进到基于矩阵分解的协同过滤。然后进入深度学习时代，协同过滤与深度学习紧密的结合，提高了传统的协同过滤模型的特征交叉能力，通过特征非线性的组合来优化模型。但是基于深度学习的协同过滤模型的基本原理还是经典的协同过滤的思路。