### 基于深度学习的协同过滤方法

#### 基于表示学习的模型

分别学习用户的表示以及物品的表示，也就是用户和物品各自的 embedding 向量，然后通过定义 matching score 的函数，一般是简单的向量点击、或者 cosine 距离来得到两者的匹配分数。

![](../../picture/1/235.png)

##### `CF`模型

`CF`模型用户和物品的输入分别是`userid`, `itemid`的`one-hot`编码，分别学习用户和物品的`embedding`向量$\mathbf{p}_u,\mathbf{q}_i$，然后通过向量内积得到$\hat{y}_{ui}=(u,i|\mathbf{p}_u,\mathbf{q}_i)=\mathbf{p}_u^T\mathbf{q}_i$

![CF模型](../../picture/1/236.png)

##### `DMF`模型

`DMF`模型的用户输入为`user-item`交互矩阵中用户交互过的物品集合，即矩阵的行；物品的输入为`user-item`交互矩阵中使用过物品的用户的集合，即矩阵的列。将物品和用户的输入分别输入`MLP`网络，得到用户和物品的`embedding`向量$\mathbf{p}_u,\mathbf{q}_i$，然后通过用 cosine 点击表示匹配分数
$$
\hat{y}_{ui}=F(u_i,v_j|\Theta)= \cos(\mathbf{p}_u,\mathbf{q}_i) = \frac{\mathbf{p}_u^T\mathbf{q}_i}{||\mathbf{p}_u||||\mathbf{q}_i||}
$$
![DMF模型](../../picture/1/237.png)

##### `AutoRec`模型

`AutoRec`模型的用户输入为`user-item`交互矩阵中用户交互过的物品集合，即矩阵的行；物品的输入为`user-item`交互矩阵中使用过物品的用户的集合，即矩阵的列。

用$r_u$表示用户向量，$r_i$表示物品向量，通过`AutoEncoder`将$r_u$或者$r_i$投射到低维向量空间，然后再将其投射到正常空间，利用`AutoEncoder`中目标值和输入值相近的特性，从而重建出用户对于未交互过的物品的打分。损失函数为最小化预测的平方差以及$W$和$V$矩阵的$L_2$正则：
$$
\min_{\theta}\sum_{i=1}^{n}||\mathbf{r}^{(i)}-h(\mathbf{r}^{(i)};\theta)||_{\mathcal{O}}^2+\frac{\lambda}{2}(||W||_F^2+||V||_F^2)
$$
其中$||\cdot||_{\mathcal{O}}^2$表示只对观测到的数据去损失函数，即在评分矩阵中，没有打分的部分不管他，只让模型去拟合已有的打分部分，让这一部分充分拟合好，然后对于没有数据的部分，训练好的权重会给出一个非零值，这就是模型预测的结果。

![](../../picture/1/242.png)

##### `CDAE`模型

`CDAE`的输入为用户的`userid`的`one-hot`编码和用户交互过的物品集合，即`user-item`交互矩阵中的行，对于用户$u$学习一个与物品无关的$\mathbf{v}_u$表示，可以认为是用户本身的bias，隐藏层为$\mathbf{z}_u=h(\mathbf{W}^T\mathbf{y}_u+\mathbf{v}_u+b)$，输出层为$\hat{y}_{ui}=f(\mathbf{W}_i^{\prime T}\mathbf{z}_u+b_i^{\prime})$。使用向量点积作为匹配分数：$\hat{y}_{ui}=\mathbf{W}_i^{\prime T}\mathbf{v}_u$

![](../../picture/1/243.png)

总结：用户或者物品要么由本身id表达，要么由其历史交互过的行为来表达；用历史交互过的行为来作为user或者item的表达，比用id本身表达效果更好，但模型也变得更复杂； Auto-encoder本质上等同于MLP+MF，MLP用全连接网络做user和item的特征表达； 所有训练数据仅用到user-item的交互信息，完全没有引入user和item的side info信息

#### 基于匹配方法学习的模型

基于match function learning最大的特点是，不直接学习user和item的embedding，而是通过已有的各种输入，通过一个neural network框架，来直接拟合user和item的匹配分数

![](../../picture/1/238.png)

##### 基于`NCF`框架的方法

基于神经网络的学习方法对比传统的 CF 网络，在得到 user vector 和 item vector 后，连接了 MLP 网络后，最终拟合输出，得到一个 end-2-end 的 model。这套框架好处就是足够灵活，user 和 item 侧的双塔设计可以加入任意 side info 的特征，而 MLP 网络也可以灵活的设计。

![](../../picture/1/239.png)

##### `NeuMF`模型 Neural Matrix Factorization

利用了 MF 和神经网络 MLP 的能力来拟合 matching score；MF 利用向量内积学习 user 和 item 的关联，同时 MLP 部分捕捉两者的其他高阶信息。模型可以分为 GMF 和 MLP 两个部分来看

![](../../picture/1/248.png)

###### `GMF`部分

user和item都通过one-hot编码得到稀疏的输入向量，然后通过一个embedding层映射为user vector和item vector。这样就获得了user和item的隐向量，一般可以通过向量点积或者哈达马积得到交互，不过在NeuMF中多连接了一个连接层，也就是GMF layer
$$
\hat{y}_{ui} = \alpha_{o}(\mathbf{h}^T(\mathbf{p}_u \odot\mathbf{q}_i))
$$

###### MLP部分

输入和GMF部分一样，都是one-hot的稀疏编码，然后通过embedding层映射为user vector和item vector。注意到这里user和item的vector 和GMF部分是不一样的，原因是GMF和MLP两个网络结构对隐层维度要求不同，MLP部分会高一些
$$
\mathbf{z}_1 = \phi_1(\mathbf{p}_u,\mathbf{q}_i)=\left[\begin{array}{c} \mathbf{p}_u\\\mathbf{q}_i\end{array}\right]\\
\phi_2(\mathbf{z}_1) = a_2(\mathbf{W}_2^T\mathbf{z}_1+\mathbf{b}_2)\\
\cdot\\
\cdot\\
\hat{y}_{ui} = \sigma(\mathbf{h}^T\phi_L(\mathbf{z}_{L-1}))
$$

##### `NNCF`模型 Neighbor-based NCF

输入除了user和item的信息，还各自引入了user和item各自的neighbor信息。

##### `ONCF`模型 Outer-Product based NCF

基于NCF框架的方法基础原理是基于协同过滤，而协同过滤本质上又是在做user和item的矩阵分解，所以，基于NCF框架的方法本质上也是基于MF的方法。矩阵分解本质是尽可能将user和item的vector，通过各种方法去让user和item在映射后的空间中的向量尽可能接近

而另外一种思路，基于翻译的方法，也叫translation based model，认为user和item在新的空间中映射的vector可以有gap，这个gap用relation vector来表达，也就是让用户的向量加上relation vector的向量，尽可能和item vector接近。

![](../../picture/1/342.png)

##### `transRec`模型

要解决的是next item的推荐问题。基本思想是说用户本身的向量，加上用户上一个交互的item的向量，应该接近于用户下一个交互的item的向量，输入是(user, prev item, next item)，预测下个item被推荐的概率

##### `LRML`模型 Latent Relation Metric Learning

![](../../picture/1/343.png)

协同过滤只依赖于过去的用户行为，从最传统的基于邻近的方法，推进到基于矩阵分解的协同过滤。然后进入深度学习时代，协同过滤与深度学习紧密的结合，提高了传统的协同过滤模型的特征交叉能力，通过特征非线性的组合来优化模型。但是基于深度学习的协同过滤模型的基本原理还是经典的协同过滤的思路。



典型的有：选择偏差、位置偏差、曝光偏差和流行度偏差等。

从用户处收集数据，包括用户和商品的交互以及其它的side信息，我们将收集到的交互表示为用户集合$U=\{u_1,u_2,\cdots,u_n\}$商品集合$I=\{i_1,i_2,\cdots,i_m\}$的反馈矩阵，一般会有两种不同的用户反馈。隐式反馈：$X\in\mathcal{R}^{n\times m}$其中$x_{ui}$表示用户$u$是否和商品$i$有交互，如果有交互则为1，否则为0；显式反馈：$R\in\mathcal{R}^{n\times m}$其中$r_{ui}$表示用户$u$给商品$i$打的分。

##### 数据中的`Bias`

| 类型       | 说明                                                         | 案例                                                         |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 选择偏差   | 当用户可以自由选择要评分的项目时，会出现选择偏差，因此观察到的评分并不是所有评分的代表性样本。换言之，评级数据往往是不随机缺失的 | 在rating数据集上面, 用户并非是随机打分的，用户会选择它们喜欢的商品进行打分；用户更倾向于给特别好的商品和坏的商品打分; |
| 一致性偏差 | 一致性偏差发生在用户倾向于与组中其他人的评分相似时，即使这样做违背了他们自己的判断，使得评分值并不总是表示用户真正的偏好。 | 一个用户会受到诸多其它人的评分的影响,如果很多其他人都打了高分,他可能会改变自己的评分,避免过于严厉。这个问题主要是由于用户受社会影响导致，一个用户往往会受到他朋友的影响。所以我们观测到的评分是有偏的,有些是没法反映真实用户的喜好。 |
| 曝光偏差   | 暴露偏差的发生是因为用户只接触到特定项目的一部分，因此未观察到的交互并不总是代表消极偏好。 | 用户和商品之间未被观察到的交互由于两大原因：商品与用户兴趣不匹配；用户不知道该商品。无法区分真正的消极互动和潜在的积极互动将导致严重的Bias。 |
| 位置偏差   | 位置偏差是因为用户倾向于与位于推荐列表中较高位置的商品进行交互，而不管这些商品的实际相关性如何，因此交互的商品可能不是高度相关的; | 它描述了一种用户倾向于以更高的概率注意到列表中某些位置上的商品或与之交互，而不管这些项目的实际相关性。 |







##### 模型中的`Bias`

| 分类     | 说明                                                         | 案例 |
| -------- | ------------------------------------------------------------ | ---- |
| 归纳偏置 | 归纳偏差是指模型为了更好地学习目标函数并将其推广到训练数据之外而做出的假设。 |      |

##### 结果的`Bias`和`Unfairness`

| 分类       | 说明                                                         | 案例                                                         |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 流行度偏差 | 热门商品的推荐频率甚至超过了它们的受欢迎程度.                | 在大多数情况下，一小部分受欢迎的商品占了大多数用户交互的比例。当对这些长尾数据进行训练时，该模型通常会给热门项目的评分高于其理想值，而只是简单地将不受欢迎的商品预测为负值。因此，推荐热门商品的频率甚至比数据集中显示的原始受欢迎程度还要高。 |
| 不平衡     | 系统地、不公平地歧视某些个人或个人群体而偏袒其他人是不公平的。 | 基于诸如种族、性别、年龄、教育程度或财富等属性，不同的用户群体通常在数据中不平等地表示。在对这些不平衡数据进行训练时，模型很可能学习这些表示性过高的群体，在排名结果中对其进行强化，并可能导致系统性歧视，降低弱势群体的可见度 |

忽略流行度经常会带来非常多的问题:(1).降低个性化的程度影响,影响用户的体验; (2).降低了推荐系统的公平性, 流行的商品却不一定是高质量的, 对流行商品的推荐会降低其它商品的曝光,这是不公平的; (3).Popular Bias会增加流行商品的曝光率, 使得流行的商品越加流行，使模型训练更加不平衡;

##### 评估`Debiasing`

前处理Selection Bias的方法主要有：

1. Propensity scores: 将推荐视为类似于用特定药物治疗患者的干预措施。在这两个任务中，我们只知道某些患者(User)从某些治疗(Item)中获益的程度，而大多数患者治疗(user-item)的结果却不被观察到。对于这两个任务，一个很有效的策略是用相反的倾向分数加权(inverse propensity scores)观察结果。
2. ATOP:Steck等人提出的无偏的metricATOP来评估推荐性能，它有两个假设:(1).相关(高)ratings值在观察数据中随机缺失;(2)对于其他rating值，我们允许任意缺失数据机制，只要它们以高于相关rating值的概率丢失。

模型训练的`Debiasing`

1. Data imputation：同时考虑rating预测任务以及缺失数据预测任务;因为联合训练缺失数据模型以及rating模型会导致非常复杂的方案。所以目前非常多的工作采用启发式的优化方案,例如直接对缺失值填充等,然而，由于缺失数据模型或rating预估值是以启发式方式指定的，这类方法会因缺失数据模型的指定不当或估算的评级值不准确而出现经验误差。
2. Propensity score:另一种方法在训练推荐模型时，利用Propensity score来减轻选择偏差，它们直接以基于IPS的无偏估计量为目标并优化特定的loss。但是,制定准确的Propensity score是非常严格的，基于IPS的模型的性能依赖于propensities的准确性。此外, 基于Propensity score的方法会受到高方差的影响,最终导致非最有的结果。
3. Doubly rost model:将上述的两种方案通过某种方式结合, 使其具有期望的双重鲁棒性.尽管此类方法比单个模型更加鲁棒,但是它也需要准确的propensity score或者imputation数据。
4. Meta Learning：解决上述方法高度依赖propensity和imputation，Saito等人提出了meta-learning的方案，但是这种方法依赖于预训练的predictor的质量,所以学习到满意的程度依然是非常具有挑战性。

目前解决一致性偏差的方案主要有两类：

- 第一类认为用户的rating是符合公众意见;
- 将用户的评分只作为用户喜好和social影响的综合结果。很多工作直接利用base推荐模型的social因子来生成最终的预测结果,与此同时,引入特定的参数来控制一致性偏差的影响。

曝光偏差会误导模型的训练和评估；

1. 评估的Debiasing

目前处理该问题的策略主要还是使用inverse propersity score。为了解决这个问题，类似于外显反馈数据中的选择偏差处理，Yang等人建议用隐式反馈数据倾向的倒数来加权每个观测值。intuition是把经常观察到的交互降权，而对少的样本进行升权;

2. 模型训练的Debiasing

为了解决曝光偏差的问题，传统的策略就是将所有被观测的交互作为负例并且明确它们的交互。confidence weight可以被分为三类：

**1.Heuristic**：典型的例子是加权的矩阵分解以及动态MF,未观测到的交互被赋予较低的权重。还有很多工作则基于用户的活跃度指定置信度等;但是赋予准确的置信权重是非常有挑战的,所以这块依然处理的不是非常好。

**2.Sampling**: 另一种解决曝光bias的方式就是采样,经常采用的采样策略有均匀的负采样,对于流行的负样本过采样,但是这些策略却较难捕捉到真实的负样本。

**3.Exposure-based model**:另外一个策略是开发基于曝光的模型,这样可以知道一个商品被曝光到某个用户的可能性等。

**4.Others**:例如考虑用户的序列行为等,对应的设计inverse propensity的模型等。

位置偏差表明，无论相关性如何，排名较高的项目更有可能被选中

1. 点击模型

目前有很多模型将position bias直接建模到模型中，在预测的时候则忽略这块分支。当然策略还有很多。不过大多数模型模型通常需要为每个查询项或用户项对进行大量的点击，这使得它们很难应用于点击数据高度稀疏的系统中。

2. Propensity score

采用inverse propensity score来纠正position bias。

解决流行度偏差的方案有四类：

1.正则

合适的正则可以将模型推向平衡的推荐列表。

2. 对抗训练

基本思路在推荐G以及引入的adversary D进行min-max博弈，这样D可以给出提升推荐锡惠的信号。通过G和D之间的对抗学习，D学习流行项和利基项之间的隐式关联，G学习捕捉更多与用户历史相关的niche商品，从而为用户推荐更多长尾商品。

3. Causal graph

因果图是反事实推理的有力工具。Zheng等人利用因果推理解决流行偏差。他们假设用户对商品的点击行为取决于兴趣和流行程度，并构建了一个特定的因果图。为了解决用户兴趣和流行偏差的问题，作者考虑了两种嵌入方法：兴趣嵌入以捕获用户对商品的真实兴趣，以及流行度嵌入来捕获由流行度引起的伪兴趣。在多任务学习的框架下，可以利用特定原因的数据对这些嵌入进行训练。最后，兴趣嵌入将被用于最终推荐，在这里，受欢迎度偏差已经被消除。

4. 其它方法

通过引入其它side information来降低流行度的偏差, propensity score也可以被用来做popularity的bias.通过降低流行项对模型训练的影响，可以减轻流行偏差.