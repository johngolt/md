### 传统匹配模型

#### Generic feature-based的方法

`feature-based` 的模型的特征体系包括三个模块：用户信息、物品信息、交互信息

![](../../picture/1/234.png)

### 基于representation learning

embedding也快速地在其他适用深度学习的领域或任务上（例如推荐系统、广告点击率预估等）流行，用于物品、用户或相关特征的表示。

![](../../picture/2/300.png)

在点击率预估等任务上，一般以特征field的embedding作为神经网络的embedding层输出，对于单值特征，field embedding等于特征的embedding；对于多值特征，field embedding等于多个特征embedding的求和结果。当然，求和是对多值特征embedding的sum pooling操作，在具体应用上，也可以使用mean/max/k-max pooling代替。

![](../../picture/2/301.png)

当前业界通用的深度神经网络模型结构，大抵可以划分为输入层、embedding层、拼接层、若干全连接层和输出层。输入层和embedding层，上文已经有过介绍，输入层是按特征field划分的one-hot（或multi-hot）离散特征向量表示，而图中的embedding层实际包含lookup和pooling两个操作。拼接层是对embedding层输出的m个长度分别为$d_i, i=1,2,\cdots,m$的稠密向量拼成一个长度为$\sum d_i$的稠密向量。拼接后的向量经过若干全连接层后，最终在输出层得到回归值或分类概率值。

经典DNN网络结构具有天然的自动学习交叉特征信息的能力，然而从特征embedding向量拼接和前向全连接的计算特点来看，这种能力更多是限于对隐式元素级（bit-wise）的交叉表示建模上。而经验上，特征间显式的向量级交叉信息（vector-wise）具有更直接的描述特征关系的能力，有助于使模型获得更强的交叉特征信号，降低模型学习难度。

#### 基于协同过滤+side information

| 模型名称   | input layer                                        | representation function                                      |      |
| ---------- | -------------------------------------------------- | ------------------------------------------------------------ | ---- |
| `DCF`模型  | 除了用户和物品的交互矩阵，还有用户特征X和物品特征Y | 引入了用户侧特征X；物品侧特征 Y；user 和 item 侧的特征各自通过一个 auto-encoder 来学习，而交互信息$R$矩阵依然做矩阵分解$U,V$。 |      |
| `DUIF`模型 | 除了用户和物品的交互矩阵，还有用户特征X和物品特征Y |                                                              |      |
|            |                                                    |                                                              |      |

##### `DCF`模型 Deep Collaborative Filtering



![](../../picture/1/244.png)

![](../../picture/1/245.png)

其中$W_1$，表示的用户侧特征$X$在 auto-encoder 过程中的 encode 部分，也就是输入到隐层的重建，$P_1$表示的是用户特征到交互矩阵$R$的映射；而$W_2$表示物品侧特征$Y$在 auto-encoder 过程中的 encode 部分。$P_2$表示的是物品特征到交互矩阵$R$的映射。

##### `DUIF`模型 Deep User and Image Feature Learning

$f_i$表示原始图片特征，通过CNN网络提取的图片特征作为item的表达，然后用一个线性映射$\mathbf{W}$可以得到item的embedding表达，通过模型学到的$\mathbf{p}_u$作为用户的表示，以及通过CNN提取的图片特征作为物品的表示, 两者通过向量点积得到两者的匹配分数
$$
\hat{y}_{ui} = <\mathbf{p}_u,\mathbf{W}^T\text{CNN}(\mathbf{f}_i)>
$$

##### `ACF`模型 Attentive Collaborative Filtering

用户侧：userid；用户历史交互过的 item。Item侧：itemid；item 相关的视觉相关特征。representation function：可以分为两个 attention，一个是 component 层级的 attention，主要是提取视觉特征；第二层是 item 层级的 attention，主要提取用户对物品的喜好程度权重。

![](../../picture/1/246.png)

###### component-attention

###### item-attention

第二层attention，认为用户作用过的item历史中，权重应该是不同的。用户本身的表达引入了$a(i,l)$，代表的是用户$i$对其历史交互过的物品$l$的权重。
$$
a(i,l) = \mathbf{w}_1^T\phi(\mathbf{W}_{1u}\mathbf{u}_i+\mathbf{W}_{1v}\mathbf{v}_l+\mathbf{W}_{1p}\mathbf{p}_l+\mathbf{W}_{1x}\overline{\mathbf{x}}_l+\mathbf{b}_1)+\mathbf{c}_1\\
\alpha(i,l) = \frac{exp(a(i,l))}{\sum_{n\in \mathcal{R}(i)}exp(a(i,n))}
$$
其中$\mathbf{u}_i$是用户本身的latent vector, $\mathbf{v}_l$是物品$l$的latent vector，$\mathbf{p}_l$是物品$l$的辅助latent vector; $\overline{\mathbf{x}}_l$是表示前面提到的从图文信息提取的特征latent vector。用户$\mathbf{u}_i$最终的表达是自身的latent vector，以及历史行为的attention加权的representation表示。

##### `CKB`模型 Collaborative Knowledge Base Embedding

整个CKB模型框架其实思想比较简单，分别在结构化信息、文本信息和视觉信息中提取item侧特征作为item的representation

![](../../picture/1/341.png)

##### 方法总结

总结上述基于 CF 的方法，可以用如下的范式作为表达

![](../../picture/1/247.png)

 representation learning：目的是学习到 user 和 item 各自的 representation。特征表达：user 侧特征除了用户 id 本身 userid，可以加上其他 side info；item 侧特征除了物品 id 本身 itemid，还有其他文本特征、图文特征、视频帧特征等信息。模型表达：除了传统的 DNN，其他结构如 Auto-Encoder，Denoise-Auto-Encoder，CNN，RNN 等。

基于representation learning的深度匹配模型不是一个端到端模型，通过user和item各自的representation作为中间产物，解释性较好，而且可以用在出了排序阶段以外的其他环节，例如求物品最相似的item集合，召回环节等。





