机器学习根据任务类型，可以划分为：

| 任务类型   | 说明                                                         |
| ---------- | ------------------------------------------------------------ |
| 监督学习   | 从已标记的训练数据来训练模型。 主要分为：分类任务、回归任务、序列标注任务。 |
| 无监督学习 | 从未标记的训练数据来训练模型。主要分为：聚类任务、降维任务。 |
| 半监督学习 | 用大量的未标记训练数据和少量的已标记数据来训练模型。         |
| 强化学习   | 从系统与环境的大量交互知识中训练模型。                       |

没有免费的午餐定理：对于一个学习算法`A`，如果在某些问题上它比算法`B`好，那么必然存在另一些问题，在那些问题中`B`比`A`更好。因此要谈论算法的优劣必须基于具体的学习问题。

通常输入实例用 $\vec{\mathbf{x}}$表示，真实标记用$\tilde{y}$表示，模型的预测值用$\hat{y}$表示。所有的向量均为列向量。其中输入实例 $\vec{\mathbf{x}}$的特征向量记作
$$
\vec{\mathbf{x}}=\left[\begin{array}{cccc}x_1\\
 x_2\\
 \cdot\\
 \cdot\\
 x_n\end{array}
 \right]
$$
这里$x_i$为$\vec{\mathbf{x}}$的第$i$个特征的取值。

#### 监督学习

监督学习假设输入$\vec{\mathbf{x}}$与标记$y$遵循联合概率分布 ，训练数据和测试数据依联合概率分布$p(\vec{\mathbf{x}},y)$独立同分布产生。监督学习的模型可以为概率模型或者非概率模型：

- 概率模型由条件概率分布$p(y|\vec{\mathbf{x}})$表示。
- 非概率模型由决策函数$y=f(\vec{\mathbf{x}})$表示。

给定训练集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, y_{1}\right),\left(\vec{\mathbf{x}}_{2}, y_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, y_{N}\right)\right\}$，其中$\vec{\mathbf{x}}_{i}\in \mathcal{X}$为输入值，$y_i\in \mathcal{Y}$是标记值。假设训练数据与测试数据是依据联合概率分布$p(\vec{\mathbf{x}},y)$独立同分布的产生的。

- 学习过程：在给定的训练集$\mathbb{D}$上，通过学习训练得到一个模型。该模型表示为条件概率分布$p(y|\vec{\mathbf{x}})$或者决策函数$y=f(\vec{\mathbf{x}})$
- 预测过程：对给定的测试样本$\vec{\mathbf{x}}_{test}$，给出其预测结果：对于概率模型，其预测值为：$\hat{y}_{test}=\text{argmax}_yp(y|\vec{\mathbf{x}_{test}})$。对于非概率模型，其预测值为：$\hat{y}_{test}=\text{argmax}_yf(\vec{\mathbf{x}}_{test})$ 

##### 生成模型和判别模型

监督学习又分为生成方法和判别方法，生成方法通过数据学习联合概率分布$p(\vec{\mathbf{x}},y)$，然后求出条件概率分布$p(y|\vec{\mathbf{x}})$作为预测的模型。即生成模型为：
$$
p(y|\vec{\mathbf{x}}) = \frac{p(\vec{\mathbf{x}},y)}{p(\vec{\mathbf{x}})}
$$
生成方法的优点：能还原联合概率分布$p(\vec{\mathbf{x}},y)$，收敛速度快，且当存在隐变量时只能用生成方法。生成方法有：朴素贝叶斯法，隐马尔可夫链。

判别方法 ：直接学习决策函数$f(\vec{\mathbf{x}})$或者条件概率分布$p(y|\vec{\mathbf{x}}) $的模型。判别方法的优点：直接预测，一般准确率更高，且一般比较简化问题。判别方法有：逻辑回归，决策树。

#### 机器学习三要素

不同机器学习算法的区别在于模型、学习准则和优化算法的差异。模型定义了解空间。模型的解空间包含了所有可能的条件概率分布或者决策函数，因此解空间中的模型有无穷多个。策略考虑的是按照什么样的准则学习，从而定义优化目标。算法指学习模型的具体计算方法。通常采用数值计算的方法求解，如：梯度下降法。

![](../../picture/1.png)

##### 模型

模型为一个条件概率分布：解空间为条件概率的集合：$\mathcal{F} = \{p|p(y|\vec{\mathbf{x}})\}$。其中： $\vec{\mathbf{x}}\in \mathcal{X}, y\in\mathcal{Y}$为随机变量。通常$\mathcal{F}$是由一个参数向量$\vec{\theta}=(\theta_1,\cdots,\theta_n)$决定的概率分布族：$\mathcal{F} = \{p|p_{\vec{\theta}}(y|\vec{\mathbf{x}}), \vec{\theta}\in \mathbb{R}^n\}$。其中：$p_{\vec{\theta}}$只与$\vec{\theta}$有关，称$\vec{\theta}$为参数空间。

模型为一个决策函数：解空间为决策函数的集合：$\mathcal{F} = \{f|y=f(\vec{\mathbf{x}})\}$。其中： $\vec{\mathbf{x}}\in \mathcal{X}, y\in\mathcal{Y}$为变量。通常$\mathcal{F}$是由一个参数向量$\vec{\theta}=(\theta_1,\cdots,\theta_n)$决定的函数族：$\mathcal{F} = \{y=f_{\vec{\theta}}(\vec{\mathbf{x}}), \vec{\theta}\in \mathbb{R}^n\}$。其中：其中：$f_{\vec{\theta}}$只与$\vec{\theta}$有关，称$\vec{\theta}$为参数空间。

解的表示一旦确定，解空间以及解空间的规模大小就确定了。将学习过程看作一个在解空间中进行搜索的过程，搜索目标就是找到与训练集匹配的解。

##### 策略

对于给定的输入$\vec{\mathbf{x}}$，由模型预测的输出值$\hat{y}$与真实的标记值$\tilde{y}$可能不一致。此时，用损失函数度量错误的程度，记作$L(\tilde{y}, \hat{y})$，也称作代价函数。

| 名称                         | 定义                       |
| ---------------------------- | -------------------------- |
| 损失函数`Loss Function`      | 通常是针对单个训练样本而言 |
| 代价函数`Cost Function`      | 通常是针对整个训练集       |
| 目标函数`Objective Function` | 表示任意希望被优化的函数   |

###### `0-1`损失函数

$$
\mathcal{L}(\tilde{y},\hat{y})=\left\{\begin{array}{ll}{0} & {\text { if } \hat{y}=\tilde{y}} \\ {1} & {\text { if } \hat{y} \neq \tilde{y}}\end{array}\right.
=I(\hat{y} \neq \tilde{y})
$$

###### 平方损失函数`MSE`

`MSE`损失是回归任务中最常用的一种损失函数$\mathcal{L}(\tilde{y},\hat{y})=\frac{1}{2}(\tilde{y}-\hat{y})^{2}$。假设模型预测与真实值之间的误差服从标准高斯分布，则给定一个$\vec{\mathbf{x}}_i$模型输出真实值$\tilde{y}$的概率为
$$
P(y_i|\vec{\mathbf{x}}_i)=\frac{1}{\sqrt{2\pi}}\exp(-\frac{(\tilde{y}-\hat{y})^2}{2})
$$
给定所有$\vec{\mathbf{x}}$输出所有真实值$\tilde{y}$的概率，即似然函数为
$$
L(\vec{\mathbf{x}},\tilde{y})=\prod_{i=1}^N\frac{1}{\sqrt{2\pi}}\exp(-\frac{(\tilde{y}-\hat{y})^2}{2})\\
LL(\vec{\mathbf{x}},\tilde{y}) = \log(L(\vec{\mathbf{x}},y))=-\frac{N}{2}\log2\pi-\frac{1}{2}\sum_{i=1}^N(\tilde{y}-\hat{y})^2
$$
去掉与$\hat{y}_i$无关的第一项，然后转化为最小化负对数似然
$$
NLL(\vec{\mathbf{x}},y) = \frac{1}{2}\sum_{i=1}^N(\tilde{y}-\hat{y})^2
$$
在模型输出与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的。

###### 平均绝对误差损失

平均绝对误差`MAE`是另一类常用的损失函数$\mathcal{L}(\tilde{y}, \hat{y}) = |\tilde{y}-\hat{y}|$。假设模型预测与真实值之间的误差服从拉普拉斯分布，则给定一个$\vec{\mathbf{x}}_i$模型输出真实值$\tilde{y}_i$的概率为
$$
P(y_i|\vec{\mathbf{x}}_i) = \frac{1}{2}\exp(-|\tilde{y}-\hat{y}|)
$$
可以得到的负对数似然实际上就是`MAE`损失的形式
$$
L(\vec{\mathbf{x}},y)=\prod_{i=1}^N\frac{1}{2}\exp(-|y_i-\hat{y}_i|)\\
LL(\vec{\mathbf{x}},y) = \log(L(\vec{\mathbf{x}},y))=-\frac{N}{2}-\sum_{i=1}^N|y_i-\hat{y}_i|\\

NLL(\vec{\mathbf{x}},y)= \sum_{i=1}^N|y_i-\hat{y}_i|
$$
`MSE`损失相比`MAE`通常可以更快地收敛，但`MAE`损失对于异常点更加健壮，即更加不易受到`outlier`影响。

###### `Huber Loss`

$$
L_{\delta}(\tilde{y},\hat{y})=\left\{\begin{array}{ll}{\frac{1}{2}(\tilde{y}-\hat{y})^2} & {\text { if } |\tilde{y}-\hat{y}| \le \delta} \\ {\delta|\tilde{y}-\hat{y}|-\frac{1}{2}\delta^2} & {\text { else }}\end{array}\right.
$$

上式中$\delta$是`Huber Loss`的一个超参数。`Huber Loss`结合了`MSE`和`MAE`损失，在误差接近0时使用`MSE`，使损失函数可导并且梯度更加稳定；在误差较大时使用`MAE`可以降低`outlier`的影响，使训练对`outlier`更加健壮。缺点是需要额外地设置一个$\delta$超参数。

###### 分位数损失

分位数回归是通过使用分位数损失来实现这一点的，分位数损失形式如下，式中的$r$分位数系数。
$$
L_{r}(\tilde{y},\hat{y})=\left\{\begin{array}{ll}{(1-r)|\tilde{y}-\hat{y}|} & {\hat{y}\ge \tilde{y}} \\ {r|\tilde{y}-\hat{y}|} & {\hat{y}<\tilde{y}}\end{array}\right.
$$
分位数损失实现了分别用不同的系数控制高估$\hat{y}\ge \tilde{y}$和低估$\hat{y}<\tilde{y}$的损失，进而实现分位数回归。

| 指标                          | 公式                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| 均方根误差`RMSE`              | $ \sqrt{\frac{1}{N}\sum_{i=1}^N(y_i-\hat{y}_i)^2}$           |
| 均方根对数误差`RMLSE`         | $\sqrt{\frac{1}{N}\sum_{i=1}^N(\log(y_i+1)-\log(\hat{y}_i+1))^2}$ |
| 平均绝对百分比误差`MAPE`      | $\frac{100%}{n}\sum_i|\frac{\hat{y_i}-y_i}{y_i}|$            |
| 对称平均绝对百分比误差`SMAPE` | $\frac{100%}{n}\sum_i\frac{|\hat{y_i}-y_i|}{(|{\hat{y_i}}|+|y|)/2}$ |

当真实值的分布范围比较广时，如果使用`MAE、MSE、RMSE` 等误差，这将使得模型更关注于那些真实标签值较大的样本。而`RMSLE` 关注的是预测误差的比例，使得真实标签值较小的样本也同等重要;当数据中存在标签较大的异常值时，`RMSLE` 能够降低这些异常值的影响。

###### 交叉熵损失

假设样本的标签$y ∈ \{1, · · · C\}$为离散的类别，模型$f(x, θ) ∈ [0, 1]^C$ 的输出为类别标签的条件概率分布，即：$p(y=c | \mathbf{x}, \theta)=f_{c}(\mathbf{x}, \theta)$。并满足：$f_{c}(\mathbf{x}, \theta) \in[0,1], \quad \sum_{c=1}^{C} f_{c}(\mathbf{x}, \theta)=1$。标签的真实分布$y$和模型预测分布$f(\mathbf{x}, θ)$之间的交叉熵为：
$$
\mathcal{L}(\mathbf{y}, f(\mathbf{x}, \theta))=-\sum_{c=1}^{C} y_{c} \log f_{c}(\mathbf{x}, \theta)
$$
在二分类中使用` Sigmoid `函数将模型的输出压缩到$(0,1)$区间内$\hat{y}\in (0,1)$，用来代表给定输入$\vec{\mathbf{x}}$，模型判断为正类的概率。由于只有正负两类，因此同时也得到了负类的概率。
$$
p(y_i=1|\vec{\mathbf{x}}_i) = \hat{y}_i\\
p(y_i|\vec{\mathbf{x}}_i) = (\hat{y}_i)^{y_i}(1-\hat{y}_i)^{1-y_i}
$$
假设数据点之间独立同分布,可以得到的负对数似然即为交叉熵损失函数的形式
$$
L(\vec{\mathbf{x}},y)=\prod_{i=1}^N(\hat{y}_i)^{y_i}(1-\hat{y}_i)^{1-y_i}\\
LL(\vec{\mathbf{x}},y) = \sum_{i=1}^N[y_i\log(\hat{y}_i)+(1-y_i)\log(1-\hat{y}_i)]\\
NLL(\vec{\mathbf{x}},y)= -\sum_{i=1}^N[y_i\log(\hat{y}_i)+(1-y_i)\log(1-\hat{y}_i)]
$$
`Softmax `函数将每个维度的输出范围都限定在$(0,1)$之间，同时所有维度的输出和为1，用于表示一个概率分布。
$$
p(y_i|\vec{\mathbf{x}}_i) = \prod_{k=1}^K(\hat{y}^k_i)^{y^k_i}
$$
同样的假设数据点之间独立同分布，可得到负对数似然为
$$
NLL(\vec{\mathbf{x}},y) = -\sum_{i=1}^N\sum_{k=1}^Ky_i^k\log(\hat{y}^k_i)
$$
由于$y_i$是一个 one-hot 向量，除了目标类为1之外其他类别上的输出都为0，因此上式也可以写为
$$
NLL(\vec{\mathbf{x}},y) =-\sum_{i=1}^N y_i^{c_i}\log(\hat{y}^{c_i}_i)
$$
其中$c_i$是样本$\vec{\mathbf{x}}_i$的目标类。

给定分布$p$和分布$q$， 两者的 KL 散度公式
$$
KL(p,q) = \sum_{k=1}^Kp^k\log p^k-\sum_{k=1}^Kp^k\log q_k
$$
假设对于样本$\vec{\mathbf{x}}_i$存在一个最优分布$y_i^*$真实地表明了这个样本属于各个类别的概率，那么我们希望模型的输出$\hat{y}_i$尽可能地逼近这个最优分布
$$
KL(y^*_i\hat{y}_i) = \sum_{k=1}^Ky^{*k}_i\log y_i^{*k} -\sum_{k=1}^Ky^{*k}_i\log \hat{y}_i^k
$$
由于我们希望两个分布尽量相近，因此我们最小化 KL 散度。同时由于上式第一项信息熵仅与最优分布本身相关，因此我们在最小化的过程中可以忽略掉，变成最小化
$$
-\sum_{k=1}^Ky^{*k}_i\log \hat{y}_i^k
$$
我们并不知道最优分布$y^*_i$，但训练数据里面的目标值$y$可以看做是$y_i^*$的一个近似分布
$$
-\sum_{k=1}^Ky^{k}_i\log \hat{y}_i^k
$$
通过最小化交叉熵的角度推导出来的结果和使用最大化似然得到的结果是一致的

###### `Hinge Loss`

合页损失` Hinge Loss `是另外一种二分类损失函数，适用于`maximum-margin`的分类
$$
\begin{aligned} \mathcal{L}(y, f(x, \theta)) &=\max (0,1-y f(x, \theta)) \\ & \triangleq[1-y f(x, \theta)]_{+} \end{aligned}
$$
合页损失不仅惩罚预测错的，并且对于预测对了但是置信度不高的也会给一个惩罚，只有置信度高的才会有零损失。使用合页损失直觉上理解是要找到一个决策边界，使得所有数据点被这个边界正确地、高置信地被分类。

###### 指数损失函数

$$
L(y, f(x, \theta))=\frac{1}{n}\sum_{i=1}^n \exp[-y_if(x_i)]
$$

通常损失函数值越小，模型就越好。但是由于模型的输入、标记都是随机变量，遵从联合分布$p(\vec{\mathbf{x}},y)$， 因此定义风险函数为损失函数的期望：
$$
\begin{equation}R_{e x p}=\mathbb{E}_{P}[L(\tilde{y}, \hat{y})]=\int_{\mathcal{X} \times \mathcal{Y}} L(\tilde{y}, \hat{y}) p(\overrightarrow{\mathbf{x}}, y) d \overrightarrow{\mathbf{x}} d y\end{equation}
$$

###### 经验风险

给定一个训练集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, y_{1}\right),\left(\vec{\mathbf{x}}_{2}, y_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, y_{N}\right)\right\}$，模型关于$\mathbb{D}$的经验风险定义为：
$$
\mathcal{R}_{\mathcal{D}}^{e m p}(\theta)=\frac{1}{N} \sum_{n=1}^{N} \mathcal{L}(\tilde{y}_i,\hat{y}_i)
$$
经验风险最小化策略认为：经验风险最小的模型就是最优的模型。即：
$$
\min_{f\in \mathcal{F}}\frac{1}{N} \sum_{n=1}^{N} \mathcal{L}(\tilde{y}_i,f(\vec{\mathbf{x}}_i))
$$
结构风险是在经验风险上叠加表示模型复杂度的正则化。它是为了防止过拟合而提出的。给定一个训练集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, y_{1}\right),\left(\vec{\mathbf{x}}_{2}, y_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, y_{N}\right)\right\}$，模型关于$\mathbb{D}$的结构风险定义为：
$$
\begin{aligned} R_{\text{srm}}=\frac{1}{N} \sum_{n=1}^{N} \mathcal{L}(\tilde{y}_i,\hat{y}_i)+\lambda\mathcal{J}(f) \end{aligned}
$$
其中$\mathcal{J}(f)$用来减少参数空间，避免过拟合；$λ$用来控制正则化的强度。结构风险最小化策略认为：结构风险最小的模型是最优的模型。即：
$$
\min_{f\in \mathcal{F}}\frac{1}{N} \sum_{n=1}^{N} \mathcal{L}(\tilde{y}_i,f(\vec{\mathbf{x}}_i))+\lambda\mathcal{J}(f)
$$
极大似然估计就是经验风险最小化的例子。已知训练集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}$，则出现这种训练集的概率为：$\prod_{i=1}^N{p(\tilde{y}_i|\vec{\mathbf{x}_i})}$。根据$\mathbb{D}$出现概率最大，有：
$$
\begin{equation}\max \prod_{i=1}^{N} p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right) \rightarrow \max \sum_{i=1}^{N} \log p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right) \rightarrow \min \sum_{i=1}^{N}\left(-\log p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right)\right)\end{equation}
$$
定义损失函数为：$L(\tilde{y}, \hat{y})=-\log{p(\tilde{y}|\vec{\mathbf{x}})}$，则有：
$$
\begin{equation}\min \sum_{i=1}^{N}\left(-\log p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right)\right) \rightarrow \min \sum_{i=1}^{N} L\left(\tilde{y}_{i}, \hat{y}_{i}\right) \rightarrow \min \frac{1}{N} \sum_{i=1}^{N} L\left(\tilde{y}_{i}, \hat{y}_{i}\right)\end{equation}
$$
即：极大似然估计 = 经验风险最小化 。

最大后验估计就是结构风险最小化的例子。已知训练集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}$，假设已知参数$\theta$的先验分布为$g(\theta)$，则出现这种训练集的概率为：$\prod_{i=1}^N{p(\tilde{y}_i|\vec{\mathbf{x}_i})}g(\theta)$。

根据$\mathbb{D}$出现概率最大：
$$
\begin{equation}\begin{array}{l}
\max \prod_{i=1}^{N} p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right) g(\theta) \rightarrow \max \sum_{i=1}^{N} \log p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right)+\log g(\theta) \\
\quad \rightarrow \min \sum_{i=1}^{N}\left(-\log p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right)\right)+\log \frac{1}{g(\theta)}
\end{array}\end{equation}
$$
定义损失函数为：$L(\tilde{y}, \hat{y})=-\log{p(\tilde{y}|\vec{\mathbf{x}})}$；定义模型复杂度为$J(f)=\log{\frac{1}{g(\theta)}}$；定义正则化系数为$\lambda=\frac{1}{N}$。则有：
$$
\begin{equation}\begin{array}{c}
\min \sum_{i=1}^{N}\left(-\log p\left(\tilde{y}_{i} | \overrightarrow{\mathbf{x}}_{i}\right)\right)+\log \frac{1}{g(\theta)} \rightarrow \min \sum_{i=1}^{N} L\left(\tilde{y}_{i}, \hat{y}_{i}\right)+J(f) \\
\rightarrow \min \frac{1}{N} \sum_{i=1}^{N} L\left(\tilde{y}_{i}, \hat{y}_{i}\right)+\lambda J(f)
\end{array}\end{equation}
$$
即：最大后验估计 = 结构风险最小化。

##### 优化算法

在确定了训练集 $D$、假设空间$ F$ 以及学习准则后，如何找到最优的模型$f(\mathbf{x}, θ^∗)$就成了一个最优问题。机器学习的训练过程其实就是最优化问题的求解过程。**参数与超参数**在机器学习中，优化又可以分为参数优化和超参数优化。模型$f(\mathbf{x}, θ)$中的$θ$ 称为模型的参数，可以通过优化算法进行学习。除了可学习的参数$θ$之外，还有一类参数是用来定义模型结构或优化策略的，这类参数叫做超参数。

梯度下降算法：$\theta_{t+1}=\theta_{t}-\alpha \frac{\partial \mathcal{R}_{\mathcal{D}}(\theta)}{\partial \theta}
=\theta_{t}-\alpha \cdot \frac{1}{N} \sum_{n=1}^{N} \frac{\partial \mathcal{L}\left(y^{(n)}, f\left(\mathbf{x}^{(n)}, \theta\right)\right)}{\partial \theta}$

$\text{Stochastic Gradient Descent}$：$\theta \leftarrow \theta-\alpha \frac{\partial \mathcal{L}\left(\theta ; x^{(n)}, y^{(n)}\right)}{\partial \theta}$

$\text{Mini-Batch Gradient Descent}$：$\theta_{t+1} \leftarrow \theta_{t}-\alpha \cdot \frac{1}{K} \sum_{(\mathbf{x}, y) \in \mathcal{I}_{t}} \frac{\partial \mathcal{L}(y, f(\mathbf{x}, \theta))}{\partial \theta}$

坐标下降法：一个可微的凸函数$J(θ)$, 其中$θ$是$n \times1$的向量。如果在某一点$\overline{\theta}$，使得$J(θ)$在每一个坐标轴$\overline{\theta}_i(i = 1,2,...n)$上都是最小值，那么$J(\overline{\theta})$就是一个全局的最小值。

首先，我们把$θ$向量随机取一个初值。记为$θ^{(0)}$，上面的括号里面的数字代表我们迭代的轮数，当前初始轮数为$0$.

对于第k轮的迭代。我们从$θ^{(k)}_1$开始，到$θ^{(k)}_n$为止，依次求$θ^{(k)}_i$。$θ^{(k)}_i$的表达式如下：
$$
\theta^{(k)}_i = \mathbf{argmin}_{\theta_i}J(\theta^{(k)}_1,\cdot\cdot\cdot,\theta^{k}_{i-1},\theta_i,\cdot\cdot\cdot,\theta^{(k-1)}_n
$$

##### 缺失值处理

缺失值的处理有三种方法：

- 直接使用含有缺失值的数据。某些算法可以直接使用含有缺失值的情况，如决策树算法可以直接使用含有缺失值的数据。
- 删除含有缺失值的数据。最简单的办法就是删除含有缺失值的样本。
- 缺失值补全。用最可能的值来插补缺失值。这也是在实际工程中应用最广泛的技术。

缺失值补全常见有以下方法：均值插补；同类均值插补；建模预测；高维映射；多重插补；压缩感知及矩阵补全

均值插补：

- 如果样本的属性是连续值，则该属性的缺失值就以该属性有效值的平均值来插补。
- 如果样本的属性是离散值，则该属性的缺失值就以该属性有效值的众数来插补。

同类均值插补首先将样本进行分类，然后以该类中的样本的均值来插补缺失值。

建模预测的思想是：将缺失的属性作为预测目标，通过建立模型来预测。

给定数据集$\mathbb{D}=\{(\vec{\mathbf{x}}_1,\tilde{y}_1),\cdots,(\vec{\mathbf{x}}_N,\tilde{y}_N)\}$。假设属性$j$含有缺失值，根据$x_{i,j}$是否缺失，将数据集划分为：$\mathbb{D}_1=\{\vec{\mathbf{x}}_i|x_{i,j}\ne\text{null}\}$：属性$j$有效的样本的集合。$\mathbb{D}_2=\{\vec{\mathbf{x}}_i|x_{i,j}=\text{null}\}$：属性$j$缺失的样本的集合。

将$\mathbb{D}_1$中的样本作为新的训练集，标签值重新定义为属性$j$的值，通过建模来完成属性$j$的学习。将$\mathbb{D}_2$中的样本作为测试集，通过学得的模型来预测其属性$j$的值。

这种方法的效果相对较好，但是该方法有个根本缺陷：

- 如果其他属性和属性$j$无关，则预测的结果无意义。
- 如果预测结果相当准确，则又说明属性$j$可以由其它属性计算得到， 于是属性$j$信息冗余，没有必要纳入数据集中。

###### 高维映射

高维映射的思想是：将属性映射到高维空间。给定数据集$\mathbb{D}$，假设属性$j$的取值为离散值$\{a_1,\cdots,a_K\}$一共$K$个值，则将该属性扩展为$K+1$个属性 ，其中：

- 若在属性$j$上的取值为$a_k$，则在新的属性$j_k$上的取值为1，在新的属性$j_1,\cdots,j_{k-1},j_{k+1},\cdots,j_{K+1}$上的取值为 0 。
- 若在属性$j$上缺失，则样本的新的属性$j_{K+1}$上的取值为 1,在新的其他属性为 0 。

对于连续特征，高维映射无法直接处理。可以在连续特征离散化之后，再进行高维映射。

高维映射是最精确的做法，它完全保留了所有的信息，也未增加任何额外的信息。

- 优点：完整保留了原始数据的全部信息。
- 缺点：计算量大大提升。而且只有在样本量非常大的时候效果才好，否则会因为过于稀疏，效果很差。 

##### 特征编码

###### 特征二元化

特征二元化的算法比较简单。 对属性$j$指定一个阈值$\epsilon$。

- 如果样本在属性$j$上的值大于等于$\epsilon$，则二元化之后为 1 。
- 如果样本在属性$j$上的值小于$\epsilon$，则二元化之后为 0 。

###### `one-hot`

假设属性$j$的取值为非数值的离散集合$\{a_1,\cdots,a_K\}$，独热码将其扩展成$K$个属性，每个新属性代表属性 的一个状态位：若样本在属性$j$上的取值为$a_k$，则样本在新的属性$j_k$上的取值为 1，在新的属性$j_1,\cdots,j_{k-1},j_{k+1},\cdots,j_{K+1}$上的取值为 0 。

- 这种做法中，如果在$j_1,\cdots,j_K$上取值全为 0，则表示发生了缺失。
- 也可以扩展成$K-1$个属性， 如果在$j_1,\cdots,j_{K-1}$上取值全为 0，则表示样本在属性$j$上的取值为$a_K$。

在决策树模型中，并不推荐对离散特征进行`one-hot`。 主要有两个原因：

- 产生样本切分不平衡的问题，此时且分增益会非常小。
- 影响决策树的学习。决策树依赖的是数据的统计信息。而独热码编码会把数据切分到零散的小空间上。在这些零散的小空间上，统计信息是不准确的，学习效果变差。

##### 标准化和正则化

数据标准化是将样本的属性取值缩放到某个指定的范围。数据标准化的两个原因：

- 某些算法要求样本数据的属性取值具有零均值和单位方差。
- 样本不同属性具有不同量级时，消除数量级的影响。

数据集$\mathbb{D}=\{(\vec{\mathbf{x}}_1,\tilde{y}_1),\cdots,(\vec{\mathbf{x}}_N,\tilde{y}_N)\},\vec{\mathbf{x}}_i=(x_{i,1},\cdots,x_{i,n})^T$。常用标准化算法有：

- `min-max`标准化：对于属性$j$，设所有样本在属性$j$上的最大值为$j_{\text{max}}$，最小值为$j_{\text{min}}$。则标准化后的属性值为：
  $$
  \hat{x}_{i,j}=\frac{x_{i,j}-j_{\text{min}}}{j_{\text{max}}-j_{\text{min}}}
  $$

- `z-score`标准化：对于属性$j$，设所有样本在属性$j$上的均值为$\mu_j$，方差为$\sigma_j$。则标准化后的属性值为：

$$
\hat{x}_{i,j}=\frac{x_{i,j}-\mu_j}{\sigma_j}
$$

训练集、验证集、测试集使用相同标准化参数，该参数的值都是从训练集中得到。

- 如果使用`min-max` 标准化，则属性$j$的标准化参数$j_{\text{max}},j_{\text{min}}$都是从训练集中计算得到。
- 如果使用`z-score` 标准化，则属性$j$的标准化参数$\mu_j,\sigma_j$都是从训练集中计算得到。

数据正则化是将样本的某个范数缩放到单位1。设数据集$\mathbb{D}=\{(\vec{\mathbf{x}}_1,\tilde{y}_1),\cdots,(\vec{\mathbf{x}}_N,\tilde{y}_N)\},\vec{\mathbf{x}}_i=(x_{i,1},\cdots,x_{i,n})^T$。 则样本 正则化后的结果为：
$$
\hat{\vec{\mathbf{x}}}_i=\left(\frac{x_{i,1}}{L_p(\vec{\mathbf{x}}_i)},\cdots,\frac{x_{i,n}}{L_p(\vec{\mathbf{x}}_i)}\right)^T
$$
其中$L_p$为范数：$L_p(\vec{\mathbf{x}}_i)=(|x_{i,1}|^p+\cdots+|x_{i,n}|^p)^{1/p}$。

正则化的过程是针对单个样本的，对每个样本将它缩放到单位范数。标准化是针对单个属性的，需要用到所有样本在该属性上的值。

##### 类别不平衡问题

通常在机器学习中都有一个基本假设：不同类别的训练样本数目相当。如果不同类别的训练样本数目稍有差别，通常影响不大。如果不同类别的训练样本数目差别很大，则会对学习过程造成影响。这就是类别不平衡问题(`class-imbalance`)。对于类别不平衡问题，常用的有三种方法：

- 基于再缩放策略进行决策，称之为阈值移动`threshold-moving` 。
- 直接对训练集里的反类样本进行欠采样`undersampling`。
- 直接对训练集里的正类样本进行过采样`oversampling`。

对于正负样本极不平衡的场景，可以完全换一个不同的角度来看问题：将它看作一分类`One Class Learning`或者异常检测`Novelty Detection`问题。此时可以用`One-class SVM`模型。

##### 多分类问题

对于只能求解二分类问题的算法，一旦遇到问题是多类别的，那么可以将多分类问题拆解成二分类任务求解。即：先对原问题进行拆分，然后为拆出的每个二分类任务训练一个分类器。测试时，对这些二分类器的预测结果进行集成，从而获得最终的多分类结果。假设类别为$\{c_1,c_2,\cdots,c_K\}$

| 方法           | 说明                                                         | 训练                                                         | 预测                                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `One VS Rest`  | 为每一个类别训练一个分类器。则训练$K$个分类器$CL_1,\cdots,CL_K$ | 训练$CL_i$时，将类别为$i$的样本点定义为正类，将类别不是$i$的样本点定义为负类，训练$CL_i$不光需要给出预测结果是否属于类别$c_i$，还要给出置信度。 | 预测时，对于未知的实例，用训练出来的$K$个分类器来预测。假设置信度最高的分类器为$CL_m$，则该实例的类别预测为$c_m$。 |
| `One VS One`   | 为每一对类别训练一个分类器。那么训练$\frac{K(K-1)}{2}$个分类器$CL_{1,2},\cdots,CL_{K-1,K}$ | $CL_{i,j}$分类器从原始训练集中提取类别为$c_i,c_j$的样本点作为新的训练集，然后训练 | 预测时，首先设投票结果为$s_0=0,\cdots,s_K=0$,然后用每个分类器 对未知实例进行预测：若预测结果是类别$c_i$，则$s_i+=1$。若预测结果是类别$c_j$，则$s_j+=1$。最终假设$s_m$最大，则该未知的实例分类为$c_m$。 |
| `Many VS Many` | 每次都将若干个类作为正类，若干个其他类作为反类。             | 对$K$个类别进行$M$次划分，每次划分都将一部分类别划分为正类，一部分类别划分为反类，从而形成一个二分类训练集。这样一个产生$M$个训练集，可以训练出$M$个分类器。 | 用$M$个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。 |

