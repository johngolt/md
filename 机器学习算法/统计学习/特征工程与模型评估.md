#### 数据预处理

##### 缺失值处理

缺失值的处理有三种方法：直接使用含有缺失值的数据、删除含有缺失值的数据、缺失值补全。缺失值补全常见有以下方法：均值插补、同类均值插补、建模预测、高维映射、多重插补、压缩感知及矩阵补全

###### 均值插补&同类均值插补

均值插补：如果样本的属性是连续值，则该属性的缺失值就以该属性有效值的平均值来插补。如果样本的属性是离散值，则该属性的缺失值就以该属性有效值的众数来插补。均值插补在含有缺失值的属性上的所有缺失值都填补为同一个值。

同类均值插补首先将样本进行分类，然后以该类中的样本的均值来插补缺失值。

###### 建模预测

建模预测的思想是：将缺失的属性作为预测目标，通过建立模型来预测。

给定数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}$。假设属性$j$含有缺失值，根据$x_{i,j}$是否缺失，将数据集划分为：$\mathbb{D}_1=\{\vec{\mathbf{x}_i}|x_{i,j}\ne null\}$：属性$j$有效的样本的集合。$\mathbb{D}_2=\{\vec{\mathbf{x}_i}|x_{i,j}= null\}$：属性$j$缺失的样本的集合。将$\mathbb{D}_1$中的样本作为新的训练集，标签值重新定义为属性$j$的值，通过建模来完成属性$j$的学习。将$\mathbb{D}_2$中的样本作为测试集，通过学得的模型来预测其属性$j$的值。

这种方法的效果相对较好，但是该方法有个根本缺陷：

- 如果其他属性和属性$j$无关，则预测的结果无意义。
- 如果预测结果相当准确，则又说明属性  可以由其它属性计算得到， 于是属性$j$信息冗余，没有必要纳入数据集中。

###### 高位映射

高维映射的思想是：将属性映射到高维空间。

![](D:/MarkDown/picture/2/52.png)

对于连续特征，高维映射无法直接处理。可以在连续特征离散化之后，再进行高维映射。

优点：完整保留了原始数据的全部信息。缺点：计算量大大提升。而且只有在样本量非常大的时候效果才好，否则会因为过于稀疏，效果很差。

###### 多重插补

**多重插补**认为待插补的值是随机的，它的值来自于已观测到的值。具体实践上通常是估计出待插补的值，然后再加上不同的噪声，形成多组可选插补值。然后根据某种选择依据，选取最合适的插补值。

多重插补法的步骤：通过变量之间的关系对缺失数据进行预测，利用蒙特卡洛方法生成多个完整的数据集。在每个完整的数据集上进行训练，得到训练后的模型以及评价函数值。对来自各个完整的数据集的结果，根据评价函数值进行选择，选择评价函数值最大的模型，其对应的插值就是最终的插补值。

###### 压缩感知&矩阵补全

压缩感知分为感知测量和重构恢复两个阶段。感知测量：关注如何对原始信号进行处理以获得稀疏样本表示。常用的手段是傅里叶变换、小波变换、字典学习、稀疏编码等。重构恢复：关注的是如何基于稀疏性从少量观测中恢复原信号。

限定等距性：对于大小为$m \times n, m \ll n$的矩阵$\mathbf{A}$，若存在常数$\delta_{k} \in(0,1)$，使得对于任意向量$\vec{\mathbf{s}}$和$\mathbf{A}$的所有子矩阵$\mathbf{A}_{k} \in \mathbb{R}^{m \times k}$，都有：$\left(1-\delta_{k}\right)\|\vec{\mathbf{s}}\|_{2}^{2} \leq\left\|\mathbf{A}_{k} \vec{\mathbf{s}}\right\|_{2}^{2} \leq\left(1+\delta_{k}\right)\|\vec{\mathbf{s}}\|_{2}^{2}$则称$\mathbf{A}$满足$k$限定等距性。此时通过下面的最优化问题可以近乎完美的从$\vec{y}$中恢复出稀疏信号  ，进而恢复出$\overrightarrow{\mathbf{x}}$
$$
\begin{array}{c}{\min _{\overrightarrow{\mathrm{s}}}\|\overrightarrow{\mathbf{s}}\|_{1}} \\ {\text { s.t. } \overrightarrow{\mathbf{y}}=\mathbf{A} \overrightarrow{\mathbf{s}}}\end{array}
$$
矩阵补全`matrix completion`解决的问题是：
$$
\begin{array}{l}{\operatorname{min}_{\mathbf{X}} \operatorname{rank} (\mathbf{X})} \\ {\text {s.t. } \quad x_{i, j}=a_{i, j},(i, j) \in \Omega}\end{array}
$$
$\mathbf{A}$为观测矩阵，其中有很多缺失值。$\Omega$为$\mathbf{A}$中所有的有数值的下标的集合。$\mathbf{X}$为需要恢复的稀疏信号， 为矩阵$rank(\mathbf{X})$的秩。

考虑到$rank(\mathbf{X})$在集合$\left\{\mathbf{X} \in \mathbb{R}^{m \times n} :\|\mathbf{X}\|_{F}^{2} \leq 1\right\}$上的凸包是$\mathbf{X}$的核范数`nuclear norm`：
$$
\|\mathbf{x}\|_{*}=\sum_{j=1}^{\min \{m, n\}} \sigma_{j}(\mathbf{X})
$$
其中$\sigma_{j}(\mathbf{X})$表示$\mathbf{X}$的奇异值。于是可以通过最小化矩阵核范数来近似求解：
$$
\begin{array}{l}{\operatorname{min}_{\mathbf{X}} \|\mathbf{X}\|_*} \\ {\text {s.t. } \quad x_{i, j}=a_{i, j},(i, j) \in \Omega}\end{array}
$$
该最优化问题是一个凸优化问题，可以通过半正定规划求解。

##### 特征编码

###### 特征二元化

特征二元化的算法比较简单。 对属性 指定一个阈值 。

- 如果样本在属性  上的值大于等于 ，则二元化之后为 1 。
- 如果样本在属性  上的值小于 ，则二元化之后为 0 。

###### one-hot

假设属性 的取值为非数值的离散集合 ，独热码将其扩展成 个属性，每个新属性代表属性 的一个状态位：若样本在属性 上的取值为 ，则样本在新的属性 上的取值为 1，在新的属性 上的取值为 0 。

- 这种做法中，如果在 上取值全为 0，则表示发生了缺失。
- 也可以扩展成 个属性， 如果在 上取值全为 0，则表示样本在属性 上的取值为 。

`One-Hot Encoding` 的优点：

- 能够处理非数值属性。
- 在一定程度上也扩充了特征。
- 编码后的属性是稀疏的，存在大量的零元分量。

在决策树模型中，并不推荐对离散特征进行`one-hot`。 主要有两个原因：

- 产生样本切分不平衡的问题，此时且分增益会非常小。这种划分的增益非常小，因为拆分之后：较小的那个拆分样本集，它占总样本的比例太小。无论增益多大，乘以该比例之后几乎可以忽略。较大的那个拆分样本集，它几乎就是原始的样本集，增益几乎为零。
- 影响决策树的学习。决策树依赖的是数据的统计信息。而独热码编码会把数据切分到零散的小空间上。在这些零散的小空间上，统计信息是不准确的，学习效果变差。本质是因为独热码编码之后的特征的表达能力较差的。该特征的预测能力被人为的拆分成多份，每一份与其他特征竞争最优划分点都失败。最终该特征得到的重要性会比实际值低。

###### 离散化

离散化用于将连续的数值属性转化为离散的数值属性。是否使用特征离散化，这背后是：使用“海量离散特征+简单模型”，还是“少量连续特征+复杂模型”。

对于线性模型，通常使用“海量离散特征+简单模型”。优点：模型简单。缺点：特征工程比较困难。但是一旦有成功的经验就可以推广，并且可以很多人并行研究。对于非线性模型，通常使用“少量连续特征+复杂模型”。优点是：不需要进行复杂的特征工程。缺点是：模型复杂。

在工业界很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列 0/1 的离散特征。其优势有：

- 离散化之后得到的稀疏向量，内积乘法运算速度更快，计算结果方便存储。
- 离散化之后的特征对于异常数据具有很强的鲁棒性。
- 逻辑回归属于广义线性模型，表达能力受限，只能描述线性关系。特征离散化之后，相当于引入了非线性，提升模型的表达能力，增强拟合能力。
- 离散化之后可以进行特征交叉。假设有连续特征$j$，离散化为$N$个 0/1 特征；连续特征$k$，离散化为$M$特 0/1 特征，则分别进行离散化之后引入了$M+N$个特征。假设离散化时，并不是独立进行离散化，而是特征$j,k$联合进行离散化，则可以得到$M\times N$个组合特征。这会进一步引入非线性，提高模型表达能力。
- 离散化之后，模型会更稳定。

特征离散化简化了逻辑回归模型，同时降低模型过拟合的风险。能够对抗过拟合的原因：经过特征离散化之后，模型不再拟合特征的具体值，而是拟合特征的某个概念。因此能够对抗数据的扰动，更具有鲁棒性。另外它使得模型要拟合的值大幅度降低，也降低了模型的复杂度。

##### 数据标准化、正则化

###### 标准化

数据标准化是将样本的属性取值缩放到某个指定的范围。

数据标准化的两个原因：

- 某些算法要求样本数据的属性取值具有零均值和单位方差。
- 样本不同属性具有不同量级时，消除数量级的影响。数量级的差异将导致量级较大的属性占据主导地位。数量级的差异将导致迭代收敛速度减慢。标准化后进行梯度下降时，每一步梯度的方向都几乎指向最小值（等高线中心点）的方向，迭代次数较少。所有依赖于样本距离的算法对于数据的数量级都非常敏感。

设数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}, \vec{\mathbf{x}}_{i} =(x_{i,1},\cdots,x_{i,n})^T$。常用的标准化算法有：

- `min-max`标准化：对于属性 ，设所有样本在属性 上的最大值为 ，最小值为 。则标准化后的属性值为：
  $$
  \hat{x}_{x,j} = \frac{x_{i,j}-j_{min}}{j_{max}-j_{min}}
  $$

- `z-score`标准化：对于属性 ，设所有样本在属性 上的均值为 ，方差为 。则标准化后的属性值为：
  $$
  \hat{x}_{x,j} = \frac{x_{i,j}-\mu_j}{\sigma_j}
  $$

###### 正则化

数据正则化是将样本的某个范数缩放到单位1。

设数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}, \vec{\mathbf{x}}_{i} =(x_{i,1},\cdots,x_{i,n})^T$。 则样本$\vec{\mathbf{x}}_{i}$正则化后的结果为：
$$
\hat{\vec{\mathbf{x}}_{i}} = (\frac{x_{i,1}}{L_p(\vec{\mathbf{x}}_{i})},\cdots,\frac{x_{i,n}}{L_p(\vec{\mathbf{x}}_{i})})^T
$$
其中$L_P$为范数：$L_P(\vec{\mathbf{x}}_{i}) = (|x_{i,1}|^p+\cdots+|x_{i,n}|^p)^{\frac{1}{p}}$

正则化的过程是针对单个样本的，对每个样本将它缩放到单位范数。标准化是针对单个属性的，需要用到所有样本在该属性上的值。

##### 特征选择

特征选择可能会降低模型的预测能力。因为被剔除的特征中可能包含了有效的信息，抛弃了这部分信息会一定程度上降低预测准确率。这是计算复杂度和预测能力之间的折衷：

- 如果保留尽可能多的特征，则模型的预测能力会有所提升，但是计算复杂度会上升。
- 如果剔除尽可能多的特征，则模型的预测能力会有所下降，但是计算复杂度会下降。

###### 特征选择原理

要想从初始的特征集合中选取一个包含了所有重要信息的特征子集，如果没有任何领域知识作为先验假设，则只能遍历所有可能的特征组合。一个可选的方案是：

- 产生一个候选子集，评价出它的好坏。
- 基于评价结果产生下一个候选子集，再评价其好坏。
- 这个过程持续进行下去，直至无法找到更好的后续子集为止。

**子集搜索**：解决该问题的算法步骤如下：

- 给定特征集合$\mathbb{A} = \{A_1,\cdots,A_d\}$，首先将每个特征看作一个候选子集，然后对这$d$个候选子集进行评价。假设$A_2$最优，于是将$A_2$作为第一轮的选定子集。
- 然后在上一轮的选定子集中加入一个特征，构成了包含两个特征的候选子集。假定$A_2,A_5$最优，且优于$A_2$，于是将$A_2,A_5$作为第二轮的选定子集。
- 假定在第$k+1$轮时，本轮的最优的特征子集不如上一轮的最优的特征子集，则停止生成候选子集，并将上一轮选定的特征子集作为特征选择的结果。

这种逐渐增加相关特征的策略称作前向`forward`搜索。类似地，如果从完整的特征集合开始，每次尝试去掉一个无关特征，这样逐渐减小特征的策略称作后向`backward`搜索。也可以将前向和后向搜索结合起来，每一轮逐渐增加选定相关特征（这些特征在后续迭代中确定不会被去除）、同时减少无关特征，这样的策略被称作双向`bidirectional`搜索。该策略是贪心的，因为它们仅仅考虑了使本轮选定集最优。但是除非进行穷举搜索，否则这样的问题无法避免。

**子集评价**：特征子集$\mathbb{A}$实际上确定了对数据集$\mathbb{D}$的一个划分规则。

- 每个划分区域对应着$\mathbb{A}$上的一个取值，而样本标记信息$y$则对应着$\mathbb{D}$的真实划分。
- 通过估算这两种划分之间的差异，就能对$\mathbb{A}$进行评价：与$y$对应的划分的差异越小，则说明$\mathbb{A}$越好。
- 信息熵仅仅是判断这个差异的一种方法，其他能判断这两个划分差异的机制都能够用于特征子集的评价。

给定数据集$\mathbb{D}$，假设所有属性均为离散型。对属性子集$\mathbb{A}$， 假定根据其取值将$\mathbb{D}$分成了$V$个子集：$\{\mathbb{D}_1,\cdots,\mathbb{D}_V\}$。于是可以计算属性子集$\mathbb{A}$的信息增益：
$$
g(\mathbb{D},\mathbb{A}) = H(\mathbb{D})-H(\mathbb{D}|\mathbb{A}) = H(\mathbb{D}) = \sum_{v=1}^V\frac{|\mathbb{D}_v|}{|\mathbb{D}|}H(\mathbb{D}_v)
$$
其中$|\cdot|$为集合大小，$H(\cdot)$为熵。信息增益越大，则表明特征子集$\mathbb{A}$包含的有助于分类的信息越多。于是对于每个候选特征子集，可以基于训练数据集$\mathbb{D}$来计算其信息增益作为评价准则。

过滤式方法先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关。这相当于先用特征选择过程对初始特征进行过滤，再用过滤后的特征来训练模型。包裹式特征选择直接把最终将要使用的学习器的性能作为特征子集的评价准则。其目的就是为给定学习器选择最有利于其性能、量身定做的特征子集。嵌入式特征选择是将特征选择与学习器训练过程融为一体，两者在同一个优化过程中完成的。即学习器训练过程中自动进行了特征选择。

##### 稀疏表示和字典学习

数据集具有这样的稀疏表达形式时，对学习任务来讲会有不少好处：

- 如果数据集具有高度的稀疏性，则该问题很可能是线性可分的。对于线性支持向量机，这种情况能取得更佳的性能。
- 稀疏样本并不会造成存储上的巨大负担，因为稀疏矩阵已经有很多很高效的存储方法。

现在问题是：如果给定数据集 是稠密的（即普通的、非稀疏的），则能否将它转化为稀疏的形式？这就是字典学习 `dictionary learning`和稀疏编码`sparse coding`的目标。

字典学习：学习一个字典，通过该字典将样本转化为合适的稀疏表示形式。它侧重于学得字典的过程。稀疏编码：获取样本的稀疏表达，不一定需要通过字典。它侧重于对样本进行稀疏表达的过程。这两者通常是在同一个优化求解过程中完成的，因此这里不做区分，统称为字典学习。

给定数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}$，希望对样本$\vec{\mathbf{x}}_{i}$学习到它的一个稀疏表示 。其中$\vec{\alpha}_{i} \in \mathbb{R}^{k}$是一个$k$维列向量，且其中大量元素为 0 。一个自然的想法进行线性变换，即寻找一个矩阵$\mathbf{P} \in \mathbb{R}^{k \times n}$使得 $\mathbf{P} \vec{\mathbf{x}}_{i}=\vec{\alpha}_{i}$。

因此给出字典学习的最优化目标：$\min _{\mathbf{B}, \vec{\alpha}_{i}} \sum_{i=1}^{N}\left\|\vec{\mathbf{x}}_{i}-\mathbf{B} \vec{\alpha}_{i}\right\|_{2}^{2}+\lambda \sum_{i=1}^{N}\left\|\vec{\alpha}_{i}\right\|_{1}$。其中$\mathbf{B} \in \mathbb{R}^{n \times k}$称作字典矩阵。$k$称作字典的词汇量。

第一步：固定字典$\mathbf{B}$， 为每一个样本$\vec{\mathbf{x}_i}$找到相应的$\vec{\alpha_i}$：$\min _{\vec{\alpha}_{i}}\left\|\vec{\mathbf{x}}_{i}-\mathbf{B} \vec{\alpha}_{\dot{z}}\right\|_{2}^{2}+\lambda \sum_{i=1}^{N}\left\|\vec{\alpha}_{i}\right\|_{1}$。第二步：根据$\min _{\mathbf{B}}\|\mathbf{X}-\mathbf{B} \mathbf{A}\|_{F}^{2}$，以$\vec{\alpha_i}$为初值来更新字典$\mathbf{B}$。反复迭代上述两步，最终即可求得字典$\mathbf{B}$和样本$\vec{\mathbf{x}_i}$的稀疏表示$\vec{\alpha_i}$。

这里有个最优化问题：$\min _{\mathbf{B}}\|\mathbf{X}-\mathbf{B} \mathbf{A}\|_{F}^{2}$，该问题有多种求解方法，常用的有基于逐列更新策略的`KSVD`算法。令$\vec{\mathbf{b}}_i$为字典矩阵$\mathbf{B}$的第$i$列，$\vec{\mathbf{a}}^j$表示稀疏矩阵$\mathbf{A}$的第$j$行。 固定$\mathbf{B}$其他列，仅考虑第$i$列，则有：
$$
\min _{\overrightarrow{\mathbf{b}}_{i}}\left\|\mathbf{X}-\sum_{j=1}^{k} \overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{j}\right\|_{F}^{2}=\operatorname{mir}_{\overrightarrow{\mathbf{b}}_{i}}\left\|\left(\mathbf{X}-\sum_{j=1, j \neq i}^{k} \overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{j}\right)-\overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{i}\right\|_{F}^{2}
$$
令$\mathbf{E}_{i}=\mathbf{X}-\sum_{j=1, j \neq i}^{k} \overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{j}$，它表示去掉$\vec{\mathbf{x}}_i$的稀疏表示之后，样本集的稀疏表示与原样本集的误差矩阵。考虑到更新字典的第$i$列$\vec{\mathbf{b}}_i$时，其他各列都是固定的，则$\mathbf{E}_{i}$是固定的。则最优化问题转换为：
$$
\min _{\overrightarrow{\mathrm{b}}_{\mathfrak{i}}}\left\|\mathbf{E}_{i}-\overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{i}\right\|_{F}^{2}
$$
求解该最优化问题只需要对$\mathbf{E}_{i}$进行奇异值分解以取得最大奇异值所对应的正交向量。直接对$\mathbf{E}_{i}$进行奇异值分解会同时修改$\vec{\mathbf{b}}_i$和 $\vec{\mathbf{b}}^i$， 从而可能破坏$\mathbf{A}$的稀疏性。因为第二步 “以$\vec{\alpha}^i$为初值来更新字典$\mathbf{B}$” 中， 在更新$\mathbf{B}$前后$\vec{\alpha}^i$的非零元所处的位置和非零元素的值很可能不一致。为避免发生这样的情况 `KSVD` 对$\mathbf{E}_{i}$和$\overrightarrow{\mathbf{a}}^{i}$进行了专门处理：$\overrightarrow{\mathbf{a}}^{i}$仅保留非零元素。$\mathbf{E}_{i}$仅保留$\overrightarrow{\mathbf{b}}_{i}$和$\overrightarrow{\mathbf{a}}^{i}$的非零元素的乘积项，然后再进行奇异值分解，这样就保持了第一步得到的稀疏性。

##### 多分类问题

对于只能求解二分类问题的算法，一旦遇到问题是多类别的，那么可以将多分类问题拆解成二分类任务求解。即：先对原问题进行拆分，然后为拆出的每个二分类任务训练一个分类器。测试时，对这些二分类器的预测结果进行集成，从而获得最终的多分类结果。

###### one VS rest

一对其余：为每一个类别训练一个分类器。假设类别为$\{c_1,c_2,\cdots,c_K\}$，则训练$K$个分类器$CL_1,\cdots,CL_K$：

- 训练$CL_i$时，将类别为$i$的样本点定义为正类，将类别不是$i$的样本点定义为负类。
- 训练$CL_i$不光需要给出预测结果是否属于类别$c_i$，还要给出置信度。

预测时，对于未知的实例，用训练出来的$K$个分类器来预测。假设置信度最高的分类器为$CL_m$，则该实例的类别预测为$c_m$。

###### one VS one

一对一：为每一对类别训练一个分类器。假设类别为$\{c_1,c_2,\cdots,c_K\}$。那么训练$\frac{K(K-1)}{2}$个分类器$CL_{1,2},\cdots,CL_{K-1,K}$。$CL_{i,j}$分类器从原始训练集中提取类别为$c_i,c_j$的样本点作为新的训练集，然后训练 。

预测时，对于未知的实例，对预测结果进行投票。

- 首先设投票结果为$s_0=0,s_1=0,\cdots,s_K=0$
- 然后用每个分类器 对未知实例进行预测：若预测结果是类别$c_i$，则$s_i+=1$。若预测结果是类别$c_j$，则$s_j+=1$。最终假设$s_m$最大，则该未知的实例分类为$c_m$。

###### many VS many

多对多：每次都将若干个类作为正类，若干个其他类作为反类。

`ECOC`工作过程主要分两步，假设类别为$c_1,c_2,\cdots,c_K$：

- 编码：对$K$个类别进行$M$次划分，每次划分都将一部分类别划分为正类，一部分类别划分为反类，从而形成一个二分类训练集。这样一个产生$M$个训练集，可以训练出$M$个分类器。
- 解码：用$M$个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。

#### 模型评估

##### 过拟合、欠拟合

过拟合`overfitting`：选择的模型包含的参数过多，以至于该模型对于已知数据预测得很好，但是对于未知数据预测的很差，使得训练误差和测试误差之间的差距太大。过拟合的原因是：将训练样本本身的一些特点当作了所有潜在样本都具有的一般性质，这会造成泛化能力下降。过拟合无法避免，只能缓解

欠拟合`underfitting`：选择的模型包含的参数太少，以至于该模型对已知数据都预测的很差，使得训练误差较大。欠拟合的原因一般是学习能力低下造成的。

###### 模型容量

模型的假设空间指的是：代表模型的函数集合。这也称作模型的表示容量`representational capacity`。由于额外的限制因素（比如优化算法的不完善），模型的有效容量`effective capacity`一般会小于模型的表示容量。

通常泛化误差是关于模型容量的 `U`形函数。随着模型容量增大：训练误差会下降直到逼近其最小值、泛化误差先减小后增大、泛化误差与训练误差的差值会增大。

![](D:/MarkDown/picture/2/53.png)

高偏差对应于模型的欠拟合：模型过于简单，以至于未能很好的学习训练集，从而使得训练误差过高。此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。

高方差对应于模型的过拟合：模型过于复杂，以至于将训练集的细节都学到，将训练集的一些细节当做普遍的规律，从而使得测试集误差与训练集误差相距甚远。此时模型预测的偏差较小，表示预测较准确。但是模型预测的方差较大，表示预测较不稳定。

误差诊断：通过训练误差和测试误差来分析模型是否存在高方差、高偏差。如果训练误差较高：说明模型的偏差较大，模型出现了欠拟合。如果训练误差较低，而测试误差较高：说明模型的偏差较大，出现了过拟合。如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。

缓解过拟合的策略：正则化；数据集增强：通过人工规则产生虚假数据来创造更多的训练数据；噪声注入：包括输入噪声注入、输出噪声注入、权重噪声注入。将噪声分别注入到输入/输出/权重参数中；早停：当验证集上的误差没有进一步改善时，算法提前终止。

##### bias-variance 分解

点估计：对参数$\theta$的一个预测，记作$\hat{\theta}$。假设$\left\{x_{1}, x_{2}, \cdots, x_{m}\right\}$为独立同分布的数据点，该分布由参数$\theta$决定。则参数$\theta$的点估计为某个函数：$\hat{\theta}_{m}=g\left(x_{1}, x_{2}, \cdots, x_{m}\right)$。注意：点估计的定义并不要求  返回一个接近真实值  。根据频率学派的观点：真实参值$\theta$是固定的，但是未知的。$\hat{\theta}$是数据点的函数。由于数据是随机采样的，因此$\hat{\theta}$是个随机变量

偏差定义为：$\operatorname{bias}\left(\hat{\theta}_{m}\right)=\mathbb{E}\left(\hat{\theta}_{m}\right)-\theta$，期望作用在所有数据上。如果$\operatorname{bias}\left(\hat{\theta}_{m}\right)=0$，则称估计量$\hat{\theta}$是无偏的。如果$\lim _{m \rightarrow \infty} \operatorname{bias}\left(\hat{\theta}_{m}\right)=0$，则称估计量$\hat{\theta}$是渐近无偏的。无偏估计并不一定是最好的估计。通常希望当数据集的大小$m$增加时，点估计会收敛到对应参数的真实值。即：

$$
\operatorname{plim}_{m \rightarrow \infty} \hat{\theta}_{m}=\theta
$$
 $\operatorname{plim}$表示依概率收敛。即对于任意的$\epsilon>0$，当$m \rightarrow \infty$时，有：$P\left(\left|\hat{\theta}_{m}-\theta\right|\right)>\epsilon \rightarrow 0$ 

###### 偏差方差分解

期望误差可以分解为
$$
\begin{aligned} \mathcal{R}(f) &=\mathbb{E}_{(\mathbf{x}, y) \sim p_{r}(\mathbf{x}, y)}\left[\left(y-f^{*}(\mathbf{x})+f^{*}(\mathbf{x})-f(\mathbf{x})\right)^{2}\right] \\ &=\mathbb{E}_{\mathbf{x} \sim p_{r}(\mathbf{x})}\left[\left(f(\mathbf{x})-f^{*}(\mathbf{x})\right)^{2}\right]+\varepsilon \end{aligned}
$$
对于单个样本$\mathbf{x}$，不同训练集$D$得到模型$f_D(\mathbf{x})$和最优模型$f^∗(\mathbf{x})$的上的期望差距为
$$
\begin{aligned} \mathbb{E}_{\mathcal{D}} &\left[\left(f_{\mathcal{D}}(\mathbf{x})-f^{*}(\mathbf{x})\right)^{2}\right] \\=& \mathbb{E}_{\mathcal{D}}\left[\left(f_{\mathcal{D}}(\mathbf{x})-\mathbb{E}_{\mathcal{D}}\left[f_{\mathcal{D}}(\mathbf{x})\right]+\mathbb{E}_{\mathcal{D}}\left[f_{\mathcal{D}}(\mathbf{x})\right]-f^{*}(\mathbf{x})\right)^{2}\right] \\=& \underbrace{\left(\mathbb{E}_{\mathcal{D}}\left[f_{\mathcal{D}}(\mathbf{x})\right]-f^{*}(\mathbf{x})\right)^{2}}_{(\text { bias })^{2}}+\underbrace{\mathbb{E}_{\mathcal{D}}\left[\left(f_{\mathcal{D}}(\mathbf{x})-\mathbb{E}_{\mathcal{D}}\left[f_{\mathcal{D}}(\mathbf{x})\right]\right)^{2}\right]}_{\text { variance }} \end{aligned}
$$

##### 参数估计准则

###### 最大似然估计

假设数据集$\mathbf{X}=\left\{\overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right\}$中的样本独立同分布地由$p_{d a t a}(\overrightarrow{\mathbf{x}})$产生，但是该分布是未知的。$p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$是一族由$\theta$参数控制的概率分布函数族，希望通过$p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$来估计真实的概率分布函数$p_{d a t a}(\overrightarrow{\mathbf{x}})$，也就是要估计$\theta$参数。最大似然估计最大化数据集$\mathbf{X}$出现的概率。即：
$$
\theta_{M L}=\arg \max _{\theta} p_{m o d e l}(\mathbf{X} ; \theta)=\arg \max _{\theta} \prod_{i=1}^{m} p_{m o d e l}\left(\overrightarrow{\mathbf{x}}_{i} ; \theta\right)
$$
由于概率的乘积容易出现数值下溢出，因此转换为对数的形式。因为$m$与$\theta$无关，因此它也等价于： $\theta_{M L}=\arg \max _{\theta} \sum_{i=1}^{m} \frac{1}{m} \log p_{m o d e l}\left(\overrightarrow{\mathbf{x}}_{i} ; \theta\right)$。由于数据集的经验分布为：$\hat{p}_{\text {data}}(\overrightarrow{\mathbf{x}})=\frac{1}{m} \sum_{i=1}^{m} \delta\left(\overrightarrow{\mathbf{x}}-\overrightarrow{\mathbf{x}}_{i}\right)$，其中$\delta(\cdot)$狄拉克函数。因此：$\theta_{M L}=\arg \max _{\theta} \mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{\text {data}}} \log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$。考虑数据集的经验分布$\hat{p}_{data}$和真实分布函数的估计量$p_{model}$之间的差异，`KL`散度为：
$$
\left.D\right|_{K L}\left(\hat{p}_{\text {data}} \| p_{\text {model}} ; \theta\right)=\mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{\text {data}}}\left[\log \hat{p}_{\text {data}}(\overrightarrow{\mathbf{x}})-\log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)\right]
$$
由于$\log \hat{p}_{d a t a}(\overrightarrow{\mathbf{x}})$与$\theta$无关，因此要使得$\left.D\right|_{K L}\left(\hat{p}_{\text { data }} \| p_{\text {model}} ; \theta\right)$最小，则只需要最小化$\mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{\text { data }}}\left[-\log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)\right]$。也就是最大化$\mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{d a z a}} \log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$。因此：最大似然估计就是最小化数据集的经验分布$\hat{p}_{data}$和真实分布函数的估计量$p_{model}$之间的差异。最大似然估计可以扩展到估计条件概率。假设数据集$\mathbf{X}=\left\{\overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right\}$，对应的观测值为$\mathbf{Y}=\left\{y_{1}, y_{2}, \cdots, y_{m}\right\}$。则条件概率的最大似然估计为：$\theta_{M L}=\arg \max _{\theta} p(\mathbf{Y} | \mathbf{X} ; \theta)$。如果样本是独立同分布的，则可以分解成：$\theta_{M L}=\arg \max _{\theta} \sum_{i=1}^{m} \log p\left(y_{i} | \overrightarrow{\mathbf{x}}_{i} ; \theta\right)$。最大似然估计有两个很好的性质：在某些条件下，最大似然估计具有一致性。这意味着当训练样本数量趋向于无穷时，参数的最大似然估计依概率收敛到参数的真实值。这些条件为：真实分布$p_{data}$必须位于分布函数族$p_{\text {model}}(\cdot ; \theta)$中；否则没有估计量可以表示$p_{data}$。真实分布$p_{data}$必须对应一个$\theta$值；否则从最大似然估计恢复出真实分布$p_{data}$之后，也不能解出参数$\theta$。最大似然估计具有很好的统计效率。即只需要较少的样本就能达到一个良好的泛化误差。最大似然估计通常是机器学习中的首选估计准则。

###### 贝叶斯估计

在最大似然估计中，频率学派的观点是：真实参数$\theta$是未知的固定的值，而点估计$\hat{\theta}$是随机变量。因为数据是随机生成的，所以数据集是随机的。在贝叶斯估计中，贝叶斯学派认为：数据集是能够直接观测到的，因此不是随机的。而真实参数$\theta$是未知的、不确定的，因此$\theta$是随机变量。对$\theta$的已知的知识表示成先验概率分布$p(\theta)$：表示在观测到任何数据之前，对于参数$\theta$的可能取值的一个分布。假设观测到一组数据$\mathbf{X}=\left\{\overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right\}$，根据贝叶斯法则，有：
$$
p(\theta | \mathbf{X})=\frac{p(\mathbf{X} | \theta) p(\theta)}{p(\mathbf{X})}
$$
贝叶斯估计与最大似然估计有两个重要区别：贝叶斯估计预测下，一个样本的分布为：
$$
p\left(\overrightarrow{\mathbf{x}}_{m+1} | \overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right)=\int p\left(\overrightarrow{\mathbf{x}}_{m+1} | \theta\right) p\left(\theta | \overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right) d \theta
$$
而最大似然估计预测下，一个样本的分布为：$p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$ 。贝叶斯估计会使得概率密度函数向着先验概率分布的区域偏移。当训练数据有限时，贝叶斯估计通常比最大似然估计泛化性能更好。当训练样本数量很大时，贝叶斯估计往往比最大似然估计计算代价较高。

有时候希望获取参数$\theta$的一个可能的值，而不仅仅是它的一个分布。此时可以通过最大后验估计`MAP` 选择后验概率最大的点：
$$
\theta_{M A P}=\arg \max _{\theta} p(\theta | \mathbf{X})=\arg \max _{\theta}[\log p(\mathbf{X} | \theta)+\log p(\theta)]
$$
最大后验估计具有最大似然估计没有的优势：拥有先验知识带来的信息。该信息有助于减少估计量的方差，但是增加了偏差。一些正则化方法可以被解释为最大后验估计，正则化项就是对应于$\log p(\theta)$。最大后验估计估计`MAP` 提供了一个直观的方法去设计复杂的、可解释的正则化项。

##### 泛化能力评估

模型泛化能力的评估：用测试集对模型进行评估。通常有下列方法：留出法`hold-out`、`K` 折交叉验证法`cross validation`、留一法`Leave-One-Out:LOO`、自助法`bootstrapping`。

留出法：直接将数据切分为三个互斥的部分（也可以切分成两部分，此时训练集也是验证集），然后在训练集上训练模型，在验证集上选择模型，最后用测试集上的误差作为泛化误差的估计。

`K` 折交叉验证法：数据随机划分为`K` 个互不相交且大小相同的子集，利用 `K-1` 个子集数据训练模型，利用余下的一个子集测试模型。对 `K` 种组合依次重复进行，获取测试误差的均值，将这个均值作为泛化误差的估计。

留一法：假设数据集中存在 个样本，令$K=N$则得到了 `K` 折交叉验证的一个特例。

自助采样法：给定包含$N$个样本的数据集$\mathbb{D}$，对它进行采样产生数据集$\mathbb{D}^{\prime}$：

- 每次随机从$\mathbb{D}$中挑选一个样本，将其拷贝放入$\mathbb{D}^{\prime}$中，然后再将该样本放回初始数据集$\mathbb{D}$中。
- 重复这个过程$N$次，就得到了包含$N$个样本的数据集$\mathbb{D}^{\prime}$。

将$\mathbb{D}^{\prime}$用作训练集，$\mathbb{D}-\mathbb{D}^{\prime}$用作测试集，这样的测试结果称作包外估计

![](../../picture/1/302.png)

##### 训练、验证、测试集

训练集用于训练模型。理论上训练集越大越好。将训练数据分成两个不相交的子集：训练集用于学习模型，验证集用于更新超参数。通常要求验证集足够大。如果验证集很小，那么模型的超参数可能就记住了一个小验证集里的样本，模型将对验证集严重过拟合。验证集通常会低估泛化误差。因此当超参数优化完成后，需要通过测试集来估计泛化误差。测试集用于评估模型的泛化误差。理论上测试集越大，则模型的泛化误差评估的越准确。测试集中的样本一定不能是训练样本。如果将训练样本放入测试集中，则会低估泛化误差。

###### 拆分

对于小批量数据，数据的拆分的常见比例为：

- 如果未设置验证集，则将数据三七分：70% 的数据用作训练集、30% 的数据用作测试集。
- 如果设置验证集，则将数据划分为：60% 的数据用作训练集、20%的数据用过验证集、20% 的数据用作测试集。

###### 分布不匹配

当训练集和验证集、测试集的数据分布不同时，有以下经验原则：

- 确保验证集和测试集的数据来自同一分布。
- 确保验证集和测试集能够反映未来得到的数据，或者最关注的数据。
- 确保数据被随机分配到验证集和测试集上。

当训练集和验证集、测试集的数据分布不同时，分析偏差和方差的方式有所不同。

- 如果训练集和验证集的分布一致，那么当训练误差和验证误差相差较大时，我们认为存在很大的方差问题。
- 如果训练集和验证集的分布不一致，那么当训练误差和验证误差相差较大时，有两种原因：
  - 第一个原因：模型只见过训练集数据，没有见过验证集的数据导致的，是数据不匹配的问题。
  - 第二个原因：模型本来就存在较大的方差。

##### 性能度量

###### 分类问题性能度量

**准确率**：$r = \frac{1}{N}\sum_{i=1}^{N}I(\tilde{y}_i=\hat{y}_i)$

**错误率**：$r = \frac{1}{N}\sum_{i=1}^{N}I(\tilde{y}_i\ne\hat{y}_i)$

|            | 预测：正类 | 预测：反类 |
| ---------- | ---------- | ---------- |
| 真实：正类 | TP         | FN         |
| 真实：反类 | FP         | TN         |

| 名称   | 定义                 |
| ------ | -------------------- |
| 查准率 | $P=\frac{TP}{TP+FP}$ |
| 查全率 | $R=\frac{TP}{TP+FN}$ |
| F1值   | $F1=\frac{P+R}{2PR}$ |

**$\text{P-R}$曲线**：假设排序后的样本集合为$\left(\overrightarrow{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\overrightarrow{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\overrightarrow{\mathbf{x}}_{N}, \tilde{y}_{N}\right)$，预测为正类的概率依次为$\left(p_{1}, p_{2}, \cdots, p_{N}\right)$。在第$i$轮，将$p_i$作为分类阈值来。即：
$$
\hat{y}_{j}=\left\{\begin{array}{ll}{1,} & {\text { if } p_{j} \geq p_{i}} \\ {0,} & {\text { else }}\end{array}, \quad j=1,2, \cdots, N\right.
$$
此时计算得到的查准率记做$P_i$，查全率记做$R_i$。以查准率为纵轴、查全率为横轴作图，就得到查准率-查全率曲线，简称 `P-R`曲线。该曲线由点$\left\{\left(R_{1}, P_{1}\right),\left(R_{2}, P_{2}\right), \cdots,\left(R_{N}, P_{N}\right)\right\}$组成。

`P-R`曲线直观显示出分类器在样本总体上的查全率、查准率。因此可以通过两个分类器在同一个测试集上的`P-R` 曲线来比较它们的预测能力：如果分类器`B`的`P-R`曲线被分类器`A`的曲线完全包住，则可断言：`A`的性能好于`B` 。如果分类器`A`的`P-R`曲线与分类器`B`的曲线发生了交叉，则难以一般性的断言两者的优劣，只能在具体的查准率和查全率下进行比较。此时一个合理的判定依据是比较`P-R`曲线下面积大小，但这个值通常不容易计算。可以考察平衡点。平衡点是`P-R`曲线上查准率等于查全率的点，可以判定：平衡点较远的`P-R`曲线较好。

![](D:/MarkDown/picture/1/113.png)

**$\text{ROC}$曲线**：定义真正例率为：$T P R=\frac{T P}{T P+F N}$。定义假正例率为：$F P R=\frac{F P}{T N+F P}$。假设排序后的样本集合为$\left(\overrightarrow{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\overrightarrow{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\overrightarrow{\mathbf{x}}_{N}, \tilde{y}_{N}\right)$，预测为正类的概率依次为$\left(p_{1}, p_{2}, \cdots, p_{N}\right)$。在第$i$轮，将$p_i$作为分类阈值来。即：
$$
\hat{y}_{j}=\left\{\begin{array}{ll}{1,} & {\text { if } p_{j} \geq p_{i}} \\ {0,} & {\text { else }}\end{array}, \quad j=1,2, \cdots, N\right.
$$
此时计算得到的真正例率记做$TPR_i$，假正例率记做$FPR_i$。以真正例率为纵轴、假正例率为横轴作图，就得到`ROC`曲线。该曲线由点$\left\{\left(T P R_{1}, F P R_{1}\right),\left(T P R_{2}, F P R_{2}\right), \cdots,\left(R P R_{N}, F P R_{N}\right)\right\}$组成。

`AUC` 是`ROC` 曲线的面积，其物理意义为：从所有正样本中随机挑选一个样本，模型将其预测为正样本的概率为$p_1$；从所有负样本中随机挑选一个样本，模型将其预测为正样本的概率为$p_0$。$p_1>p_0$的概率就等于 `AUC` 。

 CAP曲线首先将客户按照违约概率从高到低进行排序，横轴：该阈值下预测为正的样本数 / 样本集中的总样本数、纵轴：该阈值下检出的正样本中真实的正样本数 / 样本集合中的总正样本数，分别作出理想评级模型、实际评级模型、随机评级模型三条曲线。完美曲线：代表最完美的情况下，模型会将所有坏客户识别出来并将其排列于左方；随机曲线：代表模型对好坏客户比毫无区分能力，CAP曲线会是一条斜率为45度的曲线；实际曲线：代表实际模型的曲线，越接近完美曲线预测能力越强，越接近随机，曲线预测能力越弱。AR = (实际CAP曲线与随机曲线之间的面积) / （理想CAP曲线与随机之间的面积）

![](../../picture/1/319.png)

###### 回归问题性能度量

均方误差：$MSE = \frac{1}{N}\sum_{i=1}^N(\tilde{y}_i-\hat{y}_i)^2$

均方根误差：$RMSE = \sqrt{\frac{1}{N}\sum_{i=1}^N(\tilde{y}_i-\hat{y}_i)^2}$

均方根对数误差：$RMLSE = \sqrt{\frac{1}{N}\sum_{i=1}^N(\log(\tilde{y}_i)-\log(\hat{y}_i))^2}$。当真实值的分布范围比较广时，如果使用`MAE、MSE、RMSE` 等误差，这将使得模型更关注于那些真实标签值较大的样本。而`RMSLE` 关注的是预测误差的比例，使得真实标签值较小的样本也同等重要;当数据中存在标签较大的异常值时，`RMSLE` 能够降低这些异常值的影响。

平均绝对误差：$MAE = \frac{1}{N}\sum_{i=1}^N|\tilde{y}_i-\hat{y}_i)|$

平均绝对百分比误差：$MAPE = \frac{100%}{n}\sum_i|\frac{\hat{y_i}-y_i}{y_i}|$

对称平均绝对百分比误差：$SMAPE=\frac{100%}{n}\sum_i\frac{|\hat{y_i}-y_i|}{(|{\hat{y_i}|+|y_i|})/2}$

R Squared：$R^2 = 1-\frac{\sum_i(y_i-\hat{y}_i)^2}{\sum_i(\overline{y}-y_i)^2}$

##### 超参数调节

###### 搜索策略

超参数搜索有三种常见的策略：手动搜索：手动选择超参数；网格搜索：当超参数的数据相对较少时，这个方法很实用；随机搜索：通常推荐这种方式。

网格搜索的做法是：

- 对于每个超参数，选择一个较小的有限值集合去搜索。
- 然后这些超参数笛卡尔乘积得到多组超参数。
- 网格搜索使用每一组超参数训练模型，挑选验证集误差最小的超参数作为最好的超参数。

随机搜索是一种可以替代网格搜索的方法，它编程简单、使用方便、能更快收敛到超参数的良好取值。

- 首先为每个超参数定义一个边缘分布，如伯努利分布（对应着二元超参数）或者对数尺度上的均匀分布（对应着正实值超参数）。
- 然后假设超参数之间相互独立，从各分布中抽样出一组超参数。
- 使用这组超参数训练模型。
- 经过多次抽样 -> 训练过程，挑选验证集误差最小的超参数作为最好的超参数。

随机搜索的优点：

- 不需要离散化超参数的值，也不需要限定超参数的取值范围。这允许我们在一个更大的集合上进行搜索。
- 当某些超参数对于性能没有显著影响时，随机搜索相比于网格搜索指数级地高效，它能更快的减小验证集误差。

###### 调正原则

1. 通常先对超参数进行粗调，然后在粗调中表现良好的超参数区域进行精调。
2. 超参数随机搜索，并不意味着是在有效范围内随机均匀取值。需要选择合适的缩放来进行随机选取。

##### PAC学习理论

一个 PAC 可学习的算法是指该学习算法能够在多项式时间内从合理数量的训练数据中学习到一个近似正确的$f(x)$。
$$
P\left(\left(\mathcal{R}(f)-\mathcal{R}_{\mathcal{D}}^{e m p}(f)\right) \leq \epsilon\right) \geq 1-\delta
$$
其中$ϵ,δ $是和样本数量$n$、假设空间$F$相关的变量。如果固定$ϵ,δ$，可以反过来计算出样本复杂度为
$$
n(\epsilon, \delta) \geq \frac{1}{2 \epsilon^{2}}\left(\ln |\mathcal{F}|+\ln \frac{2}{\delta}\right)
$$
其中$|F|$为假设空间的大小。

