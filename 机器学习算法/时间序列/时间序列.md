#### 时间序列

###### 简介



三类时间预测模型:假设我们需要预测夏天某一个区域下一个小时的用电需求,一个最简单的带有预测变量的模型的形式为:

- $ED = f(current temperature,strength of economy,\cdots,error)$该定义中关系的定义较为明确,也较易解释,所以我们称此模型为解释模型.
- $ED_{t+1} = f(ED_t,ED_{t-1},ED_{t-2},...,error)$,其中$t$表示当前时间,$t+1$表示下一时间...... 此处下一时刻的预测完全依赖于历史上的单变量的数据,不依赖于其他的变量.
- $ED_{t+1} = f(ED_t,current temperature,\cdots, error)$,此类模型则被称为是动态回归模型。

三类时间预测模型的选择: 解释模型是首选,因为它融入了大量的信息,而不仅仅是需要预测的历史变量的信息；当系统无法解释时或者即使可以解释但是内在关系却极其复杂较难刻画,同时我们较为关心下一步会发生什么,而不是为什么它会发生,该时刻可以考虑第二种模型或者第三种模型.



时间序列四种因素有两种组合方式。

1.四种因素相互独立，即时间序列是由四种因素直接叠加而形成的，可用加法模型表示：

Y=T+S+C+I

2.四种因素相互影响，即时间序列是综合四种因素而形成的，可用乘法模型表示：

Y=T×S×C×I，通常遇到的时间序列都是乘法模型。其中，原始时间序列值和长期趋势可用绝对数表示，季节变动、循环变动和不规则变动则用相对数（通常是变动百分比）表示。

混合模型就是公式中既有加号也有乘号。

如果时间序列图的趋势随着时间的推移，序列的季节波动变得越来越大，则建议使用乘法模型；如果序列的季节波动能够基本维持恒定，则建议使用加法模型。

###### **简单时序预测**

```python
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.metrics import mean_squared_error
from math import sqrt

#Importing data
df = pd.read_csv('../../data/international-airline-passengers.csv')
df.columns = ['ds','count']
df = df.dropna()
df.Timestamp = pd.to_datetime(df.ds,format='%Y-%m') 
df.index = df.Timestamp 

#Creating train and test set 
train=df[0:100] 
test=df[100:]

dd= np.asarray(train['count'])
y_hat = test.copy()
y_hat['naive'] = dd[len(dd)-1]
y_hat_avg['avg_forecast'] = train['count'].mean()
y_hat_avg['moving_avg_forecast'] = train['count'].rolling(14).mean().iloc[-1]

from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt
fit2=SimpleExpSmoothing(np.asarray(train['count'])).fit(smoothing_level=0.6,optimized=False)
y_hat_avg['SES'] = fit2.forecast(len(test))

import statsmodels.api as sm
sm.tsa.seasonal_decompose(train['count']).plot()
result = sm.tsa.stattools.adfuller(train['count'])
plt.show()
y_hat_avg = test.copy()
fit1 = Holt(np.asarray(train['count'])).fit(smoothing_level = 0.3, smoothing_slope = 0.1)
y_hat_avg['Holt_linear'] = fit1.forecast(len(test))

y_hat_avg = test.copy()
fit1 = ExponentialSmoothing(np.asarray(train['count']) ,seasonal_periods=7 ,trend='add', seasonal='add',).fit()
y_hat_avg['Holt_Winter'] = fit1.forecast(len(test))

rms = sqrt(mean_squared_error(test['count'], y_hat['naive']))
```



###### `ARIMA`模型预测

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Importing data
df = pd.read_csv('../data/international-airline-passengers.csv')

df.columns = ['ds','count']
df = df.dropna()
df.Timestamp = pd.to_datetime(df.ds,format='%Y-%m')
df.index = df.Timestamp

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
data = train['count'].values
plot_acf(data)
plot_pacf(data)
plt.show()

from statsmodels.tsa.stattools import adfuller
print("原始序列的检验结果为", adfuller(data))
data = pd.DataFrame(data)
D_data = data.diff().dropna()
print("差分序列的ADF 检验结果为", adfuller(D_data[0]))
D_data = D_data.diff().dropna()
plt.plot(D_data)
plt.show()
plot_acf(D_data)    #画出自相关图
plot_pacf(D_data)   #画出偏相关图
print("差分序列的ADF 检验结果为", adfuller(D_data[0]))

from statsmodels.stats.diagnostic import acorr_ljungbox
print("差分序列的白噪声检验结果：" , acorr_ljungbox(D_data, lags= 1))

from statsmodels.tsa.arima_model import ARIMA
pmax = int(len(D_data) / 10)
qmax = int(len(D_data) / 10)
bic_matrix = []
for p in range(pmax +1):
    temp= []
    for q in range(qmax+1):
        try:
            temp.append(ARIMA(D_data[0], (p, 2, q)).fit().bic)
        except:
            pass
            #temp.append(None)
        bic_matrix.append(temp)

bic_matrix = pd.DataFrame(bic_matrix)
p,q = bic_matrix.stack().idxmin()
print("BIC 最小的p值 和 q 值：%s,%s" %(p,q))

model = ARIMA(D_data[0], (0,2,1)).fit()
pred = model.forecast(20)[2][:,1]
print(pred)
plt.plot(test['count'].values, label='test')
plt.plot(pred, label='pred')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error
from math import sqrt
rms = sqrt(mean_squared_error(test['count'].values, pred))
print("RESM:", rms)

tes = list(train['count'].values) + list(test['count'].values)
pre = list(train['count'].values) + list(pred)
plt.plot(tes, label='test')
plt.plot(pre, label='pred')
plt.legend()
plt.show()
```

##### 多维时间序列

多元时间序列分析一般可以用两种方法来进行预测：

**第一种方法**是按照传统机器学习流程提取特征，选取可能影响预测值的`features`，将这些`features`引入模型，应用机器学习的分类/回归模型来进行预测。为提取`features`，机器学习方法需要多个维度的数据，预测精度较高，建立的模型较为复杂，但是模型往往不够通用，针对不同应用场景需要重新提取`features`，建立模型。 在特征提取方面，与非时序的数据不同，我们可以用一些通用的**时序特征衍生方法**，包括：**序列特征**、**基于小波变换的时域**和**频域特征**、**基于多尺度滑动窗口的统计特征**（最大值、最小值、均值、中位数、标准差、偏度、峰度、变异系数）、**基于差分的特征**（一阶、二阶甚至更高阶）、**比值特征**（各类特征与当前值的比值）等。 

 **第二种方法**就是直接利用序列建模的分析方法，利用序列前面的窗口数据来预测序列后几个窗口的数据，一般无需构建时序衍生特征，比如典型的`RNN`、`LSTM`、`GRU`等，复杂点的模型一般会结合序列建模的常用方法，比如`seq2seq`、`Attention`等 

 监督学习往往需要针对样本数据进行特征和标签的划分，对于单维、多维时间序列以及时序图，其划分的方法都比较类似，具体可以分析如下几种情况： 

![](../picture/1/127.png)

one to one
不论是单维、多维还是时序图，都是把t时刻的数据作为特征，t+1的数据作
为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。

one to many:
不论是单维、多维还是时序图，都是把t时刻的数据作为特征，t+K的数据作为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。

many to one:
不论是单维、多维还是时序图，都是把t-k时刻的数据作为特征，t时刻的数据作为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。

many to many:
不论是单维、多维还是时序图，都是把t-k时刻的数据作为特征，t+K的数据作为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。





