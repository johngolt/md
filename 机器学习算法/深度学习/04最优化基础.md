#### 神经网络最优化挑战

##### 病态黑塞矩阵

病态的黑塞矩阵$\mathbf{H}$是凸优化或者其他形式优化中普遍存在的问题。

- 在神经网络训练过程中，如果$\mathbf{H}$是病态的，则随机梯度下降会卡在某些地方，此时即使很小的更新步长也会增加代价函数。
- 当黑塞矩阵是病态时，牛顿法是一个很好的解决方案。但是牛顿法并不适用于神经网络，需要对它进行较大改动才能用于神经网络。

将$f(\vec{\mathbf{x}})$在$\vec{\mathbf{x}}$处泰勒展开：
$$
f(\vec{\mathbf{x}}) \approx f\left(\vec{\mathbf{x}}_{0}\right)+\left(\vec{\mathbf{x}}-\vec{\mathbf{x}}_{0}\right)^{T} \vec{\mathbf{g}}+\frac{1}{2}\left(\vec{\mathbf{x}}-\vec{\mathbf{x}}_{0}\right)^{T} \mathbf{H}\left(\vec{\mathbf{x}}-\vec{\mathbf{x}}_{0}\right)
$$
根据梯度下降法：$\vec{\mathbf{x}}^{\prime}=\vec{\mathbf{x}}-\epsilon \nabla_{\vec{\mathbf{x}}} f(\vec{\mathbf{x}})$。应用在点$\vec{\mathbf{x}}_0$，有：
$$
f\left(\vec{\mathbf{x}}_{0}-\epsilon \vec{\mathbf{g}}\right) \approx f\left(\vec{\mathbf{x}}_{0}\right)-\epsilon \vec{\mathbf{g}}^{T} \vec{\mathbf{g}}+\frac{1}{2} \epsilon^{2} \vec{\mathbf{g}}^{T} \mathbf{H} \vec{\mathbf{g}}
$$
因此沿着负梯度的方向，步长$-\epsilon \vec{\mathrm{g}}$将导致代价函数$f$增加：$-\epsilon \vec{\mathrm{g}}^{T} \vec{\mathrm{g}}+\frac{1}{2} \epsilon^{2} \vec{\mathrm{g}}^{T} \mathbf{H} \vec{\mathrm{g}}$。当$\frac{\epsilon}{2} \vec{g}^{T} \mathbf{H} \vec{g}>\vec{g}^{T} \vec{\mathbf{g}}$时，黑塞矩阵的病态会成为问题。此时沿着负梯度的方向，代价函数值反而在增长。

##### 局部极小值

如果局部极小解和全局极小解相差很大时，此时多个局部极小解会带来很大隐患。它将给基于梯度的优化算法带来很大的问题。

目前很多人将神经网络优化中的所有困难都归结于局部极小值。有一种方案是排除局部极小值导致的困难，绘制梯度范数$\vec{\mathrm{g}}^{T} \vec{\mathrm{g}}$随着时间的变化：

- 如果梯度范数没有缩小到一个很小的值，则问题的原因既不是局部极小值引起的，也不是其他形式的临界点引起的。
- 如果梯度范数缩小到一个很小的值，则问题的原因可能是局部极小值引起的，也可能是其他原因引起的。

神经网络训练中，通常不关注代价函数的精确全局极小值，而是关心将代价函数值下降到足够小，从而获得一个很好的泛化误差。

##### 鞍点

鞍点是另一类梯度为零的点。鞍点附近的某些点的函数值比鞍点处的值更大，鞍点附近的另一些点的函数值比鞍点处的值更小。通常在低维空间中，局部极小值很普遍；在高维空间中，局部极小值很少见，鞍点更常见。

鞍点对于训练算法的影响：对于只使用了梯度的一阶优化算法而言：情况不明。对于牛顿法而言，鞍点是个大问题。如果不做任何修改，则牛顿法会主动跳入一个鞍点。

也可能出现一个恒值的、平坦的宽区域：在这个区域中，梯度和黑塞矩阵都为零

##### 悬崖

多层神经网络通常有像悬崖一样的区域，悬崖是指代价函数斜率较大的区域。产生悬崖的原因：由于几个较大的权重相乘，导致求导的时候，其梯度异常巨大。在`RNN`网络的代价函数中悬崖结构很常见。

悬崖的影响：在梯度更新时，如果遇到悬崖，则会导致参数更新的步长非常大，从而跨了非常大的一步，使得参数弹射的非常远。这样可能会使得已经完成的大量优化工作无效。因为当弹射非常远时，可能横跨了参数空间的很多个区域而进入到另一个区域。这样已经探索的参数区域就被放弃了。

解决悬崖问题的方案：使用梯度截断策略。梯度下降法只是指明了参数更新的方向，但是未指明最佳步长。当常规的梯度下降算法建议更新一大步时，梯度截断会干涉并缩减步长，从而使其基本上贴着悬崖来更新。

##### 长期依赖、

当计算图非常深时，容易产生另一种优化困难：长期依赖。假设计算图中包含一条重复地、与矩阵$\mathbf{W}$相乘的路径。经过$t$步，则相当于与$\mathbf{W}^t$相乘。在第$i$步有：$\vec{\mathbf{h}}_{t}=\mathbf{W}^{t-i} \vec{\mathbf{h}}_{i}$。根据反向传播原理，有： 
$$
\nabla_{\vec{\mathrm{h}}_{\mathrm{i}}} J=\left(\frac{\partial \vec{\mathrm{h}}_{t}}{\partial \vec{\mathrm{h}}_{\mathrm{i}}}\right)^{T} \nabla_{\vec{\mathrm{h}}_{t}} J=\left(\mathbf{W}^{t-i}\right)^{T}\nabla_{\vec{\mathrm{h}}_{\mathrm{t}}} J
$$
考虑到权重$\mathbf{W}$参与到每个时间步的计算，因此有：
$$
\nabla_{\mathbf{W}}=\sum_{i=1}^{t} \frac{\partial J}{\partial \vec{\mathbf{h}}_{i}} \vec{\mathbf{h}}_{i-1}^{T}=\sum_{i=1}^{t}\left(\mathbf{W}^{t-i}\right)^{T}\left(\nabla_{\vec{\mathbf{h}}_{i}} J\right) \vec{\mathbf{h}}_{i-1}^{T}
$$
其中记$\vec{\mathbf{x}}=\vec{\mathbf{h}}_{0}$。假设矩阵$\left(\nabla_{\vec{\mathbf{h}}_{\mathrm{t}}} J\right) \vec{\mathbf{x}}^{T}=c \mathbf{I}$，则有：
$$
\nabla_{\mathbf{W}}=\sum_{i=1}^{t}\left(\mathbf{W}^{t-i}\right)^{T}\left(\nabla_{\vec{\mathbf{h}}_{t}} J\right)\left(\mathbf{W}^{i-1} \vec{\mathbf{x}}\right)^{T}=\sum_{i=1}^{t} c\left(\mathbf{W}^{t-1}\right)^{T}=c \times t \times\left(\mathbf{W}^{t-1}\right)^{T}
$$
假设$\mathbf{W}$有特征值分解$\mathbf{W}=\mathbf{V} \Lambda \mathbf{V}^{-1}$，则：$\mathbf{W}^{t-1}=\mathbf{V} \Lambda^{t-1} \mathbf{V}^{-1}$。考虑特征值$\lambda_i$，当它不在 1 附近时：如果量级大于 1，$\lambda_i^t$非常大，这称作梯度爆炸问题。如果量级小于 1， $\lambda_i^t$非常小，这称作梯度消失问题。梯度消失使得学习难以进行，此时学习的推进会非常缓慢。

循环网络在每个时间步上使用相同的矩阵$\mathbf{W}$，因此非常容易产生梯度爆炸和梯度消失问题。前馈神经网络并没有在每一层使用相同的矩阵$\mathbf{W}$，因此即使是非常深层的前馈神经网络也能很大程度上避免梯度爆炸和梯度消失问题。

对于梯度爆炸，可以通过梯度裁剪来缓解：限定梯度的范数的上限。对于梯度消失，不能够简单的通过放大来解决。因为有两个问题：

- 当梯度很小的时候，无法分辨它是梯度消失问题，还是因为抵达了极小值点。
- 当梯度很小的时候，噪音对梯度的影响太大。获得的梯度很可能由于噪音的影响，导致它的方向是随机的。此时如果放大梯度，则无法确保此时的方向就是代价函数下降的方向。而对于梯度爆炸，如果缩小梯度，仍然可以保证此时的方向就是代价函数下降的方向。

##### 非精确梯度

大多数优化算法都假设知道精确的梯度或者`Hessian`矩阵，实际中这些量都有躁扰，甚至是有偏的估计。如：`mini-batch`随机梯度下降中，用一个`batch` 的梯度来估计整体的梯度。各种神经网络优化算法的设计都考虑到了梯度估计的不精确。

##### 局部和全局结构的弱对应

局部优秀，全局不良。局部优秀：跨过了鞍点、爬过了悬崖、克服了梯度消失，最终到达局部极小值点。全局不良：并未到达目标函数全局比较小的值所在的区域。

在局部结构中执行梯度下降的问题：

- 局部梯度下降或许能找出一条解路径，但是该路径可能包含了很多次梯度更新，遵循该路径会带来很高的计算代价。
- 如果目标函数没有任何鞍点、极值点，而是具有一个宽而平坦的区域。此时，若要寻求一个精确的临界点，则局部梯度下降无法给出解路径。这意味着算法难以收敛。
- 局部梯度下降可能太过贪心，使得训练虽然朝着梯度下降的方向移动，但是远离了真正的解

现有的很多研究方法在求解局部结构复杂的最优化问题时，解决方案为：寻求良好的初始化点，而不再是寻求良好的全局参数更新算法。

#### `mini-batch`

使用小批量样本来估计梯度的原因：

- 使用更多样本来估计梯度的方法的收益是低于线性的。
- 如果能够快速计算出梯度的估计值，则大多数优化算法会更快收敛。
- 训练集存在冗余。实践中可能发现：大量样本都对梯度做出了非常相似的贡献。

使用整个训练集的优化算法被称作`batch`梯度算法。每次只使用单个样本的优化算法被称作随机`stochastic`算法。大多数深度学习的优化算法介于两者之间：使用一个以上、又不是采用全部的训练样本，称作`mini-batch`或者`mini-batch`随机算法。

当使用小批量样本来估计梯度时，由于估计的梯度往往会偏离真实的梯度，这可以视作在学习过程中加入了噪声扰动。这种扰动会带来一些正则化效果。

`mini-batch`的大小由下列因素决定：

- 不能太大。更大的`batch`会使得训练更快，但是可能导致泛化能力下降。
  - 训练更快是因为更大的`batch size` 只需要更少的迭代步数就可以使得训练误差收敛。更大的`batch size` 可以利用大规模数据并行的优势。
  - 泛化能力下降是因为更大的`batch size` 计算的梯度估计更精确，它带来更小的梯度噪声。此时噪声的力量太小，不足以将参数推出一个尖锐极小值的吸引区域。解决方案为：提高学习率，从而放大梯度噪声的贡献。
- 不能太小。因为对于多核架构来讲，太小的`batch`并不会相应地减少计算时间。
- 如果`batch`中所有样本可以并行地预处理，则内存消耗和`batch`大小成正比。
- 在有些硬件上，特定大小的效果更好。在使用`GPU`时，通常使用 2 的幂作为`batch`大小。

通常仅仅基于梯度$\vec{\mathbf{g}}$​的更新方法相对更稳定，它能够处理更小的`batch`。如果使用了黑塞矩阵$\mathbf{H}$​通常需要更大的 `batch`。

##### 随机抽样

`mini-batch`是随机抽样的也非常重要。从一组样本中计算出梯度期望的无偏估计要求：组内的样本是独立的。另外，也希望两个连续的梯度估计也是相互独立的。这要求：两个连续的`mini-batch`样本集合也应该是彼此独立的。

实际应用中，采集的数据样本很可能出现这样的情况：连续的样本之间具有高度相关性。解决方法是：将样本随机混洗之后存储，训练时按照混洗之后的顺序读取。这种打乱顺序不会对`mini-batch`产生严重的影响，不打乱顺序的`mini-batch`才会极大降低算法泛化能力。

#### 基本优化算法

##### 随机梯度下降

从训练集中随机采样$m$个样本$\{\vec{\mathbf{x}}_1,\cdots,\vec{\mathbf{x}}_m\}$构成`mini-batch`，对应的标记为$\{\tilde{y}_1,\cdot,\tilde{y}_m\}$。计算`mini-batch`上的梯度作为训练集的梯度的估计：
$$
\hat{\vec{\mathbf{g}}}\leftarrow\frac{1}{m}\nabla_{\vec{\theta}}\sum_{i=1}^mL(f(\vec{\mathbf{x}}_i;\vec{\theta}),\tilde{y}_i)
$$
更新参数：$\vec{\theta}\leftarrow\vec{\theta}-\epsilon\hat{\vec{\mathbf{g}}}$

在深度学习中，通常的停止条件是：运行指定数量的迭代步或者`epoch`， 或者在验证集上的某个度量不再提升。

`SGD`以及其它的`mini-batch`算法的最重要性质是：每一步参数更新的计算时间不会随着训练样本数量的增加而增加。

- 即使训练样本数量非常庞大时，算法也能收敛。
- 对于足够大的数据集，`SGD`可能在处理整个训练集的所有样本之前就收敛到测试集误差的允许范围之内了

###### 学习率

`SGD`中一个关键参数是学习率。前面介绍的`SGD`算法步骤使用固定的学习率$\epsilon$，实践中有必要随着时间的推移而降低学习率。

使用标准的梯度下降到达极小点时，整个代价函数的真实梯度非常小，甚至为零。由于`SGD` 使用`mini-batch`的梯度作为整体梯度的估计，因此引入了噪源。该噪源并不会在极小值处消失，使得在极小点时，梯度的估计可能会比较大。因此，标准的梯度下降可以使用固定的学习率，而`SGD`必须使用逐渐降低的学习率。

假设在极小点时，梯度的估计值$\hat{\vec{\mathbf{g}}}$由于引入了噪源导致较大：

- 如果采取降低学习率的方法，则步长$\epsilon\hat{\vec{\mathbf{g}}}$会很小，这就会导致参数$\vec{\theta}$在极小点附近宅幅震荡直至收敛。
- 如果没有采取降低学习率的方法，则步长$\epsilon\hat{\vec{\mathbf{g}}}$会很大，这会导致参数$\vec{\theta}$在极小点附近宽幅震荡而且很难收敛。

第$k$步的学习率记做$\epsilon_k$，则对于学习率，保证`SGD`收敛的一个充分条件是：$\sum_{k=1}^{\infin}\epsilon_k=\infin$，且$\sum_{k=1}^{\infin}\epsilon_k^2<\infin$。在实践中，学习率一般线性衰减到第$\tau$次迭代，之后由于学习率足够小则可以保持不变：
$$
\epsilon_k=\left\{\begin{array}{ll}(1-\frac{k}{\tau})\epsilon_0+\frac{k}{\tau}\epsilon_{\tau}&,0\le k\le\tau\\
\epsilon_{\tau}&,k\ge\tau\end{array}\right.
$$
其中：$\tau$是预先指定的，如 `1000`，$\epsilon_0,\epsilon_{\tau}$为常数。学习率不能够衰减到零，因为一旦$\epsilon$衰减到零，则很难说明模型收敛是因为学习率为零，还是梯度为零。

 $\epsilon_0,\epsilon_{\tau},\tau$可以通过试验来选取。

- $\epsilon_{\tau}$通常被设置为$\epsilon_{0}$的大约 `1%`， 即降低到足够低的位置。
- $\tau$决定了学习率衰减的速度，经过多少个迭代步，使得学习率降低到足够低的位置。
- $\epsilon_{0}$被称作初始学习率，它的选择是个重要因素：
  - 如果太大，则学习曲线将会剧烈震荡，代价函数值会明显增加。
  - 如果太小，则学习过程会非常缓慢，学习可能会卡在一个相当高的代价函数值上。
  - 通常最好检测最早的几轮迭代，使用一个高于此时效果最佳学习率的一个学习率，但是又不能太高以至于导致严重的不稳定性。

##### 动量方法

动量方法积累了之前梯度的指数级衰减的移动平均，然后继续沿着该方向移动。

- 它是一种移动平均，权重是指数级衰减的：近期的权重较大，远期的权重很小。
- 动量方法取这些加权梯度的均值，根据该均值的方向决定参数的更新方向。

从训练集中随机采样$m$个样本$\{\vec{\mathbf{x}}_1,\cdots,\vec{\mathbf{x}}_m\}$构成`mini-batch`，对应的标记为$\{\tilde{y}_1,\cdot,\tilde{y}_m\}$。计算`mini-batch`上的梯度作为训练集的梯度的估计：
$$
\hat{\vec{\mathbf{g}}}\leftarrow\frac{1}{m}\nabla_{\vec{\theta}}\sum_{i=1}^mL(f(\vec{\mathbf{x}}_i;\vec{\theta}),\tilde{y}_i)
$$
更新速度：$\vec{\mathbf{v}}\leftarrow\alpha\vec{\mathbf{v}}-\epsilon\hat{\vec{\mathbf{g}}}$

更新参数：$\vec{\theta}\leftarrow\vec{\theta}+\vec{\mathbf{v}}$

###### 衰退因子

实践中，$\alpha$取值一般为 0.5、0.9、0.99。

- 和学习率一样，$\alpha$也可以随着时间变化。通常初始时采用一个较小的值，后面慢慢变大。
- 随着时间推移，改变$\alpha$没有收缩$\epsilon$更重要。因为只要$0<\alpha<1$，则最终$\lim_{t\rightarrow+\infin}\alpha^t=0$。因此最终参数更新主导的还是$\epsilon\hat{\vec{\mathbf{g}}}$。

###### $\text{Nesterov}$动量

`Nesterov`动量是动量方法的变种。区别在于计算`mini-batch`的梯度时，采用更新后的参数$\vec{\theta}+\alpha \vec{\mathbf{v}}$。它可以视作向标准动量方法中添加了一个校正因子：
$$
\begin{aligned} \vec{\mathbf{v}} \leftarrow \alpha \vec{\mathbf{v}} &-\epsilon \nabla_{\vec{\theta}} J(\vec{\theta}+\alpha \vec{\mathbf{v}}) \\ \vec{\theta} & \leftarrow \vec{\theta}+\vec{\mathbf{v}} \end{aligned}
$$

##### 自适应学习率算法

假设代价函数高度敏感于参数空间中的某些方向，则优化算法最好针对不同的参数设置不同的学习率。

- 代价函数变化明显的参数方向：学习率较小，使得更新的步长较小。
- 代价函数变化不明显的参数方向：学习率较大，使得更新的步长较大。

###### $\text{AdaGrad}$

`AdaGrad`算法会独立设置参数空间每个轴方向上的学习率。

- 如果代价函数在某个方向上具有较大的偏导数，则这个方向上的学习率会相应降低。
- 如果代价函数在某个方向上具有较小的偏导数，则这个方向上的学习率会相应提高

`AdaGrad`算法的思想是：参数空间每个方向的学习率反比于某个值的平方根。这个值就是该方向上梯度分量的所有历史平方值之和。
$$
\begin{array}{c}{\vec{\mathbf{r}} \leftarrow \vec{\mathbf{r}}+\hat{\vec{\mathbf{g}}} \odot \hat{\vec{\mathbf{g}}}} \\ {\vec{\theta} \leftarrow \vec{\theta}-\frac{\epsilon}{\sqrt{\mathbf{r}}} \odot \hat{\vec{\mathbf{g}}}}\end{array}
$$
其中$\odot$表示两个向量的逐元素的相乘。

从训练集中随机采样$m$个样本$\{\vec{\mathbf{x}}_1,\cdots,\vec{\mathbf{x}}_m\}$构成`mini-batch`，对应的标记为$\{\tilde{y}_1,\cdot,\tilde{y}_m\}$。计算`mini-batch`上的梯度作为训练集的梯度的估计：
$$
\hat{\vec{\mathbf{g}}}\leftarrow\frac{1}{m}\nabla_{\vec{\theta}}\sum_{i=1}^mL(f(\vec{\mathbf{x}}_i;\vec{\theta}),\tilde{y}_i)
$$
累计平方梯度：${\vec{\mathbf{r}} \leftarrow \vec{\mathbf{r}}+\hat{\vec{\mathbf{g}}} \odot \hat{\vec{\mathbf{g}}}} $

计算更新逐元素：$\Delta\vec{\theta}\leftarrow-\frac{\epsilon}{\delta+\sqrt{\vec{\mathbf{r}}}} \odot \hat{\vec{\mathbf{g}}}$

更新参数：$\vec{\theta}\leftarrow\vec{\theta}+\Delta\vec{\theta}$

由于随迭代次数的增加，$r_i$的值也会增加，因此$\frac{\epsilon}{\delta+\sqrt{\vec{\mathbf{r}}}}$随着迭代的推进而降低。这起到了一个学习率衰减的效果。

###### $\text{RMSProp}$

`RMSProp`是`AdaGrad`的一个修改将梯度累计策略修改为指数加权的移动平均。
$$
\begin{aligned} \vec{\mathbf{r}} & \leftarrow \rho \vec{\mathbf{r}}+(1-\rho) \hat{\vec{\mathbf{g}}} \odot \hat{\vec{\mathbf{g}}} \\ \vec{\theta} & \leftarrow \vec{\theta}-\frac{\epsilon}{\sqrt{\vec{\mathbf{r}}}} \odot \hat{\vec{\mathbf{g}}} \end{aligned}
$$
其中$\rho$为衰减速率，它决定了指数加权移动平均的有效长度。

从训练集中随机采样$m$个样本$\{\vec{\mathbf{x}}_1,\cdots,\vec{\mathbf{x}}_m\}$构成`mini-batch`，对应的标记为$\{\tilde{y}_1,\cdot,\tilde{y}_m\}$。计算`mini-batch`上的梯度作为训练集的梯度的估计：
$$
\hat{\vec{\mathbf{g}}}\leftarrow\frac{1}{m}\nabla_{\vec{\theta}}\sum_{i=1}^mL(f(\vec{\mathbf{x}}_i;\vec{\theta}),\tilde{y}_i)
$$
累计平方梯度：${\vec{\mathbf{r}} \leftarrow \rho \vec{\mathbf{r}}+(1-\rho) \hat{\vec{\mathbf{g}}} \odot \hat{\vec{\mathbf{g}}}} $

计算更新逐元素：$\Delta\vec{\theta}\leftarrow-\frac{\epsilon}{\delta+\sqrt{\vec{\mathbf{r}}}} \odot \hat{\vec{\mathbf{g}}}$

更新参数：$\vec{\theta}\leftarrow\vec{\theta}+\Delta\vec{\theta}$

###### 算法性质

假设迭代过程中，梯度刚好是固定的某个量，令$\vec{\mathbf{c}}=\hat{\vec{\mathbf{g}}} \odot \hat{\vec{\mathbf{g}}}$。对于某个方向，假设其分量为$c=g^2$。对于`RMSProp` 算法：根据等比数列求和公式，该方向的比例因子为：$r=c(1-\rho^{\tau})$，其中$\tau$为迭代次数。该方向的学习率为：
$$
\overline{\epsilon}=\frac{\epsilon}{\delta+\sqrt{c(1-\rho^{\tau})}}
$$
随着$\tau$​的增大，$\overline{\epsilon}$​​会减小。

当某个方向的导数$g$相对于$\delta$较大时，更新步长为（考虑到$r=g^2(1-\rho^{\tau})$）：
$$
\frac{\epsilon}{\delta+\sqrt{r}}\sim\frac{\epsilon}{\sqrt{1-\rho^{\tau}}}
$$
它与梯度无关，只与迭代次数$\tau$有关。随着$\tau$增大，趋向于$\epsilon$。当导数$g$非常小以至于和$\delta$相差无几时，此时更新步长与梯度有关。

对于`AdaGrad`算法的情况：根据等差数列的求和公式，该方向的比例因子为：$r=\tau c$，其中$\tau$为迭代次数。该方向的学习率为：
$$
\overline{\epsilon}=\frac{\epsilon}{\delta+\sqrt{\tau c}}
$$
随着$\tau$的增大，$\overline{\epsilon}$会减小。$r$在$\tau$逐渐增大时，从$c$增加到$+\infin$。从而使$\overline{\epsilon}$趋于0。当该方向的梯度对于$\delta$较大时，更新步长为：
$$
\frac{\epsilon}{\delta+\sqrt{r}}\sim\frac{\epsilon}{\sqrt{\tau}}
$$
它与梯度无关，只与迭代次数$\tau$有关。

###### `RMSProp`动量算法

从训练集中随机采样$m$个样本$\{\vec{\mathbf{x}}_1,\cdots,\vec{\mathbf{x}}_m\}$构成`mini-batch`，对应的标记为$\{\tilde{y}_1,\cdot,\tilde{y}_m\}$。

计算临时更新：$\tilde{\vec{\theta}}\leftarrow\vec{\theta}+\alpha\vec{\mathbf{v}}$

计算`mini-batch`上的梯度作为训练集的梯度的估计
$$
\hat{\vec{\mathbf{g}}}\leftarrow\frac{1}{m}\nabla_{\tilde{\vec{\theta}}}\sum_{i=1}^mL(f(\vec{\mathbf{x}}_i;\tilde{\vec{\theta}}),\tilde{y}_i)
$$
累计平方梯度： ${\vec{\mathbf{r}} \leftarrow \rho \vec{\mathbf{r}}+(1-\rho) \hat{\vec{\mathbf{g}}} \odot \hat{\vec{\mathbf{g}}}} $

计算速度更新（逐元素）：$\vec{\mathbf{v}}\leftarrow\alpha\vec{\mathbf{v}}-\frac{\epsilon}{\sqrt{\vec{\mathbf{r}}}} \odot \hat{\vec{\mathbf{g}}}$

更新参数：$\vec{\theta}\leftarrow\vec{\theta}+\vec{\mathbf{v}}$

##### $\text{Adam}$

`Adam`来自于`Adaptive moments`，它是另一种引入了动量的`RMSProp`算法。

初始化一阶和二阶矩变量$\vec{\mathbf{s}}=\vec{\mathbf{0}}, \vec{\mathbf{r}}=\vec{\mathbf{0}}$

从训练集中随机采样$m$个样本$\{\vec{\mathbf{x}}_1,\cdots,\vec{\mathbf{x}}_m\}$构成`mini-batch`，对应的标记为$\{\tilde{y}_1,\cdot,\tilde{y}_m\}$。计算`mini-batch`上的梯度作为训练集的梯度的估计：
$$
\hat{\vec{\mathbf{g}}}\leftarrow\frac{1}{m}\nabla_{\vec{\theta}}\sum_{i=1}^mL(f(\vec{\mathbf{x}}_i;\vec{\theta}),\tilde{y}_i)
$$
$t\leftarrow t+1$。更新有偏一阶矩估计：$\vec{\mathbf{s}}\leftarrow\rho_1\vec{\mathbf{s}}+(1-\rho_1)\hat{\vec{\mathbf{g}}}$

更新有偏二阶矩估计：$\vec{\mathbf{r}}\leftarrow\rho_2\vec{\mathbf{r}}+(1-\rho_2)\hat{\vec{\mathbf{g}}}\odot\hat{\vec{\mathbf{g}}}$

修正一阶矩的偏差：$\hat{\vec{\mathbf{s}}}\leftarrow\frac{\vec{\mathbf{s}}}{1-\rho_1^t}$

修正二阶矩的偏差：$\hat{\vec{\mathbf{r}}}\leftarrow\frac{\vec{\mathbf{r}}}{1-\rho_2^t}$

计算更新（逐元素）：$\Delta\vec{\theta}\leftarrow-\frac{\epsilon}{\delta+\sqrt{\hat{\vec{\mathbf{r}}}}} \odot\hat{\vec{\mathbf{s}}}$

更新参数：$\vec{\theta}\leftarrow\vec{\theta}+\Delta\vec{\theta}$

`RMSProp` 算法中，通过累计平方梯度（采用指数移动平均）来修正学习率。而 `Adam`算法中，不仅采用同样的方式来修正学习率，还通过累计梯度（采用指数移动平均） 来修正梯度。

实践证明，虽然在训练早期`Adam` 具有很好的收敛速度，但是最终模型的泛化能力并不如使用朴素的`SGD` 训练得到的模型好：`Adam` 训练的模型得到的测试集误差会更大。

- 其主要原因可能是：训练后期，`Adam` 的更新步长过小。
- 一种改进策略为：在训练的初期使用`Adam` 来加速训练，并在合适的时期切换为`SGD` 来追求更好的泛化性能。

##### 贪心监督预训练

贪心监督预训练的一个例子如下图所示：

- 先训练一个最简单的架构，只有一个隐层。
- 然后将第一个隐层的输出$\vec{\mathbf{h}}_1$作为输入，再添加一个隐层，来训练。
- 然后将第二个隐层的输出作为输入，再添加一个隐层，训练。在这个过程中，前一步训练的最末尾的隐层的输出作为后一步训练的输入。
- 为了进一步优化，最后可以联合微调所有层。

![](../../picture/1/424.png)

#### 参数初始化

深度学习中，大多数算法都受到初始值的影响。初始值能够决定：算法最终是否收敛、以及收敛时的收敛速度有多快、以及收敛到一个代价函数较高还是较低的值。深度学习中，初始值也会影响泛化误差，而不仅仅是目标函数的最优化。

##### 权重初始化

通常权重的初始化是从高斯分布或者均匀分布中挑选出来的值。初始权重的大小很重要，下面的因素决定了权重的初始值的大小：

- 更大的初始权重具有更强的破坏对称性的作用，有助于避免冗余的单元。
- 更大的初始权重也有助于避免梯度消失。
- 更大的初始权重也容易产生梯度爆炸。
- 循环神经网络中，更大的初始权重可能导致混沌现象：对于输入中的很小的扰动非常敏感，从而导致确定性算法给出了随机性结果。

有些启发式方法可用于选择权重的初始化大小。假设有$m$个输入，$n$个输出的全连接层。常见的做法是建议使用均匀分布的随机初始化：
$$
\mathbf{W}_{i,j}\sim U\left(-\sqrt{\frac{1}{m}},\sqrt{\frac{1}{m}}\right)
$$
建议使用均匀分布的随机初始化：
$$
\mathbf{W}_{i,j}\sim U\left(-\sqrt{\frac{6}{m+n}},\sqrt{\frac{6}{m+n}}\right)
$$
上述启发式初始化权重的策略往往效果不佳。有三个可能的原因：

- 可能使用了错误的标准：约束网络中信号的范数可能并不会带来什么好处。
- 初始化时强加给参数的性质可能在学习开始之后无法保持。
- 可能提高了优化速度，但意外地增大了泛化误差。

##### 偏置初始化

偏置的初始化通常更容易。大多数情况下，可以设置偏置初始化为零。有时可以设置偏置初始化为非零，这发生在下面的三种情况：

- 如果偏置是作为输出单元，则初始化偏置为非零值。
- 有时选择偏置的初始值以免初始化引起激活函数饱和。如：`ReLU` 激活函数的神经元的偏置设置为一个小的正数，从而避免`ReLU` 初始时就位于饱和的区域。
- 有时某个单元作为开关来决定其他单元是使用还是不使用。此时偏置应该非零，从而打开开关。

#### `Normalization`

##### `batch normalization`

深度神经网络训练困难的一个重要原因是：深度神经网络涉及很多层的叠加，而每一层的参数更新会导致上一层的输入数据分布发生变化。这会带来两个问题：

- 下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止。
- 通过层层叠加，高层的输入分布变化会非常剧烈。这就使得高层需要不断去适应底层的参数更新变化。

###### 白化

在机器学习中，如果数据是独立同分布的，则可以简化模型的训练，提升模型的预测能力。所以通常需要对输入数据进行白化`whitening`。 白化主要实现两个目的

- 去除特征之间的相关性，特征之间尽可能的独立。
- 使得所有特征都具有相同的均值和方差。特征之间尽可能的同分布。

理论上可以对神经网络的每一层的输入执行白化来解决输入数据分布的问题。但是有两个困难：白化操作代价高昂，算法复杂度太大。白化操作不可微，这样反向传播算法无法进行。因此`batch normalization` 就退而求其次，执行简化版的白化：将神经网络的每一层的输入的分布限定其均值和方差。

###### 深层网络的参数更新

假设有一个深层神经网络，一共有$l$层，每层只有一个单元，且每个隐层不使用激励函数。则输出为：$\hat{y}=x w_{1} w_{2} \cdots w_{l}$。其中$w_i$为第$i$层的权重。第$i$层的输出为：$h^{i}=h^{i-1} w_{i}$。

令$\vec{\mathbf{g}}=\left(g_{1}, g_{2}, \cdots, g_{l}\right)^{T}=\nabla_{\vec{\mathbf{w}}} \hat{y}$，其中：$g_{i}=\frac{\partial \hat{y}}{w_{i}}=x \prod_{j=1, j \neq i}^{l} w_{j}$。

利用梯度下降法更新参数，则有：$\vec{\mathbf{w}} \leftarrow \vec{\mathbf{w}}-\epsilon \vec{\mathbf{g}}$。如果使用$\hat{y}$的一阶泰勒近似，则有：
$$
f(\vec{\mathbf{w}}-\epsilon \vec{\mathbf{g}})-f(\vec{\mathbf{w}}) \approx-\epsilon \vec{\mathbf{g}}^{T} \vec{\mathbf{g}}
$$
即：$\hat{y}$的值下降了$\epsilon \vec{\mathrm{g}}^{T} \vec{\mathrm{g}}$。因此梯度下降法一定能够降低$\hat{y}$的值。如果直接按多项式乘法展开，则会考虑$\epsilon$的二阶、三阶甚至更高阶的项，有：
$$
\begin{array}{l}{f(\vec{\mathbf{w}}-\epsilon \vec{\mathbf{g}})-f(\vec{\mathbf{w}})=x\left(w_{1}-\epsilon g_{1}\right)\left(w_{2}-\epsilon g_{2}\right) \cdots\left(w_{l}-\epsilon g_{l}\right)-x w_{1} w_{2} \cdots w_{l}} \\ {\quad=-\epsilon x \sum_{i=1}^{l}\left(g_{i} \prod_{j=1, j \neq i}^{l} w_{j}\right)+\epsilon^{2} x \sum_{j=i}^{l}\left(g_{i} g_{j} \prod_{k=1, k \neq i, k \neq j}^{l} w_{k}\right)+\cdots}\end{array}
$$
考虑到$g_{i}=x \prod_{j=1, j \neq i}^{l} w_{j}$，则有：
$$
f(\vec{\mathbf{w}}-\epsilon \vec{\mathrm{g}})-f(\vec{\mathbf{w}})=-\epsilon \vec{\mathrm{g}}^{T} \vec{\mathrm{g}}+\epsilon^{2} x \sum_{i=1}^{l} \sum_{j=i}^{l}\left(g_{i} g_{j} \prod_{k=1, k \neq i, k \neq j}^{l} w_{k}\right)+\cdots
$$
如果$w_i$都比较小，则$\prod_{k=1, k \neq i, k \neq j}^{l} w_{k}$很小，则二阶项可以忽略不计。如果$w_i$都比较大，则该二阶项可能会指数级大。此时很难选择一个合适的学习率，使得$f(\vec{\mathbf{w}}-\epsilon \vec{\mathbf{g}})-f(\vec{\mathbf{w}})<0$。

因此某一层中参数更新的效果会取决于其他所有层。虽然二阶优化算法会利用二阶项的相互作用来解决这个问题，但是还有三阶项甚至更高阶项的影响。

###### $\text{BN}$算法

`batch normalization`解决了多层之间协调更新的问题，它可以应用于网络的任何输入层或者隐层。设$\mathbb{H}=\left\{\vec{\mathbf{h}}_{1}, \vec{\mathbf{h}}_{2}, \cdots, \vec{\mathbf{h}}_{m}\right\}$为神经网络某层的一个`mini-batch` 的输入，$n$为输入的维度。首先计算这个`mini-batch` 输入的均值和每维特征的标准差：
$$
\begin{array}{c}{\vec{\mu}=\frac{1}{m} \sum_{i=1}^{m} \vec{\mathbf{h}}_{i}} \\ {\vec{\sigma}^{2}=\left(\sigma_{1}^{2}, \sigma_{2}^{2}, \cdots, \sigma_{n}^{2}\right)^{T}, \quad \sigma_{j}^{2}=\frac{1}{m} \sum_{i=1}^{m}\left(h_{i, j}-\mu_{j}\right)^{2}}\end{array}
$$
然后对输入进行归一化：
$$
\vec{\mathbf{h}}_{i}^{1}=\frac{\vec{\mathbf{h}}_{i}-\vec{\mu}}{\sqrt{\vec{\sigma}^{2}+\epsilon}}
$$
其中$\frac{1}{\sqrt{\vec{\sigma}^{2}+\epsilon}}$表示逐元素的除法：$h_{i, j}^{1}=\frac{h_{i j}-\mu_{j}}{\sqrt{\sigma_{j}^{2}+\epsilon}}, j=1,2, \cdots, n$。最后执行缩放：
$$
\vec{\mathbf{h}}_{i}^{2}=\vec{\gamma} \odot \vec{\mathbf{h}}_{i}^{1}+\vec{\beta}
$$
其中$\vec{\gamma}, \vec{\beta}$是网络从数据中自动学习到的参数，用于调整$\vec{\mathbf{h}}_{i}^{2}$的均值和方差。虽然$\vec{\mathbf{h}}_{i}^{2}$的每个维度不是零均值、单位方差的，但是可以保证它的每个维度的均值、方差不再依赖于低层的网络。

归一化一个神经元的均值和标准差会降低包含该神经元的神经网络的表达能力。若每个神经元的输出都是均值为0、标准差为 1 ，则会产生两个问题：

- 无论底层的神经元如何学习 ，其输出在提交给上层神经元处理之前，都被粗暴的归一化。导致底层神经元的学习毫无意义。
- `sigmoid` 等激活函数通过区分饱和区、非饱和区（线性区），使得神经网络具有非线性计算的能力。输入归一化使得数据几乎都被映射到激活函数的线性区，从而降低了模型的表达能力。因此执行缩放的原因是：保证模型的容量不会被降低。

根据梯度的链式法则，反向传播规则为：$\nabla_{\vec{\mathbf{h}}_{i}^{1}}\mathcal{L}=\vec{\gamma} \odot \nabla_{\vec{\mathbf{h}}_{i}^{2}}\mathcal{L}$。考虑到$\vec{\gamma}, \vec{\beta}$出现在$\vec{\mathbf{h}}_{1}^{2}, \cdots, \vec{\mathbf{h}}_{m}^{2}$中，因此有：
$$
\nabla_{\vec{\beta}} \mathcal{L}=\sum_{i=1}^{m} \nabla_{\vec{\mathbf{h}}_{i}^{2}}\mathcal{L}\\
\nabla_{\vec{\gamma}} \mathcal{L}=\sum_{i=1}^{m}\left(\nabla_{\vec{\mathbf{h}}_{i}^{2}}\right) \odot \vec{\mathbf{h}}_{i}^{1}
$$
由于$=\vec{\mu}, \vec{\sigma}^{2}$出现在$\vec{\mathbf{h}}_{1}^{2}, \cdots, \vec{\mathbf{h}}_{m}^{2}$中，因此有：
$$
\begin{array}{c}\nabla_{\vec{\mu}} \mathcal{L}=\sum_{i=1}^{m}\left(\frac{\partial \vec{\mathbf{h}}_{i}^{1}}{\partial \vec{\mu}}\right)^{T} \nabla_{\vec{\mathbf{h}}_{i}^{1}} \mathcal{L}=\sum_{i=1}^{m}-\frac{\nabla_{\vec{\mathbf{h}}_{i}^{1}}\mathcal{L}}{\sqrt{\vec{\sigma}^{2}+\epsilon}}\\
\nabla_{\vec{\sigma}^{2}} \mathcal{L}=\sum_{i=1}^{m}\left(\frac{\partial \vec{\mathbf{h}}_{i}^{1}}{\partial \vec{\sigma}^{2}}\right)^{T} \nabla_{\vec{\mathbf{h}}_{i}^{1}} \mathcal{L}=\sum_{i=1}^{m}-\frac{1}{2} \frac{\vec{\mathbf{h}}_{i}-\vec{\mu}}{\left(\vec{\sigma}^{2}+\epsilon\right)^{3 / 2}} \odot\left(\nabla_{\vec{\mathbf{h}}_{i}^{1}} \mathcal{L}\right)\end{array}
$$
由于$\vec{\mathbf{h}}_{i}$出现在多条路径中，因此有：
$$
\begin{aligned} \nabla_{\vec{\mathbf{h}}_{i}} \mathcal{L}=( & \frac{\partial \vec{\mathbf{h}}_{i}^{1}}{\partial \vec{\mathbf{h}}_{i}} )^{T} \nabla_{\vec{\mathbf{h}}_{i}^{1}} \mathcal{L}+\left(\frac{\partial \vec{\mu}}{\partial \vec{\mathbf{h}}_{i}}\right)^{T} \nabla_{\vec{\mu}} \mathcal{L}+\left(\frac{\partial \vec{\sigma}^{2}}{\partial \vec{\mathbf{h}}_{i}}\right)^{T} \nabla_{\vec{\sigma}^{2}} \mathcal{L} \\=& \frac{\nabla_{\vec{\mathbf{h}}_{i}^1}\mathcal{L}}{\sqrt{\vec{\sigma}^{2}+\epsilon}}+\frac{\nabla_{\vec{\mu}} \mathcal{L}}{m}+\frac{2}{m}\left(\vec{\mathbf{h}}_{i}-\vec{\mu}\right) \odot \nabla_{\vec{\sigma}^{2}} \mathcal{L} \end{aligned}
$$
![](../../picture/1/112.png)

大多数神经网络隐层采用 的形式，其中$\phi(\mathbf{X}\mathbf{W}+\vec{\mathbf{b}})$是非线性激励函数。在`batch normalization` 中推荐使用$\phi(\mathbf{X}\mathbf{W})$，因为参数$\vec{\mathbf{b}}$会被 `batch normalization` 中的参数$\vec{\beta}$吸收：无论$\vec{\mathbf{b}}$的值是多少，在归一化的过程中它将被减去。

###### 内部原理

`BN` 表现良好的一个解释是：内部协方差偏移`ICS` 会对训练产生负面影响，`BN` 能够减少`ICS`。

`ICS` 带来的问题是：各个神经元的输入数据不再是独立同分布的。

- 上层参数需要不断适应新的输入数据分布，降低了学习速度。
- 下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止。
- 每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。

###### `BN`性质

`BN` 独立地归一化每个输入维度，它要求每个`mini batch` 的统计量是整体统计量的近似估计。因此`BN` 要求每个`mini-batch` 都比较大，而且每个`mini-batch` 的数据分布比较接近。所以在训练之前，需要对数据集进行充分混洗，否则效果可能很差。

当验证或者测试的`batch size` 较小时（如：只有一个测试样本），此时无法得到`mini batch` 的统计量，或者`mini batch` 统计量无法作为整体统计量的近似估计。此时的做法是：先通过训练集上得到的所有 `mini batch` 的统计量的移动平均值，然后将它们作为验证或者测试时的`mini batch` 的统计量。

`BN` 存在两个明显不足：

- 高度依赖于`mini batch` 的大小。它要求每个`mini-batch` 都比较大，因此不适合`batch size` 较小的场景，
- 不适合`RNN` 网络。因为不同样本的 `sequence` 的长度不同，因此`RNN` 的深度是不固定的。同一个`batch` 中的多个样本会产生不同深度的`RNN`，因此很难对同一层的样本进行归一化。

设$\vec{\mathbf{h}}=\mathbf{W}\vec{\mathbf{x}}_i$，则`BN` 具有权重伸缩不变性，以及数据伸缩不变性。

- 权重伸缩不变性：假设$\tilde{\mathbf{W}}=\lambda\mathbf{W}$，则有：
  $$
  \tilde{\vec{\mathbf{h}}}=\lambda\vec{\mathbf{h}},\quad\tilde{\vec{\mu}}=\lambda\vec{\mu},\quad\tilde{\vec{\sigma}}^2=\lambda^2\vec{\sigma}^2
  $$
  因此权重缩放前后， 保持不变。 是`BN` 层的输入， 就是高层流向低层的梯度，因此权重缩放不影响梯度的流动。

- 数据伸缩不变性：假设 ，同理有：

  

  因此数据的伸缩变化不会影响到对该层的权重更新，简化了对学习率的选择。

在测试阶段，如果需要对单一样本评估，此时测试集只有单个样本，无法给出均值和标准差。解决的方式为：将$\vec{\mu},\vec{\sigma}$设置为训练阶段收集的运行均值

###### 层归一化

与 `BN` 不同，`LN` 是对单个样本的同一层的神经元进行归一化，同层神经元使用相同的均值和方差。对于该层神经元，不同样本可以使用的均值和方差不同。`LN` 不依赖于`batch size`，也不依赖于网络深度。因此它适合在线学习，也适合于`RNN` 网络。

设神经网络第$l$层的输入为$\vec{\mathbf{h}}$，$\vec{\mathbf{h}}=(h_1,\cdots,h_n)^T$，$n$为该层神经元的数量。则`LN` 的步骤为：首先计算该层所有神经元的均值和方差：
$$
\mu = \frac{1}{n}\sum_{i=1}^nh_i, \quad \sigma=\frac{1}{n}\sum_{i=1}^n(h_i-\mu)^2
$$
然后对神经元进行归一化：
$$
\vec{\mathbf{h}}^1=\frac{\vec{\mathbf{h}}-\mu}{\sqrt{\sigma+\epsilon}}
$$
最后执行缩放：$\vec{\mathbf{h}}^2=\vec{\gamma}\odot\vec{\mathbf{h}}^1+\vec{\beta}$。

###### 批量归一化

对于一个深层神经网络，令第$l$层的净输入为$\mathbf{z}^{(l)}$，神经元的输出为$\mathbf{a}^{(l)}$，即
$$
\mathbf{a}^{(l)}=f\left(\mathbf{z}^{(l)}\right)=f\left(W \mathbf{a}^{(l-1)}+\mathbf{b}\right)
$$
给定一个包含$ K $个样本的小批量样本集合，第 $l $层神经元的净输入$\mathbf{z}^{(1, l)},\cdots,\mathbf{z}^{K,l}$的均值和方差为
$$
\begin{aligned} \mu_{\mathcal{B}} &=\frac{1}{K} \sum_{k=1}^{K} \mathbf{z}^{(k, l)} \\ \sigma_{\mathcal{B}}^{2} &=\frac{1}{K} \sum_{k=1}^{K}\left(\mathbf{z}^{(k, l)}-\mu_{\mathcal{B}}\right) \odot\left(\mathbf{z}^{(k, l)}-\mu_{\mathcal{B}}\right) \\
\hat{\mathbf{z}}^{(l)} &=\frac{\mathbf{z}^{(l)}-\mu_{\mathcal{B}}}{\sqrt{\sigma_{\mathcal{B}}^{2}+\epsilon}} \odot \gamma+\beta \\ & \triangleq \mathrm{B} \mathrm{N}_{\gamma, \beta}\left(\mathbf{z}^{(l)}\right)
\end{aligned}
$$
批量归一化操作可以看作是一个特殊的神经层，加在每一层非线性激活函数之前，即
$$
\mathbf{a}^{(l)}=f\left(\mathrm{BN}_{\gamma, \beta}\left(\mathbf{z}^{(l)}\right)\right)=f\left(\mathrm{BN}_{\gamma, \beta}\left(W \mathbf{a}^{(l-1)}\right)\right)
$$

###### 局部响应归一化

假设一个卷积层的输出特征映射$ Y ∈ R^{M′×N′×P}$ 为三维张量，其中每个切片矩阵$Y^p ∈ R^{M′×N′}$ 为一个输出特征映射，$1 ≤ p ≤ P$。
$$
\begin{aligned} \hat{Y}^{p} &=Y^{p} /\left(k+\alpha \sum_{j=\max \left(1, p-\frac{n}{2}\right)}^{\min \left(P, p+\frac{n}{2}\right)}\left(Y^{j}\right)^{2}\right)^{\beta} \\ & \triangleq \operatorname{LRN}_{n, k, \alpha, \beta}\left(Y^{p}\right) \end{aligned}
$$
其中除和幂运算都是按元素运算，$n, k, α, β $为超参，$n$为局部归一化的特征窗口大小。

#### `Online Learning`

##### 梯度截断

在基于梯度下降的优化过程中，如果梯度突然增大，用大的梯度进行更新参数，反而会导致其远离最优点。为了避免这种情况，当梯度的模大于一定阈值时，就对梯度进行截断，称为梯度截断。

按值截断 在第$t$次迭代时，梯度为$g_t$，给定一个区间$[a, b]$，如果一个参数的梯度小于$a$时，就将其设为$a$；如果大于$b$时，就将其设为$b$。
$$
\mathbf{g}_{t}=\max \left(\min \left(\mathbf{g}_{t}, b\right), a\right)
$$
按模截断按模截断是将梯度的模截断到一个给定的截断阈值b。

如果$∥g_t∥_2 ≤ b$，保持$g_t$ 不变。如果$∥g_t∥_2 > b$，令
$$
\mathbf{g}_{t}=\frac{b}{\left\|\mathbf{g}_{t}\right\|} \mathbf{g}_{t}
$$
