图像分类、目标检测、分割是计算机视觉领域的三大任务。

一是分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(category)或实例ID来描述图片。

二是检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息，因此检测模型的输出是一个列表，列表的每一项使用一个数组给出检出目标的类别和位置

三是分割。分割包括语义分割和实例分割，前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓

目标检测的基本思路：同时解决定位（localization） + 识别（Recognition）。 

多任务学习，带有两个输出分支。一个分支用于做图像分类，即全连接+softmax判断目标类别，和单纯图像分类区别在于这里还另外需要一个“背景”类。另一个分支用于判断目标位置，即完成回归任务输出四个数字标记包围盒位置，该分支输出结果只有在分类分支判断不为“背景”时才使用。

传统的目标检测框架，主要包括三个步骤：
利用不同尺寸的滑动窗口框住图中的某一部分作为候选区域；
提取候选区域相关的视觉特征。比如人脸检测常用的Harr特征；行人检测和普通目标检测常用的HOG特征等；
利用分类器进行识别

目前目标检测领域的深度学习方法主要分为两类：两阶段的目标检测算法；一阶段目标检测算法。

两阶段：首先由算法生成一系列作为样本的候选框，再通过卷积神经网络进行样本分类。常见的算法有R-CNN、Fast R-CNN、Faster R-CNN等等。

一阶段：不需要产生候选框，直接将目标框定位的问题转化为回归问题处理。

对于上述两种方式，基于候选区域的方法在检测准确率和定位精度上占优，基于端到端的算法速度占优。

矩形框A、B的一个重合度IOU计算公式为：
$$
\text{IOU} = \frac{A\cap B}{A\cup B}
$$
非极大值抑制`NMS`，我们会从一张图片中找出N多个可能包含物体的Bounding-box，然后为每个矩形框计算其所属类别的概率。

先假设有6个矩形框，根据分类器类别分类概率做排序，从小到大分别属于车辆的概率分别为A、B、C、D、E、F。从最大概率矩形框F开始，分别判断A~E与F的重叠度IOU是否大于某个设定的阈值;假设B、D与F的重叠度超过阈值，那么就扔掉B、D；并标记第一个矩形框F，是我们保留下来的。从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框。