##### 参数范数正则化

一些正则化方法通过对目标函数$J$添加一个参数范数正则化项$\Omega(\vec{\theta})$来限制模型的容量。正则化之后的目标函数为$\tilde{J} : \tilde{J}(\vec{\theta} ; \mathbf{X}, \vec{\mathbf{y}})=J(\vec{\theta} ; \mathbf{X}, \vec{\mathbf{y}})+\alpha \Omega(\vec{\theta})$

###### $\text{L2}$正则化

假设$\vec{\theta}$参数就是权重$\vec{\mathbf{w}}$，没有偏置参数，则：
$$
\tilde{J}(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})=J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})+\frac{\alpha}{2} \vec{\mathbf{w}}^{T} \vec{\mathbf{w}}
$$

对应的梯度为：
$$
\nabla_{\vec{w}} \tilde{J}(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})=\nabla_{\vec{w}} J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})+\alpha \vec{\mathbf{w}}
$$
使用梯度下降法来更新权重，则权重的更新公式为：
$$
\vec{\mathbf{w}}\leftarrow\vec{\mathbf{w}}-\epsilon\left(\nabla_{\vec{\mathbf{w}}} J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})+\alpha \vec{\mathbf{w}}\right)
$$
即：$\vec{\mathbf{w}} \leftarrow(1-\epsilon \alpha) \vec{\mathbf{w}}-\epsilon \nabla_{\vec{\mathbf{w}}} J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})$。$\text{L2}$正则化对于梯度更新的影响是：每一步执行梯度更新之前，会对权重向量乘以一个常数因子来收缩权重向量。因此`L2` 正则化也被称作权重衰减。

令$\vec{\mathbf{w}}^{*}=\arg \min _{\vec{\mathbf{w}}} J(\vec{\mathbf{w}})$，它就是无正则化项时使得目标函数最小的权重向量。根据极小值的条件，有$\nabla_{\vec{\mathbf{w}}} J\left(\vec{\mathbf{w}}^{*}\right)=\vec{\mathbf{0}}$。于是在$\vec{\mathbf{w}}^{*}$的邻域内泰勒展开$J(\vec{\mathbf{w}})$。
$$
\hat{J}(\vec{\mathbf{w}})=J\left(\vec{\mathbf{w}}^{*}\right)+\vec{\mathbf{0}}+\frac{1}{2}\left(\vec{\mathbf{w}}-\vec{\mathbf{w}}^{*}\right)^{T} \mathbf{H}\left(\vec{\mathbf{w}}-\vec{\mathbf{w}}^{*}\right), \quad \vec{\mathbf{w}} \in \mathbb{N}\left(\vec{\mathbf{w}}^{*}\right)
$$
则$\hat{J}(\vec{\mathbf{w}})$的梯度为：$\nabla_{\vec{\mathbf{w}}} \hat{J}(\vec{\mathbf{w}})=\mathbf{H}\left(\vec{\mathbf{w}}-\vec{\mathbf{w}}^{*}\right), \quad \vec{\mathbf{w}} \in \mathbb{N}\left(\vec{\mathbf{w}}^{*}\right)$。

令$\tilde{\vec{\mathbf{w}}}^{*}=\arg \min _{\vec{\mathbf{w}}} \tilde{J}(\vec{\mathbf{w}})$，它就是有正则化项时使得目标函数最小的权重向量。

假设$\tilde{\vec{\mathbf{w}}}^{*} \in \mathbb{N}\left(\vec{\mathbf{w}}^{*}\right)$， 即$\tilde{\vec{\mathbf{w}}}^{*}$在$\vec{\mathbf{w}}^{*}$的一个邻域内，则有：
$$
\nabla_{\vec{w}} J\left(\tilde{\vec{\mathbf{w}}}^{*}\right)=\mathbf{H}\left(\tilde{\vec{\mathbf{w}}}^{*}-\vec{\mathbf{w}}^{*}\right)
$$
根据极小值条件，则有：
$$
\mathbf{H}\left(\tilde{\vec{\mathbf{w}}}^{*}-\vec{\mathbf{w}}^{*}\right)+\alpha \tilde{\vec{\mathbf{w}}}^{*}=\vec{\mathbf{0}} \Rightarrow(\mathbf{H}+\alpha \mathbf{I}) \tilde{\vec{\mathbf{w}}}^{*}=\mathbf{H} \vec{\mathbf{w}}^{*}
$$
因为$\mathbf{H}$是实对称矩阵，对其进行特征值分解：$\mathbf{H}=\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^T$。于是有：
$$
\tilde{\vec{\mathbf{w}}}^{*}=(\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^T+\alpha\mathbf{I})^{-1}\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^T\vec{\mathbf{w}}^{*}=\mathbf{Q}(\mathbf{\Lambda}+\alpha\mathbf{I})^{-1}\mathbf{\Lambda}\mathbf{Q}^T\vec{\mathbf{w}}^{*}
$$

$$
(\mathbf{\Lambda}+\alpha\mathbf{I})^{-1}\mathbf{\Lambda}=\left[\begin{array}{cccc}\frac{\lambda_1}{\lambda_1+\alpha}&0&\cdots&0\\
0&\frac{\lambda_1}{\lambda_1+\alpha}&\cdots&0\\
\cdot&\cdot&\cdots&\cdot\\
0&0&\cdots&\frac{\lambda_n}{\lambda_n+\alpha}
\end{array}\right]
$$

$\text{L}_2$正则化对模型整体的影响：沿着$\mathbf{H}$的特征向量所定义的轴来缩放$\vec{\mathbf{w}}^{*}$。

- $\mathbf{H}$的第$i$个特征向量对应的$\vec{\mathbf{w}}^{*}$分量根据$\frac{\lambda_i}{\lambda_i+\alpha}$因子缩放。
- 沿着$\mathbf{H}$特征值较大的方向受到正则化的影响较小。
- 当$\lambda_i\ll\alpha$的方向对应的权重分量将被缩小到几乎为零。

###### $\text{L1}$正则化

模型参数$\vec{\mathbf{w}}$的$\mathbf{L}_1$的正则化形式为：$\Omega(\vec{\theta})=\|\vec{\mathbf{w}}\|_{1}=\sum_{i}\left|w_{i}\right|$。即各个参数的绝对值之和。$\mathbf{L}_1$正则化后的目标函数
$$
\tilde{J}(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}}) : \tilde{J}(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})=J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})+\alpha\|\vec{\mathbf{w}}\|_{1}
$$
对应的梯度为
$$
\nabla_{\vec{\mathbf{w}}} \tilde{J}(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})=\nabla_{\vec{\mathbf{w}}} J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})+\alpha \operatorname{sign}(\vec{\mathbf{w}})
$$
使用梯度下降法来更新权重，给出权重的更新公式为：
$$
\begin{array}{l}{\vec{\mathbf{w}} \leftarrow \vec{\mathbf{w}}-\epsilon\left(\nabla_{\vec{\mathbf{w}}} J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})+\alpha \operatorname{sign}(\vec{\mathbf{w}})\right)} \\ {=(\vec{\mathbf{w}}-\epsilon \alpha \operatorname{sign}(\vec{\mathbf{w}}))-\epsilon \nabla_{\vec{\mathbf{w}}} J(\vec{\mathbf{w}} ; \mathbf{X}, \vec{\mathbf{y}})}\end{array}
$$

 $\text{L}_1$正则化对于梯度更新的影响是：不再是线性地缩放每个$\omega_i$，而是减去与$\text{sign}(\omega_i)$同号的常数因子。

令$\vec{\mathbf{w}}^{*}=\arg \min _{\vec{\mathbf{w}}} J(\vec{\mathbf{w}})$，它就是无正则化项时使得目标函数最小的权重向量。根据极小值的条件，有$\nabla_{\vec{\mathbf{w}}} J\left(\vec{\mathbf{w}}^{*}\right)=\vec{\mathbf{0}}$。于是在$\vec{\mathbf{w}}^{*}$的邻域内泰勒展开$J(\vec{\mathbf{w}})$。
$$
\hat{J}(\vec{\mathbf{w}})=J\left(\vec{\mathbf{w}}^{*}\right)+\vec{\mathbf{0}}+\frac{1}{2}\left(\vec{\mathbf{w}}-\vec{\mathbf{w}}^{*}\right)^{T} \mathbf{H}\left(\vec{\mathbf{w}}-\vec{\mathbf{w}}^{*}\right), \quad \vec{\mathbf{w}} \in \mathbb{N}\left(\vec{\mathbf{w}}^{*}\right)
$$
由于$\text{L}_1$正则化项在一般的海森矩阵情况下无法得到直接的代数表达式。因此我们进一步假设海森矩阵是对角矩阵。于是：
$$
\hat{J}(\vec{\mathbf{w}})=J\left(\vec{\mathbf{w}}^{*}\right)+\sum_i\left[\frac{1}{2}H_{i,i}(\omega_i-\omega_i^*)^2\right]
$$
考虑定义式，有：
$$
\begin{array}{c}\tilde{J}(\vec{\mathbf{w}})=J(\vec{\mathbf{w}})+\alpha\|\vec{\mathbf{w}}\|_{1}=\hat{J}(\vec{\mathbf{w}})+\alpha\|\vec{\mathbf{w}}\|_{1}\\
\tilde{J}(\vec{\mathbf{w}})=J\left(\vec{\mathbf{w}}^{*}\right)+\sum_i\left[\frac{1}{2}H_{i,i}(\omega_i-\omega_i^*)^2+\alpha|\omega_i|\right]
\end{array}
$$
对于$\vec{\mathbf{w}}$来讲，$J\left(\vec{\mathbf{w}}^{*}\right)$为常量。因此$\tilde{J}(\vec{\mathbf{w}})$的最小值由后面决定。考虑每一个维度$i$，可以考虑最优化目标：
$$
\tilde{w}_i^*=\arg\min_{\omega_i}\left[\frac{1}{2}H_{i,i}(\omega_i-\omega_i^*)^2+\alpha|\omega_i|\right]
$$
得到解析解：$\tilde{w}_i^*=\text{sign}(\omega_i^*)\max\{|\omega_i^*|-\frac{\alpha}{H_{i,i}},0\}$

- $|\omega_i^*|\le\frac{\alpha}{H_{i,i}}$则$\tilde{w}_i^*=0$。表示$\text{L}_1$正则化项将$\omega_i^*$推向 0 。
- $|\omega_i^*|>\frac{\alpha}{H_{i,i}}$则$|\tilde{\omega}_i^*|=|\omega_i^*|-\frac{\alpha}{H_{i,i}}$。此时$\text{L}_1$正则化项并不会将$\omega_i^*$推向 0，而是向零的方向推动了$\frac{\alpha}{H_{i,i}}$的距离。

###### 显式约束正则化

通过添加一个显式约束来实现正则化：
$$
\min _{\vec{\theta}} J(\vec{\theta} ; \mathbf{X}, \vec{\mathbf{y}})\\
\Omega(\vec{\theta})<k
$$
其中$k$为一个常数。可以通过构建广义拉格朗日函数来求解该约束最优化问题。定义广义拉格朗日函数：
$$
\mathcal{L}(\vec{\theta}, \alpha)=J(\vec{\theta})+\alpha(\Omega(\vec{\theta})-k)
$$
则上述约束最优化问题的解由下式给出：$\vec{\theta}^{*}=\arg \min _{\vec{\theta}} \max _{\alpha, \alpha>0} \mathcal{L}(\vec{\theta}, \alpha)$。假设$\alpha$的解为$\alpha^*$，固定$\alpha^*$则：$\vec{\theta}^{*}=\arg \min _{\vec{\theta}} J(\vec{\theta})+\alpha^{*} \Omega(\vec{\theta})$.

##### 数据增强

数据集增强仅仅用于模型的训练，而不是用于模型的预测。即：不能对测试集、验证集执行数据集增强。

###### 线性变换

对于分类问题来说，创建虚拟数据非常简单。对于一个分类器，它将高维的输入$\vec{\mathbf{x}}$映射到类别$y$。这意味着这种映射规则是不随坐标系的改变而改变的。因此可以通过线性变换，将训练集中的$(\vec{\mathbf{x}},y)$变换为$(\vec{\mathbf{x}}^{\prime},y)$从而产生了新的数据$(\vec{\mathbf{x}}^{\prime},y)$。

常见的图片数据集增强方法：

- 将训练图像沿着每个方向平移几个像素产生新的图像。
- 对训练图像进行旋转、翻转或者缩放。
- 对训练图像进行随机裁剪。
- 对训练图像进行颜色抖动：调整饱和度、调整亮度、调整对比度、调整锐度。
  - 对比度：图像画面的明暗反差程度。对比度越高，则图片亮的地方更亮，暗的地方越暗。
  - 亮度：图像的明暗程度。亮度越高，则图像整体越亮。
  - 饱和度：图像颜色种类的多少。饱和度越高，则图像的颜色种类越多，图像越鲜艳。
  - 锐度：图像的边缘轮廓的锐利程度。锐度越高，则图像的边缘越清晰。

###### 输入噪声注入

通常一个训练好的神经网络对噪声鲁棒性较差，改善其噪声鲁棒性的常用方法是：简单地将随机噪声施加到输入上，再进行训练。

- 当仔细调整噪声的幅度之后，该方法非常高效。
- 噪声被添加到每层隐单元的输入（而不仅仅是整个网络的输入）也是可行的，这被视为在多个抽象层上进行数据集增强。

##### 噪声鲁棒性

###### 权重噪声注入

权重噪声注入可以解释为：将权重视作不确定的随机变量（拥有某个概率分布），向权重注入噪声是对该随机变量采样得到的一个随机值。在某些假设下，权重噪声注入等价于传统的参数正则化形式。

###### 输出噪声注入

输出噪声注入显式地对标签上的噪音进行建模：假设某个很小的常数$\epsilon$， 标签$y$是正确的概率为$1-\epsilon$、是错误的概率为$\epsilon$。

基于$k$个输出的`softmax`单元的标签平滑正则化`label smoothing regularize`：将真实的标签从$\{0,1\}$替换为$\{\frac{\epsilon}{k},1-\frac{k-1}{k}\epsilon\}$。原始的标签：$k-1$个为 `0`， 一个为`1` 。注入噪声之后的标签：$k-1$个为$\frac{\epsilon}{k}$，一个为$,1-\frac{k-1}{k}\epsilon$。

##### `earlystopping`

当训练一个容量较大的模型时会经常发现：训练误差逐渐降低，但是验证误差先下降后上升。当验证误差没有进一步改善时，算法就提前终止。这种策略被称作早停`early stopping`。当训练终止时，返回的不是最新的模型参数，而是验证误差最小的模型参数，因此需要频繁存储模型参数。

早停策略的代价有两个：需要在训练期间定期评估验证集。需要保持最佳的参数的副本。

###### 二次训练

早停需要验证集，这意味着某些样本不能用于模型的训练过程，这会造成数据的浪费。为了更好地利用验证集的样本，可以在早停之后进行额外的训练。在第二轮额外的训练中，所有的训练数据都被包括在内（包括验证集）。有两个基本的策略可以用于第二轮训练过程 ：

- 保留迭代步：再次初始化模型，然后使用所有数据再次训练。此时使用第一轮早停确定的最佳步数作为第二轮的迭代步数。
- 保留参数：保持从第一轮训练中获得的参数，然后使用全部的数据继续训练。此时观察原始验证集的损失函数，直到它低于第一轮停止时的原始训练集的损失函数值。

##### 参数相对约束

假设模型 `A`的参数为$\vec{\mathbf{w}}_A$，模型 `B`的参数为$\vec{\mathbf{w}}_B$。如果两个模型非常相似，则给定下列形式的惩罚：
$$
\Omega(\vec{\mathbf{w}}_A,\vec{\mathbf{w}}_B)=||\vec{\mathbf{w}}_A-\vec{\mathbf{w}}_B||^2_2
$$
还有一种方案：强迫$\vec{\mathbf{w}}$的某个子集相等，这称作参数共享`parameter sharing`。

##### $\text{DropOut}$

`dropout`在前向传播过程中，对网络中的每个隐层，每个隐单元都以一定的概率$p_{drop}$​被删除，最后得到一个规模更小的网络。在反向传播过程中，仅仅针对该小网络进行权重更新。

- 所谓的删除，即指定该该隐单元的输出都为0。一旦隐单元的权重为0，则该隐单元对后续神经元的影响均为0 。
- 输入层和输出层的神经元不会被删除，因为这两个层的神经元的数量是固定的。
- 隐单元删除发生在一个训练样本的训练期间。不同的训练样本，其删除的隐单元的集合是不同的，因此裁剪得到的小网络是不同的。

![](../../picture/1/281.png)
$$
\begin{equation}\begin{array}{l}\text{Train:}&\mathbf{y}=f(\mathbf{W}\mathbf{x})\odot\mathbf{m}, m_i\sim Bernoulli(p)\\
\text{Testing:}& \mathbf{y}=(1-p)f(\mathbf{W}\mathbf{x})
\end{array}\end{equation}
$$

定义一个掩码向量$\vec{\mu}$，它给出了哪些隐单元被保留哪些隐单元被删除：掩码为 `0` 的位置对应的隐单元被删除，掩码为`1` 的位置对应的隐单元被保留。定义$J(\vec{\theta},\vec{\mu})$为参数$\vec{\theta}$和掩码$\vec{\mu}$共同定义的模型代价，`dropout`的目标是最小化$\mathbb{E}_{\vec{\mu}}J(\vec{\theta},\vec{\mu})$​。

`dropout`可以视作集成了非常多的神经网络的`bagging`集成模型，这些网络包含了所有从基础网络中删除隐单元形成的子网络。`dropout`提供了一种方便的`bagging`近似，它能够训练和评估指数级别的神经网络的集成。

`dropout`训练与`bagging`训练不同：

- `bagging`中，假设所有的子模型都是独立的。`dropout`中，所有的子模型是共享参数的，每个子模型继承了基础神经网络的不同子集。
- `bagging`中，每个子模型在其相应的训练集上训练到收敛。`dropout`中，大部分子模型都没有显式的被训练。

`dropout` 仅仅用于神经网络的训练阶段，在网络的测试阶段并不会删除神经元，而是使用所有的神经元。因为在测试期间，不希望输出是随机的。如果在测试阶段使用`dropout`，则理论上需要运行多次`dropout` 测试过程，然后对输出结果取加权平均（或者几何平均）。

在`dropout`情况下，每个子模型的输出为概率分布$p(y|\vec{\mathbf{x}},\vec{\mu})$​，不同的掩码$\vec{\mu}$就定义了不同的子模型。集成模型的输出由所有子模型输出的加权平均给出：
$$
\tilde{p}(y|\vec{\mathbf{x}})=\sum_{\vec{\mu}}p(\vec{\mu})p(y|\vec{\mathbf{x}},\vec{\mu})
$$
使用`dropout` 有两点注意：在训练期间如果对某个单元的输入神经元执行了`dropout`，则推断期间该单元的输出要进行调整。假设该单元的输出为$h$，则需要调整为$\frac{p}{1-p_{\text{drop}}}$，从而保证不影响该单元的输出值。在测试期间，不必使用`dropout` 。

##### 半监督学习

在深度学习中，半监督学习指的是学习一个表达`representation` ：$\vec{\mathbf{h}}=f(\vec{\mathbf{x}})$。学习的目标是：使得同类中的样例有类似的表达。通常可以构建两个模型：生成模型$p(\vec{\mathbf{x}})$或$p(\vec{\mathbf{x}},y)$与判别模型$p(y|\vec{\mathbf{x}})$，其中生成模型与判别模型共享参数。

- 生成模型 $p(\vec{\mathbf{x}})$或$p(\vec{\mathbf{x}},y)$表达了对于监督学习问题解的先验知识。即：$p(\vec{\mathbf{x}})$的结构通过共享参数的方式连接到$p(y|\vec{\mathbf{x}})$。
- 不需要将无监督学习和监督学习部分进行分离，二者位于同一个网络结构中。
- 最终需要对监督准则$-\log p(y|\vec{\mathbf{x}})$与无监督准则$-\log p(\vec{\mathbf{x}})$或$-\log p(\vec{\mathbf{x}},y)$进行权衡。

机器学习的许多线性问题，都依赖于求$\mathbf{X}^T\mathbf{X}$的逆矩阵。当$\mathbf{X}^T\mathbf{X}$是可逆时，该问题有解析解。当$\mathbf{X}^T\mathbf{X}$是奇异矩阵时，该问题是欠定的。此时可以考虑正则化形式：求解$\mathbf{X}^T\mathbf{X}+\alpha\mathbf{I}$的逆矩阵。大多数形式的正则化能够用于欠定问题。如：`Moore-Penrose`求解欠定线性方程， 伪逆的一个定义：$\mathbf{X}^+=\lim_{\alpha\to0}(\mathbf{X}^T\mathbf{X}+\alpha\mathbf{I})\mathbf{X}^T$。

