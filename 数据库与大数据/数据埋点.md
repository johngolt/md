埋点从准确性的角度考虑，也会分客户端埋点和服务端埋点。客户端埋点就是在客户操作的界面中在客户产生动作时就记录用户的行为，即使这些行为只会在客户端发生，而不会传输到服务器端；而服务端埋点是通常是在程序和数据库交互的界面埋点，这个时候埋点会更准确地记录数据的改变，会忽略网络传输可能造成的不确定性风险。

|          | 代码埋点                                     | 全埋点                                   | 可视化埋点                                                 |
| -------- | -------------------------------------------- | ---------------------------------------- | ---------------------------------------------------------- |
| 典型场景 | 无法通过全埋点和可视化埋点准确覆盖的埋点场景 | 简单、规范的页面主要分析点击的场景       | 简单、规范的页面主要分析点击的场景                         |
| 优势     | 可控性高、适用范围广                         | 不需要人工介入、数据可回溯、无视新老版本 | 不需要工程师接入、不同重新发布产品使埋点生效、实时测试验证 |
| 不足     | 跨团队、验证周期长、错漏难以纠正             | 分析前依然需要清洗数据、埋点适用范围有限 | 埋点适用范围有限                                           |

数据埋点是为了更好的数据采集，通常记录用户行为的基本要素采用4W+1H的方式，即人物（Who）、时间（When）、地点（Where）、行为（What）、方式（How）。用户在什么时间什么地点使用什么方式产生了什么样的行为来记录。

人物（Who）：参与事件的用户，一般使用开发过程中对用户定义的唯一ID，包含用户的设备ID、UserID、等非敏感信息。对用户的姓名、手机号、身份证号码等敏感信息不建议直接采集，如必须采集可采用脱敏的方式进行。

时间（When）：记录行为发生的时间，常见标准的YYYY-MM-DD HH-MM-SS的时间戳以外还可以使用服务端的Session或登录序号等。记录值将用于区分用户的登陆次数，界定活跃次数和行为归属。

地点（Where）：记录行为发生的地点，包括用户的IP地址、GPS位置、场景或来源（WEB/微信/APP）。

行为（What）：事件的内容，即发生的细节，可以采用记录事件的属性/参数生成记录值，常见格式为Key-Value模式。

方式（How）：事件所处环境和发生方式，常见的记录值有：网络环境（WIFI/4G）、系统版本（iOS 12.0.1/Android 8.0)、设备型号（HUAWEI/XIAOMI/Apple）。

各个平台基于事件维度，同时有一定的个性维度组建了数据分析维度。

埋点方案绕不开的三个方面为：触发条件的设置，映射关系的管理，采集上报规则的处理。

（1）事件类型字段：用于说明当前埋点是点击事件还是浏览

（2）中文名字段：用于描述X功能模块内X位置，例如起名叫：支付页——扫码

（3）事件ID字段：每一个埋点都对应唯一一个事件ID，可以通过事件ID去后台取数使用。

（4）记录规则字段：定义什么情况下触发埋点，例如：在列表页点击一次记录一次

（5）描述字段：每一个完成的页面埋点或者按钮点击的埋点都需要加一个描述字段进行业务阐释

 (6）备注字段:用于描述当前埋点什么时间新增？什么时间修改过？原因？什么时间被删除？谁删除的？等信息记录，为了信息的完整性和可追溯性最好每一次变动都要备注。







用户行为，是指用户使用APP、小程序或者Web程序所产生的点击和浏览等交互行为。用户的这些交互行为，有的仅仅引起一些前端页面的变化，有的还需要请求后端服务器，并根据服务返回的结果做不同的处理，这也是为什么埋点要分前端埋点和后端埋点。

用户产生的数据包含用户信息的数据、用户行为数据（在产品中留下的足迹）和用户交易数据（交易数据在有线上购买行为的产品中会用到）。
从用户信息数据到用户交易数据，主要是用户主动发起的，所以可以理解为用户侧。
从用户行为数据到用户交易数据，更主要是产品流程为用户营造的购买体验感，所以可以理解为产品侧。

#### 日志采集

##### 浏览器的页面日志采集

浏览器的页面型产品/服务的日志采集可分为如下两大类。
(1）页面浏览（展现）日志采集。顾名思义，页面浏览日志是指当一个页面被浏览器加载呈现时采集的日志。此类日志是最基础的互联网日志，也是目前所有互联网产品的两大基本指标:页面浏览量`PV`和访客数`UV`的统计基础。

(2)页面交互日志采集。当页面加载和渲染完成之后，用户可以在页面上执行各类操作。互动设计都要求采集用户的互动行为数据，以便通过量化获知用户的兴趣点或者体验优化点。

###### 页面浏览日志采集流程

![](../picture/2/343.png)

用户在浏览器内点击淘宝首页连接；浏览器向淘宝服务器发起HTTP请求；服务器接收并解析请求。服务器端的业务处理模块按业务逻辑 处理本次请求并按照 HTTP协议规定的格式，将处理结果以HTTP形式发回浏览器；浏览器接收到服务器的响应内容，并将其按照文档规范展现给用户，从而完成一次请求。

根据前文所述，可以很自然地得出在这一模式下最直接的日志采集思路：在 HTML 文档内的适当位置增加 一个日志采集节点，当浏览器解析到这个节点时，将自动触发一个特定 HTTP 请求到日志采集服务器。如此一来，当日志采集服务器接收到 这个请求时，就可以确定浏览器已经成功地接收和打开了页面

![](../picture/2/344.png)

页面浏览日志采集过程中，所涉及的日志相关的几个主要过程简单介绍如下： 

( 1 ）客户端日志采集。日志采集工作一般由一小段被植人页面HTML文档内的`JavaSc ript`脚本来执行。采集脚本被浏览器加载解析后执行，在执行时采集当前页面参数、浏览行为的上下文信息以及一些运行环境信息。

(2 ）客户端日志发送。采集脚本执行时，会向日志服务器发起一个日志请求，以将采集到的数据发送到日志服务器。

(3 ）服务器端日志收集。日志服务器接收到客户端发来的日志请求后，一般会立即向浏览器发回一个请求成功的响应，以免对页面的正常加载造成影响；同时，日志服务器的日志收集模块会将日志请求内容写一个日志缓冲区内，完成此条浏览日志的收集。

(4 ）服务器端日志解析存档。服务器接收到的浏览日志进人缓冲区后，会被一段专门的日志处理程序顺序读出并按照约定的日志处理逻辑解析。由日志采集脚本记录在日志请求行内的参数，将在这个环节被解析出来，转存人标准的日志文件。

###### 页面交互日志采集

要了解用户在访问某个页 面时具体的互动行为特征，比如鼠标或输入焦点的移动变化、对某些页面交互的反应等。因为这些行为往往并不触发浏览器加载新页面，所以无法通过常规的`PV`日志采集方法来收集。

业务方将交互日志采集代码植入目标页面，并将采集代码与需监测的交互行为做绑定；当用户在页面上产生指定行为时，采集代码和正常的业务互动响应代一起被触发和执行；采集代码在采集动作完成后将对应的日志通过 HTTP 协议发送到日志服务器

##### 无线客户端的日志采集

移动端的日志采集采用采集`SDK`来完成。无线客 户端的日志采集和浏览器的日志采集方式有所不同，移动端的日志采集根据不同的用户行为分成不同的事件，“事件”为移动端日志行为的最小单位。常用的包括页面事件（同页面浏览）和控件点击事件（同页面交互）等。

###### 页面事件

日志采集`SDK`对于不同事件的实现大致是类似的：只是对于通用的用户行为，抽象出来一些通用的接口方法。我们把常用的行为类别单独列出来，作为单独的事件来处理，如页面事件（页面浏览行为）。每条页面事件日志记录三类信息 ①设备及用户的基本信息：②被访问页面的信息，这里主要是一些业务参数（如商品详情页的商品 ID 、所属的店铺等） ; ③访问基本路径（如页面来源、 来源的来源 ），用于还原用户完整的访问行为。

###### 控件点击及其他事件

和浏览器客户端的日志采集一样 ，交互日志的采集无法规定统一的 采集内容，交互类的行为呈现出高度自定义的业务特征。将交互日志采集分类为控件点击事件和其他事件。

控件点击事件比页面事件要简单得多，首先，它和页面事件一样，记录了基本的设备信息、用户信息：其次，它记录了控件所在页面名称、控件名称、控件的业务参数等。由于控件点击事件的逻辑简单得多，就是操作页面上的某个控件，因此只需把相关基础信息告诉采集`SDK`即可。

其他事件，就是用户可以根据业务场景需求，使用自定义事件来采集相关信息。从某种程度上说，它几乎能满足用户的所有需求，包括页面事件和控件点击事件，只是若采用通用的页面事件埋点方法， 会帮助实现一些额外的功能。

无线客户端日志的上传，不是产生一条日志上传一条，而是无线客户端产生日志后，先存储在客户端本地，然后再伺机上传。所谓伺机， 就需要有数据分析的支持，如在启动后、使用过程中、切换到后台时这些场景下分别多久触发一次上传动作。

简单来说，`APP`分为两种:一种是纯Native APP;一种是既有Native,又有H5页面嵌入的APP，即 Hybrid APP。Native页面采用采集SDK进行日志采集，H5页面一般采用基于浏览器的页面日志采集方式进行采集。在当前的实践中，由于采集方式的不同，采集到的内容及采集服务器均分离开。若需要进行完整的数据分析，就需要将两类日志在数据处理时进行关联,而就算不考虑处理成本，在很多情况下，Native和 H5互跳,即使关联也无法还原用户路径，数据丢失严重。

#### 数据同步

数据同步技术更通用的含义是不同系统间的数据流转，有多种不 同的应用场景。主数据库与备份数据库之间的数据备份，以及主系统与 子系统之间的数据更新，属于同类型不同集群数据库之间的数据同步。 另外，还有不同地域、不同数据库类型之间的数据传输交换，比如分布式业务系统与数据仓库系统之间的数据同步。对于大数据系统来说，包 含数据从业务系统同步进入数据仓库和数据从数据仓库同步进入数据 务或数据应用两个方面。

##### 数据抽取

如何清理操作型数据，如何移除垃圾数据，如何将来自多个源系统的相同数据整合在一起。另外，还要确认数据的更新频率。在数据仓库设计的初始阶段，需要确定数据源有哪些、数据需要做哪些转换以及数据的更新频率是什么。

###### 数据抽取

实时接入还是离线抽取。离线抽取的话是全量抽取还是增量抽取。抽取频次数每天抽取还是每小时抽取。

| 逻辑抽取 | 说明                                                         |
| -------- | ------------------------------------------------------------ |
| 全量抽取 | 它将数据源中的表或视图的数据原封不动的从数据库中抽取出来，并转换成自己的`ETL`工具可以识别的格式。 |
| 增量抽取 | 增量抽取只抽取自上次抽取以来数据库中要抽取的表中新增或修改的数据。在`ETL`使用过程中，增量抽取较全量抽取应用更广。 |

在许多数据仓库中，把源系统中的整个表抽取到数据仓库过渡区，然后用这个表的数据和上次从源系统抽取得到的表数据作比对，从而找出发生变化的数据。虽然这种方法不会对源系统造成很大的影响，但显然需要考虑给数据仓库处理增加的负担。

| 物理抽取 | 说明                                                         |
| -------- | ------------------------------------------------------------ |
| 联机抽取 | 数据直接从源系统抽取。抽取进程或者直连源系统数据库，访问它们的数据表，或者连接到一个存储快照日志或变更记录表的中间层系统。 |
| 脱机抽取 | 数据不从源系统直接抽取，而是从一个源系统以外的过渡区抽取。过渡区可能已经存在，或者抽取程序自己建立。 |

过渡区可能包括：数据库备份文件、备用数据库、平面文件、导出文件、重做日志和归档日志

抽取处理需要重点考虑增量抽取，也被称为变化数据捕获，简称CDC。如何捕获变化的数据是增量抽取的关键。对捕获方法一般有两点要求：准确性，能够将业务系统中的变化数据按一定的频率准确地捕获到；性能，不能对业务系统造成太大的压力，影响现有业务。

| 增量方式     | 说明                                                         | 优点                                                         | 缺点                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 触发器       | 在要抽取的表上建立需要的触发器，一般要建立插入、修改、删除三个触发器，每当源表中的数据发生变化，就被相应的触发器将变化的数据写入一个临时表，抽取线程从临时表中抽取数据，临时表中抽取过的数据被标记或删除 | 数据抽取的性能高，`ETL`加载规则简单，速度快，不需要修改业务系统表结构，可以实现数据的递增加载。 | 要求业务表建立触发器，对业务系统有一定的影响，容易对源数据库构成威胁。 |
| 时间戳       | 在源表上增加一个时间戳字段，系统中更新修改表数据的时候，同时修改时间戳字段的值。当进行数据抽取时，通过比较上次抽取时间与时间戳字段的值来决定抽取哪些数据。 | 性能比较好，`ETL`系统设计清晰，源数据抽取相对清楚简单，可以实现数据的递增加载。 | 时间戳维护需要由业务系统完成，对业务系统也有很大的倾入性；无法捕获对时间戳以前数据的delete和update 操作，在数据准确性上受到了一定的限制 |
| 全表删除插入 | 每次`ETL`操作均删除目标表数据，由`ETL`全新加载数据。适用于全量表，只保存最新数据，历史数据不保留 | `ETL`加载规则简单，速度快。                                  | 对于维表加外键不适应，当业务系统产生删除数据操作时，综合数据库将不会记录到所删除的历史数据，不可以实现数据的递增加载；同时对于目标表所建立的关联关系，需要重新进行创建。 |
| 全表比对     | `ETL`工具事先为要抽取的表建立一个类似的临时表，该临时表记录源表主键以及根据所有字段的数据计算出来，每次进行数据抽取时，对源表和临时表进行的比对，如有不同，进行Update 操作，如目标表没有存在该主键值，表示该记录还没有，即进行Insert 操作 | 对已有系统表结构不产生影响，不需要修改业务操作程序，所有抽取规则由`ETL`完成，管理维护统一，可以实现数据的递增加载，没有风险。 | `ETL`比对较复杂，设计较为复杂，速度较慢。与触发器和时间戳方式中的主动通知不同，全表比对方式是被动的进行全表数据的比对，性能较差。当表中没有主键或唯一列且含有重复记录时，全表比对方式的准确性较差。 |
| 日志表       | 在业务系统中添加系统日志表，当业务数据发生变化时，更新维护日志表内容，当作`ETL`加载时，通过读日志表数据决定加载那些数据及如何加载。 | 不需要修改业务系统表结构，源数据抽取清楚，速度较快。可以实现数据的递增加载。 | 日志表维护需要由业务系统完成，需要对业务系统业务操作程序作修改，记录日志信息。日志表维护较为麻烦，对原有系统有较大影响。工作量较大，改动较大，有一定风险。 |

有的数据库的时间戳支持自动更新，即表的其它字段的数据发生改变时，自动更新时间戳字段的值。有的数据库不支持时间戳的自动更新，这就要求业务系统在更新业务数据时，手工更新时间戳字段。

##### 数据同步基础

###### 直连同步

直连同步是指通过定义好的规范接口API和基于动态链接库的方式直接连接业务库，如ODBC/JDBC等规定了统一规范的标准接口，不同的数据库基于这套标准接口提供规范的驱动,支持完全相同的函数调用和SQL实现。

这种方式配置简单,实现容易，比较适合操作型业务系统的数据同步。但是业务库直连的方式对源系统的性能影响较大，当执行大批量数据同步时会降低甚至拖垮业务系统的性能。如果业务库采取主备策略,则可以从备库抽取数据，避免对业务系统产生性能影响。但是当数据量较大时，采取此种抽取方式性能较差，不太适合从业务系统到数据仓库系统的同步。

###### 数据文件同步

数据文件同步通过约定好的文件编码、大小、格式等，直接从源系统生成数据的文本文件，由专门的文件服务器，如FTP服务器传输到目标系统后，加载到目标数据库系统中。当数据源包含多个异构的数据库系统（如MySQL、Oracle、SQL Server等)时，用这种方式比较简单、实用。另外，互联网的日志类数据，通常是以文本文件形式存在的,也适合使用数据文件同步方式。

由于通过文件服务器上传、下载可能会造成丢包或错误，为了确保数据文件同步的完整性，通常除了上传数据文件本身以外，还会上传一个校验文件,该校验文件记录了数据文件的数据量以及文件大小等校验信息，以供下游目标系统验证数据同步的准确性。
另外，在从源系统生成数据文件的过程中，可以增加压缩和加密功能，传输到目标系统以后,再对数据进行解压缩和解密，这样可以大大提高文件的传输效率和安全性。

###### 数据库日志解析同步

大多数主流数据库都已经实现了使用日志文件进行系统恢 ，因为日志文件信息足够丰富，而且数据格式也很稳定，完全可以通 过解析日志文件获取发生变更的数据，从而满足增量数据同步的需求。

数据库日志解析同步方式实现了实时与准实时同步的能力,延迟可以控制在毫秒级别，并且对业务系统的性能影响也比较小，目前广泛应用于从业务系统到数据仓库系统的增量数据同步应用之中。
由于数据库日志抽取一般是获取所有的数据记录的变更(增、删、改)，落地到目标表时我们需要根据主键去重按照日志时间倒排序获取最后状态的变化情况。对于删除数据这种变更情况，针对不同的业务场景可以采用一些不同的落地手法。

通过数据库日志解析进行同步的方式性能好、效率高，对业务系统的影响较小。但是它也存在如下一些问题 

·数据延迟。例如，业务系统做批量补录可能会使数据更新量超出系统处理峰值，导致数据延迟。

 ·投入较大。采用数据库日志抽取的方式投入较大，需要在源数据库与目标数据库之间部署个系统实时抽取数据。 

·数据漂移和遗漏。数据漂移，一般是对增量表而言的，通常是指该表的同一个业务日期数据中包含前一天或后一天凌晨附近的数据或者丢失当天的变更数据。

##### 数据同步遇到问题与解决方案

###### 分库分表的处理

但是对于数据同步来说，分库分表的设计加大了同步处理的复杂度。

通过中间表的方式：通过一个中间表，将分布在不同数据库中的不同表集成为一个表，就能让下游应用像访问单库单表一样方便。

###### 高效同步和批量同步

数据同步的方法通常是先创建目标表 ，再通过同步工具的填写数据库连接、表、字段等各种配置信息后测试完成数据同步。

###### 增量与全量同步的合并

在批量数据同步中，有些表的数据量随着业务的发展越来越大，如果按周期全量同步的方式会影响处理效率。在这种情况下，可以选择每 次只同步新变更的增量数据，然后与上一个同步周期获得的全量数据进 行合井，从而获得最新版本的全量数据。 

比较推荐的方式是全外连接`full outer join`＋数据全量覆盖重新加载，即如日调度，则将当天的增量数据和前一 天的全量数据做全外连接，重新加载最新的全量数据

###### 同步性能的处理

###### 数据漂移的处理

数据漂移是指 ODS 表的同一个业务日期数据中包含前一天或后一天凌晨附近的数据或者丢失当天的变更数据。

由于`ODS`需要承接面向历史的细节数据查询需求，这就需要物理落地到数据仓库的`ODS`表按时间段来切分进行分区存储 ，通常的做法 是按某些时间戳字段来切分，而实际上往往由于时间戳字段的准确性问题导致发生数据漂移。 通常，时间戳字段分为四类： 

数据库表中用来标识数据记录更新时间的时间戳字段`modified_time`；数据库日志中用来标识数据记录更新时间的时间戳字段`log_time`；数据库表中用来记录具体业务过程发生时间的时间戳字段`proc_time`；标识数据记录被抽取到时间的时间戳字段`extract_time`。

理论上，这几个时间应该是一致的，但是在实际生产中，这几个时间往往会出现差异，可能的原因有以下几点：由于数据抽取是需要时间的，`extract_time`往往会晚于前三个时间；前台业务系统手工订正数据时未更新 `modified_time`；由于网络或者系统压力问题，`log_time`或者`modified_time`会晚`proc_time`.

通常的做法是根据其中的某一个字段来切分`ODS`表，这就导致产生数据漂移。下面我们来具体看下数据漂移的几种场景。

①根据`extract_time`来获取数据。这种情况数据漂移的问题最明显；②根据`modified_time`限制。在实际生产中这种情况最常见，但是往往会发生不更新`modified_time`而导致的数据遗漏，或者凌晨时间产生的数据记录漂移到后一天；③根据`log_time`限制。由于网络或者系统压力问题，`log_time`会晚`proc_time`，从而导致凌晨时间产生的数据记录漂移到后一天；④根据`proc_time`限制。仅仅根据`proc_time`限制，我们所获取的`ODS`表只是包含一个业务过程所产生的记录，会遗漏很多其他过程的变化记录，这违背了`ODS`和业务系统保持一致的设计原则

 处理方法主要有以下两种：①多获取后一天的数据，既然很难解决数据漂移的问题，那么就在`ODS`每个时间分区中向前、向后多冗余一些数据，保障数据只会多不会少，而具体的数据切分让下游根据自身不同的业务场景用不同的业务时间`proc_time`来限制；②通过多个时间戳字段限制时间来获取相对准确的数据，首先根据`log_time`分别冗余前一天最后15分钟的数据和后一天凌晨开始15分钟的数据，并用`modified_time`过滤非当天数据， 确保数据不会因为系统问题而遗漏。 然后根据`log_time`获取后一天15分钟的数据，针对此数据，按照主键根据`log_time`做升序排列去重。最后将前两步的结果数据做全外连接，通过限制业务时间`proc_time`来获取我们所需要的数据。