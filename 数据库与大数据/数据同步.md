| 算法         | 实现         | 源表要求   | 描述                                         | 适用                   |
| ------------ | ------------ | ---------- | -------------------------------------------- | ---------------------- |
| 全删全插     | `del/ins`    | 全量       | 不保留过往数，只保留当前最新全量数据         | 维度表、参数表、主档表 |
| 增量累全     | `upsert`     | 增量或全量 | 只保留一份最新且保留源系统过往记录数据       | 参数表、主档表         |
| 增量累加     | `append`     | 增量       | 源系统提供每日事件流水，仓库直接保留每日流水 | 流水表                 |
| 标准拉链     | 全历史拉链   | 全量       | 跟踪数据删除的变化历史                       | 拉链表                 |
| 增量拉链     | 增量拉链     | 增量或全量 | 记录数据变化历史                             | 拉链表                 |
| 增删拉链     | 增删拉链     | 增量       | 利用业务字段跟踪增量数据中包含删除的变化历史 | 拉链表                 |
| 全量增删拉链 | 全量增删拉链 | 全量       | 利用业务字段跟踪全量数据中包含删除的变化历史 | 拉链表                 |
| 自拉链       | 自拉链       | 全量或增量 | 流水表数据转化成拉链表数据                   | 拉链表                 |

###### 全删全插模式

主要应用在维表、参数表、主档表加载上，即适合源表是全量数据表，该数据表业务逻辑只需保存当前最新全量数据，不需跟踪过往历史信息。

算法实现逻辑：清空目标表；源表全量插入；

```sql
--   1. 清理目标表
TRUNCATE TABLE <目标表>;
 
--   2. 全量插入
INSERT INTO <目标表>   (字段***)
SELECT 字段***
FROM <源表>
***JOIN <关联数据>
WHERE   ***;
```

###### 增量累全模式

主要应用在参数表、主档表加载上，即源表可以是增量或全量数据表，目标表始终最新最全记录。

算法实现逻辑：利用PK主键比对；目标表和源表PK一致的变化记录，更新目标表；源表存在但目标表不存在，直接插入；

```sql
-- 1. 生成加工源表
Create temp Table <临时表> ***;
INSERT INTO <临时表> (字段***)
SELECT 字段***  
FROM <源表>
***JOIN <关联数据>
WHERE ***;
 
-- 2. 可利用Merge Into实现累全能力，当前也可以采用分步Delete/Insert或Update/Insert操作
Merge INTO <目标表> As T1 (字段***)
Using <临时表> as S1
on (***PK***)
when Matched then
update set Colx = S1.Colx ***
when Not Matched then
INSERT (字段***)   values (字段*** );
```

###### 增量累加模式

主要应用在流水表加载上，即每日产生的流水、事件数据，追加到目标表中保留全历史数据。流水表、快照表、统计分析表等均是通过该逻辑实现。

算法实现逻辑：源表直接插入目标表；

```sql
--   1.插入目标表
INSERT INTO <目标表>   (字段***)
SELECT 字段***
FROM <源表>	
***JOIN <关联数据>
WHERE   ***;
```

###### 全历史拉链模式

拉链表是一张至少存在PK字段、跟踪变化的字段、开链日期、闭链日期组成的数据仓库ETL数据表；

益处：根据开链、闭链日期可以快速提取对应日期有效数据；对于跟踪源系统非事件流水类表数据，拉链算法发挥越大作用，源业务系统通常每日变化数据有限，通过拉链加工可以大大降低每日打快照带来的空间开销，且不损失数据变化历史；

全历史拉链，跟踪源表全量变化历史，若源表记录不存在，则说明数据闭链；根据PK新拉一条有效记录。

算法实现逻辑：提取当前有效记录；提取当日源系统最新数据；根据PK字段比对当前有效记录与最新源表，更新目标表当前有效记录，进行闭链操作；根据全字段比对最新源表与当前有效记录，插入目标表；

```sql
-- 1. 提取当前有效记录
Insert into <临时表-开链-pre> (不含开闭链字段***)
Select 不含开闭链字段***
From <目标表>
Where 结束日期 =date'<最大日期>';
;
-- 2. 提取当日源系统最新数据
<源表临时表-cur>
-- 3 今天全部开链的数据，即包含今天全新插入、数据发生变化的记录
Insert Into <临时表-增量-ins>
Select 不含开闭链字段***
From <源表临时表-cur>
where (不含开闭链字段***) not in
   (Select 不含开闭链字段***
 From <临时表-开链-pre>
   );
-- 4 今天需要闭链的数据，即今天发生变化的记录
Insert into <临时表-增量-upd>
Select 不含开闭链字段***,开始时间
From <临时表-开链-pre>
where (不含开闭链字段***) not in
   (Select 不含开闭链字段***
 From <临时表-开链-cur>
   );
-- 5 更新闭链数据，即历史记录闭链（删除-插入替代更新）
DELETE FROM <目标表>
WHERE (PK***) IN
(Select PK*** From <临时表-增量-upd>)
AND 结束日期=date'<最大日期>';
INSERT INTO <目标表>
      (不含开闭链字段***,开始时间,结束日期)
Select 不含开闭链字段***,开始时间,date'<数据日期>'
From <临时表-增量-upd>;
-- 6 插入开链数据，即当日新增记录
INSERT INTO <目标表> .
      (不含开闭链字段***,开始时间,结束日期)
Select 不含开闭链字段***,date'<数据日期>',date'<最大日期>'
From <临时表-增量-ins>;
```

###### 增量拉链模式

增量拉链，目的是追踪数据增量变化历史，根据PK比对新拉一条开链数据；

算法实现逻辑：提取上日开链数据；PK相同变化记录，关闭旧记录链，开启新记录链；PK不同，源表存在，新增开链记录

```sql
--   1. 提取当前有效记录
Insert into <临时表-开链-pre> (不含开闭链字段***)
Select 不含开闭链字段***
From <目标表>
Where 结束日期 =date'<最大日期>';
--   2. 提取当日源系统增量记录
<源表临时表-cur>
--   3. 提取当日源系统新增记录
Insert into <临时表-增量-ins>
Select 不含开闭链字段***
From <临时表-开链-cur>
where (***PK***) not in
  (select ***PK*** from <临时表-开链-pre>);
--   4. 提取当日源系统历史变化记录
Insert into <临时表-增量-upd>
Select 不含开闭链字段***
From <临时表-开链-cur>
inner join <临时表-开链-pre>
on (***PK 等值***)
where (***变化字段 非等值***);
--   5. 更新历史变化记录，关闭历史旧链，开启新链
update <目标表> AS T1
SET <***变化字段 S1赋值***>,结束日期 = date'<数据日期>'
FROM <临时表-增量-upd> AS S1
WHERE ( <***PK 等值***> )
AND   T1.结束日期 =date'<最大日期>'
;
INSERT INTO <目标表>
      (不含开闭链字段***,开始时间,结束日期)
SELECT 不含开闭链字段***,date'<数据日期>',date'<最大日期>'
FROM <临时表-增量-upd>;
--   6. 插入全新开链数据
INSERT INTO <目标表>
      (不含开闭链字段***,开始时间,结束日期)
SELECT 不含开闭链字段***,date'<数据日期>',date'<最大日期>'
FROM <临时表-增量-ins>;
```

###### 增删拉链模型

主要是利用业务字段跟踪增量数据中包含删除的变化历史。

算法实现逻辑：提取上日开链数据；提取源表非删除记录；PK相同变化记录，关闭旧记录链，开启新记录链；PK比对，源表存在，新增开链记录；提取源表删除记录；PK比对，旧开链记录存在，关闭旧记录链；

###### 全量增删拉链模型

主要是利用业务字段跟踪全量数据中包含删除的变化历史。

算法实现逻辑：提取上日开链数据；提取源表非删除记录；PK相同变化记录，关闭旧记录链，开启新记录链；PK比对，源表存在，新增开链记录；提取源表删除记录；PK比对，旧开链记录存在，关闭旧记录链；PK比对，提取旧开链存在但源表不存在记录，关闭旧记录链；

###### 自拉链模型

主要将流水表数据转化成拉链表数据。

算法实现逻辑：借助源表业务日期字段，和目标表开链、闭链日期比对，首尾相接，拉出全历史拉链；

#### 数据同步方案

##### 关系型数据库之间

全量同步，比如从oracle数据库中同步一张表的数据到Mysql中，通常的做法就是 分页查询源端的表，然后通过 jdbc的batch 方式插入到目标表，这个地方需要注意的是，分页查询时，一定要按照主键id来排序分页，避免重复插入。

![](../picture/2/339.png)

基于数据文件导出和导入的全量同步，这种同步方式一般只适用于同种数据库之间的同步，如果是不同的数据库，这种方式可能会存在问题。

###### 基于触发器的增量同步

增量同步一般是做实时的同步，早期很多数据同步都是基于关系型数据库的触发器trigger来做的。使用触发器实时同步数据的步骤：

A、 基于原表创触发器，触发器包含insert，modify，delete 三种类型的操作，数据库的触发器分Before和After两种情况，一种是在insert，modify，delete 三种类型的操作发生之前触发（比如记录日志操作，一般是Before），一种是在insert，modify，delete 三种类型的操作之后触发。

B、 创建增量表，增量表中的字段和原表中的字段完全一样，但是需要多一个操作类型字段（分表代表insert，modify，delete 三种类型的操作），并且需要一个唯一自增ID，代表数据原表中数据操作的顺序，这个自增id非常重要，不然数据同步就会错乱。

C、 原表中出现insert，modify，delete 三种类型的操作时，通过触发器自动产生增量数据，插入增量表中。

D、处理增量表中的数据，处理时，一定是按照自增id的顺序来处理，这种效率会非常低，没办法做批量操作，不然数据会错乱。 有人可能会说，是不是可以把insert操作合并在一起，modify合并在一起，delete操作合并在一起，然后批量处理，我给的答案是不行，因为数据的增删改是有顺序的，合并后，就没有顺序了，同一条数据的增删改顺序一旦错了，那数据同步就肯定错了。

![](../picture/2/340.png)

###### 基于时间戳的增量同步

A、首先我们需要一张临时temp表，用来存取每次读取的待同步的数据，也就是把每次从原表中根据时间戳读取到数据先插入到临时表中，每次在插入前，先清空临时表的数据

B、我们还需要创建一个时间戳配置表，用于存放每次读取的处理完的数据的最后的时间戳。

C、每次从原表中读取数据时，先查询时间戳配置表，然后就知道了查询原表时的开始时间戳。

D、根据时间戳读取到原表的数据，插入到临时表中，然后再将临时表中的数据插入到目标表中。

E、从缓存表中读取出数据的最大时间戳，并且更新到时间戳配置表中。缓存表的作用就是使用sql获取每次读取到的数据的最大的时间戳，当然这些都是完全基于sql语句在kettle中来配置，才需要这样的一张临时表。

![](../picture/2/341.png)

##### 大数据时代下的数据同步

###### 基于数据库日志的同步

数据库都支持了主从自动同步，尤其是mysql，可以支持多主多从的模式。mysql的主从同步的过程是这样的。

A、master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看）；

B、slave将master的binary log events拷贝到它的中继日志(relay log)；

C、slave重做中继日志中的事件，将改变反映它自己的数据。

阿里巴巴开源的canal就完美的使用这种方式，canal 伪装了一个Slave 去喝Master进行同步。

A、 canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议

B、 mysql master收到dump请求，开始推送binary log给slave(也就是canal)

C、 canal解析binary log对象(原始为byte流)

![](../picture/2/342.png)

###### 基于BulkLoad的数据同步

比如从hive同步数据到hbase。我们有两种方式可以实现，

A、 使用spark任务，通过HQl读取数据，然后再通过hbase的Api插入到hbase中。

但是这种做法，效率很低，而且大批量的数据同时插入Hbase，对Hbase的性能影响很大。

在大数据量的情况下，使用BulkLoad可以快速导入，BulkLoad主要是借用了hbase的存储设计思想，因为hbase本质是存储在hdfs上的一个文件夹，然后底层是以一个个的Hfile存在的。HFile的形式存在。

B、 BulkLoad实现的原理就是按照HFile格式存储数据到HDFS上，生成Hfile可以使用hadoop的MapReduce来实现。如果不是hive中的数据，比如外部的数据，那么我们可以将外部的数据生成文件，然后上传到hdfs中，组装RowKey，然后将封装后的数据在回写到HDFS上，以HFile的形式存储到HDFS指定的目录中。