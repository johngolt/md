

##### 数据应用

操作型处理，叫联机事务处理OLTP，也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理。
分析型处理，叫联机分析处理OLAP一般针对某些主题的历史数据进行分析，支持管理决策

![](../picture/1/208.png)

`OLAP`的多维分析操作包括：钻取、上卷、切片、切块以及旋转。

![](../picture/1/209.png)

`OLAP`按存储器的数据存储格式分为ROLAP、MOLAP和 HOLAP。

- 多维OLAP，传统的OLAP分析方式，数据存储在多维数据集中

- 关系OLAP，以关系数据库为核心，以关系型结构进行多维数据的表示，通过SQL的where条件以呈现传统OLAP的切片、切块功能
- 混合OLAP，将MOLAP和ROLPA的优势结合起来，以获得更快的性能

###### 多维OLAP

![](../picture/2/201.png)

处理流程：对原始数据做数据预处理，预处理后的数据存至数据仓库， 用户的请求通过OLAP server查询数据仓库中的数据。

MOLAP的优点和缺点都来自于其数据预处理环节。数据预处理，将原始数据按照指定的计算规则预先做聚合计算，这样避免了查询过程中出现大量的临时计算，提升了查询性能，同时也为很多复杂的计算提供了支持。但是这样的预聚合处理，需要预先定义维度，会限制后期数据查询的灵活性；如果查询工作涉及新的指标，需要重新增加预处理流程，损失了灵活度，存储成本也很高；同时，这种方式不支持明细数据的查询。

###### ROLAP

![](../picture/2/202.png)

处理流程：用户的请求直接发送给OLAP server；OLAP serve将用户的请求转换成关系型操作算子：①通过SCAN扫描原始数据，②在原始数据基础上做过滤、聚合、关联等处理；将计算结果返回给用户

ROLAP不需要进行数据预处理，因此查询灵活，可扩展性好。这类引擎使用MPP架构 ( 与Hadoop相似的大型并行处理架构，可以通过扩大并发来增加计算资源 )，可以高效处理大量数据。但是当数据量较大或query较为复杂时，查询性能也无法像MOLAP那样稳定。所有计算都是临时发生，因此会耗费更多的计算资源。

###### HOLAP

混合OLAP，是MOLAP和ROLAP的一种融合。当查询聚合性数据的时候，使用MOLAP技术；当查询明细数据时，使用ROLAP技术。在给定使用场景的前提下，以达到查询性能的最优化。

###### 分库分表

IO瓶颈：①磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -> 分库和垂直分表；②网络IO瓶颈，请求的数据太多，网络带宽不够 -> 分库。

CPU瓶颈：①SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作 -> SQL优化，建立合适的索引，在业务Service层进行业务计算。②单表数据量太大，查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈 -> 水平分表。

**水平分库**：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。库多了，io和cpu的压力自然可以成倍缓解。

![](../picture/2/203.png)

结果：每个库的结构都一样；每个库的数据都不一样，没有交集；所有库的并集是全量数据；

场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。

**水平分表**：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。

![](../picture/2/204.png)

结果：每个表的结构都一样；每个表的数据都不一样，没有交集；所有表的并集是全量数据；

场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。

**垂直分库**：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。

![](../picture/2/205.png)



结果：每个库的结构都不一样；每个库的数据也不一样，没有交集；所有库的并集是全量数据；

场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。

**垂直分表**：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。

![](../picture/2/206.png)

结果：每个表的结构都不一样；每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；所有表的并集是全量数据；

场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。

##### 数据分析指南

![](../picture/2/184.png)

数据指标定义了你数据分析目的（数据分析往往是为了提升某个数据指标或降低某个数据指标，发现潜藏问题、寻找潜藏机会），而数据收集则给数据分析提供了基础。

![](../picture/2/150.png)

数据指标：对当前业务有参考价值的可统计数据。数据指标对于产品而言就是说什么数据能衡量你们业务的好坏？什么数据对于你们产品是十分重要的？比如用户数、订单数、销售额、浏览数。数据指标可能有一个或多个没有固定约束，依据业务需求定义。

###### 定义指标的方法

1. 确认模块或产品特性：确认与模块特性相关的关键指标。市面上的产品或功能基本能用以下几个模块进行划分，大家在使用时可进行相似归类，套用这个模版。

![](../picture/2/151.png)

内容：内容类型产品主要关注用户使用时长和频次。
常用指标：浏览数、浏览时长、内容互动情况（弹幕、评论、点赞）

社交：社交类型产品主要关注用户与用户之间的关系密度（紧密、多少）、和用户活跃程度。
常用指标：发布量（社区使用）、互动量、关系密度（关注用户数、发送消息数）

工具：工具类型产品主要关注用户使用频次和使用完成度。
常用指标：使用量、频次、流程达成率（目标产品的用户流程较为简单，查看用户是否完成整个流程）

交易：交易类型产品主要关注用户交易规模和整个交易流程的转化率。
常用流程：详情页转化率（核心场景转化率）、金额（总交易规模）、客单价、复购率

2. 确认核心业务：确认体现核心业务健康程度的指标。其实上面的指标定义方法可以涵盖大多部分使用场景，但是如果你是为你们平台制定一个总指标的时候，那就需要用核心业务确认总指标。确认核心业务的方法：平台靠什么盈利。

###### 数据收集方法

数据收集主要是需要开发同学来进行埋点，我们需要定义埋在哪里。定义数据埋点我梳理了有以下两种方法：一种基于业务流程，一种基于功能被使用的情况，根据业务需求选择即可。

1. 以业务流程进行埋点，就是梳理业务流程，再统计各流程的数据。这种埋点方式可以发现用户前后的两个环节是否有巨大断层，或者远低或远高于行业水平，从而优化各个环节的转化率（其实就是漏斗）。

适用场景：页面层级清晰有明确的业务流程，每个页面有明确的业务目标（下单、支付）。使用方法：梳理业务流程后在各个页面或各个行为进行埋点即可。做漏斗的时候，记住用户行为一定是有连贯性的、有顺序的、有时间限制的，基于用户还是事件要想清楚。    

![](../picture/2/152.png)

中间就是根据业务流程梳理的需要统计的页面。左边是根据事件进行埋点得到的数据，右边为真实用户数据（去重后），就是告诉一下大家基于用户/事件得到的数据是不同的。当然事件和用户可以都进行统计，这样可以算出其他的一些数据，比如用户平均浏览多少个商品、平均浏览多少个分类、购买成功页面有多少用户进行分享。

2. 以功能模块拆解进行埋点。功能模块拆解，你们也可以理解为对对应数据指标的细化。以社交模块为例，直接通过脑图的方式进行说明，这种埋点方式可以体现功能模块的健康程度。

![](../picture/2/153.png)

收集数据时如数据有明显的周期性则以该周期作为单位进行收集和比较。如某应用周末用户活跃度明显上升，则建议以周为单位进行收集。与往期数据对比时，建议同比上一周的数据或本周六的数据同比上周六的数据，这样可减少数据之间的干扰性。



#### 数据指标

##### 目的

通过指标体系监测业务发展的状况，最大的价值就是高效利用时间，把时间花在解决问题上，而不是寻找问题上，从而提高整体的人效。数据指标常用于评价产品业务的好坏，通过对数据指标的拆解能够得出产品、策略、运营等各方面目前存在的问题，从而得出优化方向。非体系化的指标通常是单点分析，无法串联更多关联指标进行全局的分析评估，而体系化的指标则可以综合不同的指标不同的维度串联起来进行全面的分析，会更快的发现目前产品和业务流程存在的问题。

指标体系的输出结果应当是一份指标字典和对应的Dashboard展示，需要至少满足以下要求：

- 成体系化的指标监控系统，能够从多维度了解业务发展的现状
- 在业务发展出现问题时能够快速定位问题所在
- 高效地为团队提供数据支持

##### 指标类型及命名

在构建指标体系的过程中，首要动作就是明确指标的分类以及约束指标命名方式，使各个指标能够做到见名知意、减少沟通成本，这里我们按照阿里对指标的划分规范指标命名：

指标分为原子指标和派生指标。

原子指标是基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，是具有明确业务含义的名词 ，体现明确的业务统计口径和计算逻辑，例如支付金额。

- 原子指标=业务过程+度量
- 派生指标=时间周期+修饰词+原子指标，派生指标可以理解为对原子指标业务统计范围的圈定。

![](../picture/2/173.png)

业务板块：比数据域更高维度的业务划分方法，适用于特别庞大的业务系统。

业务过程：指企业的业务活动事件，如下单、支付、退款都是业务过程，请注意，业务过程是一个不可拆分的行为事件，通俗的讲，业务过程就是企业活动中的事件。

修饰类型：是对修饰词的一种抽象划分。修饰类型从属于某个业务域，如日志域的访问终端类型涵盖无线端、PC端等修饰词。

修饰词：指出了统计维度以外指标的业务场景限定抽象，修饰词隶属于一种修饰类型，如果在日志域的访问终端类型下，有修饰词PC端、无线端等。

时间周期：用来明确数据统计的时间范围或者时间点，如最近30天、自然周、截至当日等。

度量/原子指标：原子指标和度量含义相同，基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，具有明确业务含义的名词，通常是业务过程+度量组合而成，如支付金额。

维度：维度是度量的环境，用来反映业务的一类属性，这类属性的集合构成一个维度，也可以成为实体对象。维度属于一个数据域，如地理纬度、时间维度。例如， 在分析交易过程时，可以通过买家、卖家、商品和时间等维度描述交易发生的环境。

派生指标：派生指标=一个原子指标+多个修饰词（可选）+时间周期。可以理解为对原子指标业务统计范围的圈定。如原子指标：支付金额，最近一天海外买家支付金额则为派生指标（最近1天为时间周期，海外为修饰词，买家作为维度，而不作为修饰词）

![](../picture/2/174.png)

结果性指标和过程性指标

结果性指标，比如电商场景下的 GMV 或订单量，它通常是业务漏斗的底部，是一个不可更改的、后验性的指标。

过程性指标，可以简单理解为我到达这个结果之前经过的路径，以及通过这个路径去衡量转化好坏的过程，它是可干预的，而且通常是“用户行为”。

在实际的业务运营过程中，不仅要关注结果性指标，更要关注过程性指标，通过优化过程性指标便能够更加有效的达成结果性指标。

核心指标应当是结果性指标，然后在核心指标的基础上拆解过程性指标并纵向划分层级，在此基础上再划分层级之间的关系，通过层次划分，最终实现我们需要的效果。

![](../picture/2/175.png)

##### 指标体系搭建

搭建指标体系的时候，横向使用OSM模型，纵向进行三级指标分级。

###### 横向选择数据指标

选取数据指标是需要有方向性的，需要针对业务现状选取最能代表业务发展状态的指标，在这方面有成熟的模型可以参考，这里我们使用OSM模型来选取指标。

OSM模型分别代表业务目标、业务策略、业务度量。

O：用户使用产品的目标是什么？产品满足了用户的什么需求？业务的核心目标是什么？

S：为了达成上述目标采取的策略是什么？

M：这些策略随之带来的数据指标变化有哪些？

![](../picture/2/176.png)

搭建指标体系的第一步，应该先明确产品的类型，明确业务究竟是什么，目标是什么。梳理出业务流程，形成一个指标体系框架。不同业务类型的产品会有不同的指标体系框架。例如电商类产品，指标框架可能涵盖：

![](../picture/2/133.png)

 而o2o类产品，它的框架可能涵盖：(以下指标均可根据o2o业务类型，拆分买/卖家、司机/乘客 等多端) 

![](../picture/2/134.png)

###### 纵向划分数据指标层级 

基于以上选择的数据指标，再对数据指标进行层级划分，划分指标层级能够帮助公司搭建一套完整的**数据监控指标体系**，从而及时发现业绩的升高或降低，以及产生的原因，节省花在寻找问题上的时间。

指标分级可以帮助我们更高效的去定位问题，去验证你的方法论，无需每次都要思考要去看哪些指标。

- 一级指标：**公司战略层面指标**，必须是全公司都认可的、衡量业绩的核心指标。它可以直接指引公司的战略目标，衡量公司的业务达成情况，本质上需要管理层和下级员工的双向理解、认同，且要易于沟通传达。比如公司的销售额，或者社交产品的活跃度。
- 二级指标：**业务策略层面指标**，二级指标是一级指标的路径指标，一级指标发生变化的时候，我们通过查看二级指标，能够快速定位问题的原因所在。比如uv、转化率、客单价，通过这三个指标可以快速定位销售额降低的原因。
- 三级指标：**业务执行层面指标**，三级指标是对二级指标的路径的拆解，即是二级指标的过程性指标。通过三级指标，可以高效定位二级指标波动的原因，并可以快速做出相应的动作。这一步会基于历史经验进行拆解，拆解时可以试着不断询问自己为了实现二级指标我需要做哪些事情？这些事对应的指标是什么？

根据以上原则拆分指标如下(指标都为日度汇总指标)：

![](../picture/2/177.png)

##### 搭建数仓

 指标体系方案敲定后，就可开始着手整理底层数据的存储逻辑，明确每个字段要从哪里获取，每张表应该涵盖哪些指标哪些字段维度。这个过程可能会出现很多问题，例如1、想做的的指标没有埋点所以无法获取，2、有埋点但是数据未传 3、数据缺失、错误严重。我们需要整理出这些存在的问题并将问题归类，找到相应数据仓库、埋点研发负责的部门寻求配合，沟通存在的问题并商定问题的解决方案，明确协作的过程及责任划分，确认排期。这个过程中，建议每周将指标体系搭建项目做一次进度汇报，让相关部门及上级了解目前具体的项目进展，促进部门之间的配合，有利于项目正常进行。

搭建好了指标体系，已经梳理出了需要的指标，高效的计算出我们需要的指标就需要构建数仓，通过ETL过程对数据进行多维度计算汇总，再经由Bi产品可视化展现，最终产出我们需要的指标体系。并且这个数仓需要满足幂等性，即多次复核计算的结果都应该是相同的。

###### 划分数据域

数据仓库是面向主题的应用。数据仓库模型设计除横向的分层外，通常也需要根据业务情况进行纵向划分数据域。数据域是联系较为紧密的数据主题的集合，是业务对象高度概括的概念层次归类，目的是便于数据的管理和应用。

数据域是指面向业务分析，将业务过程或者维度进行抽象的集合。为保障整个体系的生命力，数据域需要抽象提炼，并长期维护更新。在划分数据域时，既能涵盖当前所有的业务需求，又能让新业务在进入时可以被包含进已有的数据域或扩展新的数据域。数据域的划分工作可以在业务调研之后进行，需要分析各个业务模块中有哪些业务活动。

数据域可以按照用户企业的部门划分，也可以按照业务过程或者业务板块中的功能模块进行划分。例如A公司电商营销业务板块可以划分为如下数据域，数据域中每一部分都是实际业务过程经过归纳抽象之后得出的。

![](../picture/2/181.png)

###### 构建总线矩阵

明确每个数据域下有哪些业务过程后，即可构建总线矩阵。同时需要明确业务过程与哪些维度相关，并定义每个数据域下的业务过程和维度。构建总线矩阵的重点在于：

- 明确业务过程所属的数据域
- 明确业务过程与维度的关系

基于以上两点，宏观上构建业务主题与数据域之间的关系，微观上构建业务主题中的业务过程与维度之间的关系。

1.宏观业务矩阵

宏观矩阵是业务主题和数据主题的关系，由于社区数仓仅涉及社区业务主题，故这里仅放置社区涉及到的业务过程。

![](../picture/2/179.png)

2.微观业务矩阵

微观矩阵是数据主题和维度的关系。

在构建微观业务矩阵的时候，需要结合对业务过程的分析定义维度，根据业务的不同形态需要从不同的维度进行分析，这个维度的定义需要结合业务场景与分析指标，最终定义如下：

![](../picture/2/180.png)

基于以上得到的总线矩阵，我们可以进行如下模型的设计：

- 明细模型设计：设计一致性维表DIM和一致性事实表DWD

- 汇总模型设计：设计公用汇总层DWS和应用汇总层ADS

###### 确定统计指标

这一步需要依据之前使用OSM模型和指标分层构建的指标体系，对数据进行计算，标准化命名，然后将涉及到的指标计算出来。

###### 数仓分层

数仓分层的目的在于我们希望数据的流转能够更加有序可控，减少重复开发，统一数据口径，且能够及时有效的响应多样的数据需求，参照如下结构，将数据进行组织：

 ODS (Operation Data Store) 层：从日志或者业务DB传输过来的原始数据，传统的离线数仓做法也有直接用CDC (Change Data Capture) 工具周期同步到数仓里面。用一套统一的Kafka来承接这个角色，可以让数据更实时的落入数仓，也可以在这一层统一实时和离线的。

**DWD层**：明细事实层，这一层的数据应该是经过清洗的，干净的、准确的数据，它包含的信息和ODS层相同，但是它遵循数仓和数据库的标准Schema定义。

**DWS层**：主题汇总层，这一层可能经过了轻度的聚合，可能是星型或雪花模型的结构数据，这一层已经做了一些业务层的计算，用户可以基于这一层，计算出数据服务所需数据。这一步可以拆分两层：

- DWM层基于明细事实表的维度进行日度汇总
- DWS层基于常用分析维度进行的数据汇总

按照以下层级调用标准进行分层计算：

- 禁止逆向调用
- 避免同层调用
- 优先使用公共层
- 避免跨层引用

![](../picture/2/178.png)

###### 输出指标字典

数据在经过ETL之后就计算出了我们需要的指标，但是在数据的计算过程中，我们会遇到很多计算口径的问题，需要我们和运营、技术、产品一起多次明确口径。

比如用户互动中已删除的点赞算不算点赞、已删除的评论算不算互动等类似问题。。。

故，在最后阶段，我们要将计算过程中每一个指标的计算口径，异常值的处理等等输出一份指标字典，以便我们和运营之间进行沟通。 

当然，这一步也可以在构建完纵向指标层级之后就进行输出，但是由于我们无法提前预知计算过程中的问题，所以还是建议在指标体系搭建的最后阶段输出准确的指标字典。 

###### BI层展示

展示层需要满足以下功能：

- 能够多角度的描述业务当前的运营状态
- 能够从时间、平台、人群多维度分析业务
- 能够快速获取历史数据通过excel灵活分析
- 能够了解对应指标的含义
- 能够关注到核心链路

此外，将所有数据展示在同一张DashBoard上肯定会是不现实的，所以需要按照分析主题将DashBoard规划为以下层级：

1. 整体业务层级：该层级关注当前业务状态的核心主题，即指标体系中的第一第二层级数据
2. 业务执行层级：该层级关注具体业务专题的结果指标及路径指标，即指标体系中的第二和第三层级数据

##### Hive

hive是基于Hadoop构建的一套数据仓库分析系统，它提供了丰富的SQL查询方式来分析存储在Hadoop分布式文件系统中的数据：可以将结构化的数据文件映射为一张数据库表，并提供完整的SQL查询功能；可以将SQL语句转换为MapReduce任务运行，通过自己的SQL查询分析需要的内容，这套SQL简称Hive SQL，使不熟悉mapreduce的用户可以很方便地利用SQL语言‘查询、汇总和分析数据。它与关系型数据库的SQL略有不同，但支持了绝大多数的语句如DDL、DML以及常见的聚合函数、连接查询、条件查询。
hive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL 的hiveQL 语言实现数据查询，所有hive 的数据都存储在Hadoop 兼容的文件系统中。hive 在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS 中hive 设定的目录下，因此，hive 不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。
hive中包含以下四类数据模型：表(Table)、外部表(External Tablc)、分区(Partition)、桶(Bucket)。  

- hive中的Table和数据库中的Table在概念上是类似的。在hive中每一个Table都有一个相应的目录存储数据。
- 外部表是一个已经存储在HDFS中，并具有一定格式的数据。使用外部表意味着hive表内的数据不在hive的数据仓库内，它会到仓库目录以外的位置访问数据。外部表和普通表的操作不同，创建普通表的操作分为两个步骤，即表的创建步骤和数据装入步骤。在数据的装入过程中，实际数据会移动到数据表所在的hive数据仓库文件目录中，其后对该数据表的访问将直接访问装入所对应文件目录中的数据。删除表时，该表的元数据和在数据仓库目录下的实际数据将同时删除。外部表的创建只有一个步骤，创建表和装人数据同时完成。外部表的实际数据存储在创建语句`IOCATION`参数指定的外部HDFS文件路径中，但这个数据并不会移动到hive数据仓库的文件目录中。删除外部表时，仅删除其元数据，保存在外部HDFS文件目录中的数据不会被删除。 
- 分区对应于数据库中的分区列的密集索引，但是hive中分区的组织方式和数据库中的很不相同。在hive中，表中的一个分区对应于表下的一个目录，所有的分区的数据都存储在对应的目录中。 
- 桶对指定列进行哈希(hash)计算，会根据哈希值切分数据，目的是为了并行，每一个桶对应一个文件。

数据库管理系统是一种操纵和管理数据库的大型软件，用于建立、使用和维护数据库，简称DBMS。它对数据库进行统一的管理和控制，以保证数据库的安全性和完整性。用户通过DBMS访问数据库中的数据，数据库管理员也通过DBMS进行数据库的维护工作。它可以支持多个应用程序和用户用不同的方法在同时或不同时刻去建立，修改和询问数据库。大部分DBMS提供数据定义语言DDL和数据操作语言DML，供用户定义数据库的模式结构与权限约束，实现对数据的追加、删除等操作。目前市场上比较流行的数据库管理系统产品主要是Oracle、IBM、Microsoft和Sybase、Mysql等公司的产品。

Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。
Hive利用HDFS存储数据，利用MapReduce查询数据。由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，Hive在加载的过程中不会对数据本身进行任何修改，而只是将数据内容复制或者移动到相应的HDFS目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive中不支持对数据的改写和添加，所有的数据都是在加载的时候中确定好的。
Hive在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些Key建立索引。Hive要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于 MapReduce 的引入， Hive 可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 Hive 不适合在线数据查询。

物理表：物理表是具体某个数据源中的一张表。对于mysql就是一个table，对于Hbase可以是一张hbase表，对于ES是一个索引。mysql， Hbase和ES这些物理表必须要有合理的key。特殊的物理表不含有key逻辑表：逻辑表可以理解为数据库中的视图，是一张虚拟表。可以映射到一张物理表，也可以由多张物理表组成，这些物理表可以来自于不同的数据源。

关系型数据库，是指采用了关系模型来组织数据的数据库，其以行和列的形式存储数据，以便于用户理解，关系型数据库这一系列的行和列被称为表，一组表组成了数据库。用户通过查询来检索数据库中的数据，而查询是一个用于限定数据库中某些区域的执行代码。关系模型可以简单理解为二维表格模型，而一个关系型数据库就是由二维表及其之间的关系组成的一个数据组织。

如今的 Hadoop 由两大部分组成。第一部分是名为 Hadoop 分布式文件系统（HDFS）的大规模存储系统，该系统能高效、低成本地存储数据，且针对大数据的容量、多样性和速度进行了优化。第二部分是名为 YARN 的计算引擎，该引擎能在 HDFS 存储的数据上运行大量并行程序。MapReduce 只是 Hadoop 集群处理数据的诸多方式之一。Spark 可以替代 MapReduce。
Hadoop 分布式文件系统，支持对应数据高吞吐量访问的分布式文件系统；
（3）  用于作业调度和集群资源管理的 Hadoop YANRN 框架；
（4）  Hadoop MapReduce ，基于  YARN  的大数据并行处理系统  

处理无界数据通常要求以特定顺序（例如事件发生的顺序）摄取事件，以便能够推断结果完整性。有界流具有定义的开始和结束。可以在执行任何计算之前通过摄取所有数据来处理有界流。处理有界流不需要有序摄取，因为可以始终对有界数据集进行排序。有界流的处理也称为批处理。



数据抽取是指把ODS源数据抽取到DW中，然后处理成展示给相关人员查看的数据

源数据：用户访问日志、自定义事件日志、操作日志、业务日志
抽取频次：如果没有特殊要求可以一天一次，但是需要避开拉去日志的高峰期；对于有实时性要求的日志，可以一小时一次，或者直接使用kafka等相关工具收集，需要考虑到系统能否承受
抽取策略：由于数据量较大，一般都是采用增量抽取，但是对于一些特殊场景的数据，比如订单数据，由于订单的状态会发生变化，并且订单的量级是可预知和相对较少的，就需要采用全量拉取的策略对于增量拉取的日志，如果是文件类型，可以在文件名称上追加日期，例如 server_log_2018082718.log，这样就可以满足按小时拉取的需求，对于源数据的保留，考虑到突发情况，服务器上的源数据至少要保证2天以上的时间
二、数据转换、清洗
　一般情况下，数据仓库分为ODS、DW两部分。通常的做法是从业务系统到ODS做清洗，将脏数据和不完整数据过滤掉，在从ODS到DW的过程中转换，进行一些业务规则的计算和聚合。

#### 总体规划

![](../picture/1/278.png)

##### 数据集成

首先我们需要确认平台接入哪些数据，确认数据接入的方式是实时接入还是离线抽取。离线抽取的话是全量抽取还是增量抽取。抽取频次数每天抽取还是每小时抽取。

![](../picture/1/265.png)

实时接入可以使用kafka实时写入数据到HDFS集群上。

![](../picture/1/266.png)

离线数据可以使用Sqoop抽取关系型数据库到HDFS。

##### 模型建设

模型建设是数据中台的重要部分，可以说数据中台的成败在于模型建设的好坏。模型分为我们常指的数据仓库的分析模型和我们的一些通用算法模型。

###### 数仓模型

数据接入到数据仓库中，我们需要对数据进行加工，按照我们规划的业务域，对各个业务的数据汇总聚合，形成我们的数据模型。

![](../picture/1/279.png)

原始数据ODS，经过清洗成为数仓中的明细数据DWS和维度数据DIM，各个业务的明细数据按照业务域和维度数据关联形成我们的数据模型DW，不同的DW经过聚合形成各个业务指标数据APP层。

在数仓的建设中我们声明业务粒度，粒度能够精确的表明业务含义。同时还要确定维度，是用户维度还是商品维度等，最终形成我们的主数据，也就是模型数据的基础。

###### 算法模型

我们在业务开发过程中会形成一些通用的算法，可以是封装好的随机森林、回归等通用算法，也可以是我们业务算法，比如用户商品推荐算法等。通过把这些算法总结，形成我们的算法模型，供各个业务直接调用。

##### ETL平台

在开发数据模型时，我们必须有一个统一的平台，能够像流水线一样，把数据一步步加工成数据模型。这其中涉及到数据萃取、数据聚合、作业调度等。根据自己的实际业务整理一份需求模板。其中包括数据来源字段，统计口径，任务调度周期，字段mapping，粒度，维度，需求方，开发人，指标类型，优先级等。

##### 数据资产

通俗的来说，我们在数仓中开发的模型就是数据资产，数据资产需要规范的管控和治理。

资产管理最基础的工作是做好元数据的管理，元数据包含了数据的口径，数据模型的释义，模型之间的血缘等等。将元数据和数据模型统一有序的管理起来形成企业的数据资产。

##### 数据服务

数据服务标准：数据结构标准化、在线查询实时化、数据开发可视化。

###### 数据结构标准化

对各个业务板块的数据交互，我们需要提供统一的接口视图，可进行数据的查询、权限管控。

###### 在线查询实时化

对于各业务的调用，我们需要提供指标级数据口径统一的实时数据结果。对于复杂的查询，需要我们优化后端的数据服务，屏蔽繁重的数据存储和计算引擎，对外提供轻量的在线服务接口。

###### 数据开发可视化

提供数据接口的可视化统一管理页面，开发人员通过通过可视化管理API，降低接口理解的难度，易于维护。

用户行为主要包括哪些数据呢？

•用户来源渠道、地区；

•用户的pv、uv、ip、老访问数、新访问数；

•用户停留时间、使用时间及频次、跳出率、回访次数、回访相隔天数；

•用户使用频次分布、时间段分布，平均停留时长；

•用户所使用搜索引擎、关键词、关联关键词和站内关键字；

•用户在页面上的点击量；

•用户进入下一个路径的转化率；

•用户的客单价、订单数、会员购买率；

•用户发视频数，创建企业数等等。

来梳理一下如何分析用户行为数据，来驱动业务增长？

**第一、了解产品业务线的整体用户情况。**

如，pv、日均访问量、用户总数、订单数、会员数、总销售额、用户来源分布及占比、有购买行为的用户数量、用户的客单价、复购率分别是多少？等等整体用户概况数据。

**第二、利用用户行为转化漏斗梳理用户的全行为路径。**

**第三、根据不同的行为进行用户分群，了解人群特征。**

如，完成支付与未完成支付的人群有什么特征？添加购物车与未添加购物车的人群有什么特征？注册用户和非注册用户，分析两者之间的浏览特征等等，

**第四、根据不同时间段维度，了解用户行为习惯。**

如，用户在不同时段的访问量情况分布、活跃情况、新增情况、使用间隔分布等。看出不用时间段的用户行为趋势，通过分析，看出趋势高低的原因，进而优化运营策略，加大或者减少投放费用等，驱动业务增长。

**第五、基于RFM模型进行用户分析。**

RFM模型通过一个客户的近期购买行为、购买的总体频率以及花了多少钱3项指标来描述该客户的价值状况。基于一个理想的客户特征来衡量现实中客户价值的高低，通过此类分析，定位最有可能成为品牌忠诚客户的群体，让我们把主要精力放在最有价值的用户身上。进而实现精准的营销以及用户维护，驱动业务增长。

#### 大数据工具

下面分不同层介绍各个技术，当然各个层并不是字面意义上的严格划分，如Hive既提供数据处理功能也提供数据存储功能，但此处将其划为数据分析层中。

##### 数据采集和传输层

Flume
Flume一个分布式、可靠的、高可用的用于数据采集、聚合和传输的系统。常用于日志采集系统中，支持定制各类数据发送方用于收集数据、通过自定义拦截器对数据进行简单的预处理并传输到各种数据接收方如HDFS、HBase、Kafka中。之前由Cloudera开发，后纳入Apache
Logstash
ELK工作栈的一员，也常用于数据采集，是开源的服务器端数据处理管道
Sqoop
Sqoop主要通过一组命令进行数据导入导出的工具，底层引擎依赖于MapReduce，主要用于Hadoop（如HDFS、Hive、HBase）和RDBMS（如mysql、oracle）之间的数据导入导出
Kafka
分布式消息系统。生产者（producer）——消费者（consumer）模型。提供了类似于JMS的特性，但设计上完全不同，不遵循JMS规范。如kafka允许多个消费者主动拉取数据，而JMS中只有点对点模式消费者才会主动拉取数据。主要应用在数据缓冲、异步通信、汇集数据、系统接偶等方面
Pulsar
pub-sub模式的分布式消息平台，拥有灵活的消息模型和直观的客户端API。类似于Kafka，但Pulsar支持多租户，有着资产和命名空间的概念，资产代表系统里的租户。假设有一个Pulsar集群用于支持多个应用程序，集群里的每个资产可以代表一个组织的团队、一个核心的功能或一个产品线。一个资产可以包含多个命名空间，一个命名空间可以包含任意个主题

##### 数据存储层

HBase
基于Google Bigtable的开源实现，是一个具有高可靠性、高性能、面向列、可伸缩性、典型的key/value分布式存储的nosql数据库系统，主要用于海量结构化和半结构化数据存储。它介于nosql和RDBMS之间，仅能通过行键（row key）和行键的range来检索数据，行数据存储是原子性的，仅支持单行事务（可通过hive支持来实现多表join等复杂操作）。HBase查询数据功能很简单，不支持join等复杂操作，不支持跨行和跨表事务
Kudu
介于HDFS和HBase之间的基于列式存储的分布式数据库。兼具了HBase的实时性、HDFS的高吞吐，以及传统数据库的sql支持
HDFS
分布式文件存储系统，具有高容错（high fault-tolerant）、高吞吐（high throughput）、高可用（high available）的特性。HDFS非常适合大规模数据集上的应用，提供高吞吐量的数据访问，可部署在廉价的机器上。它放宽了POSIX的要求，这样可以实现流的形式访问（文件系统中的数据。主要为各类分布式计算框架如Spark、MapReduce等提供海量数据存储服务，同时HDFS和HBase底层数据存储也依赖于HDFS

##### 数据分析层

Spark
Spark是一个快速、通用、可扩展、可容错的、内存迭代式计算的大数据分析引擎。目前生态体系主要包括用于批数据处理的SparkRDD、SparkSQL，用于流数据处理的SparkStreaming、Structured-Streaming，用于机器学习的Spark MLLib，用于图计算的Graphx以及用于统计分析的SparkR，支持Java、Scala、Python、R多种数据语言
Flink
分布式的大数据处理引擎，可以对有限数据流和无线数据流进行有状态的计算。Flink在设计之初就是以流为基础发展的，然后再进入批处理领域，相对于spark而言，它是一个真正意义上的实时计算引擎
Storm
由Twitter开源后归于Apache管理的分布式实时计算系统。Storm是一个没有批处理能力的数据流处理计算引擎，storm提供了偏底层的API，用户需要自己实现很多复杂的逻辑
MapReduce
分布式运算程序的编程框架，适用于离线数据处理场景，内部处理流程主要划分map和reduce两个阶段
Hive
Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供HQL语句（类SQL语言）查询功能，存储依赖于HDFS。支持多种计算引擎，如Spark、MapReduce（默认）、Tez；支持多种存储格式，如TextFile、SequenceFile、RCFile、ORC、Parquet（常用）；支持多种压缩格式，如gzip、lzo、snappy（常用）、bzip2
Tez
支持DAG作业的开源计算框架。相对于MapReduce性能更好，主要原因在于其将作业描述为DAG（有向无环图），这一点与Spark类似
Pig
基于Hadoop的大规模数据分析平台，它包含了一种名为Pig Latin的脚本语言来描述数据流，并行地执行数据流处理的引擎，为复杂的海量数据并行计算提供了一个简单的操作和编程接口。Pig Latin本身提供了许多传统的数据操作，同时允许用户自己开发一些自定义函数用来读取、处理和写数据，该语言的编译器会把类SQL的数据分析请求转换为一系列经过优化处理的MapReduce运算
Mahout
提供一些可扩展的机器学习领域经典算法的实现，Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。通过使用Apache Hadoop 库，可以将Mahout扩展到云中
Phoenix
构建在HBase之上的一个SQL层，能让我们通过标准的JDBC API操作HBase中的数据。Phoenix完全使用Java编写，作为HBase内嵌的JDBC驱动。Phoenix查询引擎会将SQL查询转换为一个或多个HBase scan，并编排执行以生成标准JDBC结果集

##### OLAP引擎

Druid
开源的、基于列存储的、分布式的，适用于实时数据分析的存储系统，能够快速聚合、灵活过滤、毫秒级查询和低延迟数据导入。通过使用Bitmap indexing加速列存储的查询速度，并使用CONCISE算法来对bitmap indexing进行压缩，使得生成的segments比原始文本文件小很多，并且它的各个组成部分之间耦合性低，如果不需要实时数据完全可以忽略实时节点
Kylin
最初由eBayInc.开发并贡献至开源社区的分布式分析引擎。提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，它能在亚秒内查询巨大的Hive表。需要使用者对数仓模型有深度了解，并需构建cube。能够与多种可视化工具，如Tableau，PowerBI等，令用户可以使用BI工具对Hadoop数据进行分析
Impala
提供对HDFS、HBase等数据的高性能、低延迟的交互式SQL查询功能的大数据查询分析引擎，由Cloudera开源。它基于Hive，使用Hive的元数据在内存中计算，具有实时、批处理、高并发等优点
Presto
开源的分布式大数据SQL查询引擎，适用于交互式分析查询。可以将多个数据源的数据进行合并，并且可以直接从HDFS读取数据，在使用前不需要大量的ETL操作

##### 资源管理层

Yarn
Yarn是一个资源调度平台，负责为运算程序分配资源和调度，不参与用户程序内部工作。核心组件包括：ResourceManager（全局资源管理器，负责整个系统的资源管理和分配）、NodeManager（每个节点上的资源和任务管理器）
Kubernetes
又称K8s，为容器化的应用提供资源调度、部署运行、均衡容灾、服务注册、扩容缩容等功能的自动化容器操作的开源平台。具体体现在：自动化容器的部署和复制、随时扩展或收缩容器规模、将容器组织成组，并且提供容器间的负载均衡等。Kubernetes支持docker和Rocket，可以将Docker看成Kubernetes内部使用的低级别组件
Mesos
类似于Yarn，也是一个分布式资源管理平台，为MPI、Spark作业在统一资源管理环境下运行。它对Hadoop2.0支持很好，但国内用的不多

##### 工作流调度器

Oozie
基于工作流引擎的任务调度框架，能够提供能够提供对MapReduce和Pig 任务的调度与协调
Azkaban
由LinkedIn开源，相对Oozie更轻量级。用于在一个工作流内以一个特定顺序运行一组任务，通过一种kv文件格式来建立任务之间的依赖关系并为用户提供了易于使用的web界面来维护和跟踪允许任务的工作流

##### 其他

Ambari
基于web的安装部署工具，支持对大多数的Hadoop组件，如HDFS、MapReduce、Hive、Pig、HBase等的管理和监控
Zookeeper
分布式协调服务即为用户的分布式应用程序提供协调服务，如主从协调、服务器节点动态上下线、统一配置管理、分布式共享锁等，它本身也是一个分布式程序（部署奇数台，只要由半数以上zookeeper节点存活，zookeeper集群就能正常提供服务），它是Google Chubby一个开源实现







数据基础层主要完成的工作包括以下几点：

 

数据采集：把不同数据源的数据统一采集到一个平台上；

数据清洗，清洗不符合质量要求的数据，避免脏数据参与后续数据计算；

数据归类，建立数据目录，在基础层一般按照来源系统和业务域进行分类；

数据结构化，对于半结构化和非结构化的数据，进行结构化；

数据规范化，包括规范维度标识、统一计量单位等规范化操作。

数据中间层最为重要的目标就是把同一实体不同来源的数据打通起来，这是因为当前业务形态下，同一实体的数据可能分散在不同的系统和来源，且这些数据对同一实体的标识符可能不同。此外，数据中间层还可以从行为中抽象关系。从行为中抽象出来的基础关系，会是未来上层应用一个很重要的数据依赖。例如抽象出的兴趣、偏好、习惯等关系数据是推荐、个性化的基础生产资料。

在中间层，为了保证主题的完整性或提高数据的易用性，经常会进行适当的数据冗余。比如某一实事数据和两个主题相关但自身又没有成为独立主题，则会放在两个主题库中；为了提高单数据表的复用性和减少计算关联，通常会在事实表中冗余部分维度信息。