#### 时间序列回归模型

##### 线性模型

$$
y_t = \beta_0 + \beta_1x_{1,t}+\cdots+\beta_kx_{k,t}+\epsilon_t
$$

首先，我们假设预测变量和被预测变量之间的关系基本满足这个线性方程。

其次，我们对误差项$(\epsilon_1,\cdots,\epsilon_T)$做出如下假设：

- 期望为零$E[\epsilon_t]=0$；否则预测结果会产生系统性偏差。
- 随机误差项彼此不相关；否则预测效果会很差，因为这表明数据中尚有很多可用信息没有包含在模型中。
- 与预测变量不相关；若误差项与预测变量相关，则表明模型的系统部分中应该包含更多信息。

为了方便得到预测区间，我们还需要假设随机误差项服从方差为$\sigma^2$的正态分布。

##### 最小二乘估计

可决系数$R^2$评价线性回归模型对数据的拟合程度
$$
R^2 = \frac{\sum{(\hat{y}_t}-\overline{y})^2}{\sum(y_t-\overline{y})^2}
$$
利用模型在测试集上的预测结果来衡量模型好坏比直接根据$R^2$大小来衡量模型更加有效。

另外一个衡量模型拟合效果的指标是残差的标准偏差，通常称之为“残差标准误差”。
$$
\hat{\sigma}_e = \sqrt{\frac{1}{T-k-1}\sum_{t=1}^Te_t^2}
$$
其中， $k$是模型中预测变量的个数。

##### 回归模型的评估

残差项$e_t = y_t-\hat{y}_t$有两个非常有用的性质：

1. $\sum_{t=1}^Te_t=0$
2. $\sum_{t=1}^T{x_{k,t}e_t}=0$

###### 残差的自相关函数图

对于时间序列数据而言，在当前时间段观测到的变量值很可能与历史时段的变量值很相似。因此，当采用回归模型拟合时间序列数据时，残差经常会出现自相关效应。此时，模型违背了残差中无序列自相关的假设，并会导致模型的预测效率低下

另一个用于检验残差自相关的效果较好的检验方法是 Breusch-Godfrey 检验。假如p值小于一个特定值（例如0.05），则表明残差中存在显著的自相关性。

###### 残差直方图

检查残差是否服从正态分布也是很有必要的。它对预测值并不重要，但它可以让我们更加容易的确定预测区间。

残差直方图、残差时序图、ACF图

时序图显示了不同时间下残差的变化，显然存在异方差性。这种异方差性会导致预测区间的不准确。

预测变量与残差关系图：期望残差是随机分布的并且不显示任何规律，还需要对没有加入到模型中的预测变量绘制其与残差的散点图。如果某个残差图显示出明显的规律，则需要将对应的预测变量加入到模型之中

残差与拟合值之间也应没有明显规律。如果观察到明显规律，则残差中可能存在“异方差性”，这意味着残差的方差不是固定的。如果出现异方差性，可能需要对预测变量做对数或者平方根变换



时间序列数据一般都是“不平稳的”；也就是说，时间序列数据没有固定的均值和方差。不平稳的时间序列会导致伪回归。伪回归的特点是高$R^2$值和高残差自相关共存。

##### 高效的预测变量

如果有两个以上的类别，则可以使用多个虚拟变量（需要注意的是，虚拟变量个数应比类别数少1）对变量进行编码。

##### 预测变量的筛选

一个常见的但是不推荐的方法是画出被预测变量和特定的预测变量之间的关系图，如果不能看出明显的相关关系，则删除该预测变量。但这个方法常常会失效，尤其在未考虑其他预测变量时，散点图并不总能正确的反映两个变量之间的关系。

另一种常见的无效方法是对所有预测变量进行多元线性回归，并删除所有$p$值大于0.05的所有变量。统计显著性并不总能表示预测变量的预测价值。因为当两个或者多个预测变量相互关联时，$p$值可能会是错误的结果

对于$CV$，$AIC$，$AICc$和$BIC$准则，它们的值越小越好；而对于调整的可决系数$\overline{R}^2$，我们希望它尽可能的大。采用调整的可决系数可以解决以上问题：
$$
\overline{R}^2 = 1-(1-R^2)\frac{T-1}{T-k-1}
$$
最大化$\overline{R}^2$在筛选变量时一般会比较有效，但当变量数目太多时，效果往往会比较差。

对选择的预测变量使用经典的留一法交叉验证，该过程步骤如下：

1. 将$t$时刻的观测值从数据集中移出，用剩下的数据拟合出模型。然后计算$t$时刻观测值和预测值之间的误差$e_t^* = y_t-\hat{y}_t$。
2. 分别令$t=1,\cdots,T$，重复步骤一。
3. 计算$e_1^*,\cdots,e_T^*$的MSE 。我们称之为 **CV**。

赤池信息准则也是一个重要的方法，我们通常称之为 AIC 准则，其定义如下：
$$
AIC = T\times \log(\frac{SSE}{T}) + 2(k+2)
$$
其中，$T$是观测点的个数；$k$是预测变量的个数。

当$T$值较小时，$AIC$准则总是倾向于选择更多的预测变量，因此出现了修正的$AIC$准则，其定义如下：
$$
AIC_c = AIC + \frac{2(k+2)(k+3)}{T-k-3}
$$
施瓦茨的贝叶斯信息准则，通常被称为 BIC 、 SBIC 或 SC ，其定义如下：
$$
BIC = T\times \log(\frac{SSE}{T}) + (k+2)\log(T)
$$
与 AIC 一样，最小化 BIC 可以选择得到最佳模型。BIC 准则选择出的模型比 AIC 准则选择出的模型具有更少的预测变量。这是因为 BIC 准则对参数个数的惩罚力度更强。

被广泛用于模型筛选，但是由于它倾向于选择具有很多预测变量的模型，因此它并不适用于预测。测。在给定足够多数据情况下， BIC 准则能找出真正完美拟合这些数据的模型，因此统计学家更喜欢用 BIC 准则筛选模型。但是，很少有数据存在完美的模型，即使存在，该模型的预测结果也不一定准确。因此，我们建议使用$AIC_c$、 AIC 或 CV 准则的其中一个，因为他们都是以预测数据为目标。当$T$足够大时，它们会选择出相同的模型。

##### 回归预测

##### 矩阵方程

##### 非线性回归

##### 相关关系、因果关系和预测

当不同变量对被预测变量的影响无法分离时会产生混淆。事实上，任何一对相关预测变量都会有一定程度的混淆，但只有当两预测变量之间的相关性较高时，才把它们当作混淆变量处理。

当两个预测变量彼此高度相关时，就会导致模型出现多重共线性。当预测变量的线性组合与预测变量的另一个线性组合高度相关时，也可能导致多重共线性。在这种情况下，由于两组预测变量提供类似的信息，那么当我们知道第一组预测变量值的同时也会得到很多关于第二组预测变量值的信息。当存在多重共线性时，单个预测变量的回归系数的不确定性会很大。因此，回归系数的统计检验是不可靠的。





我们发现当训练集的数据不是非常多的时候，使用能带来不错的提升；当数据集比较多的时候，有时候也会有帮助，但提升并不会非常明显，那么该操作是怎么做的呢？
1.1.1  基础版
使用有标签的数据集训练得到自己最好的模型（可以是单个也可以是多个），然后对测试集进行预测；
筛选出测试集合中的高概率的预测样本（例如二分类中，我们选出预测概率大于0.99的样本，并标注为1）；
将伪标签样本加入模型一起训练，然后预测提交。
上述这种操作，一般效果不会比直接使用有标签的样本训练效果差，所以早期大家也都是这么用的。
1.1.2  升级版
上面的操作，有一个升级版本，迭代版本。基本的操作是类似的，就是会迭代多轮。
使用有标签的数据集训练得到自己最好的模型（可以是单个也可以是多个），然后对测试集进行预测；
筛选出测试集合中的高概率的预测样本（例如二分类中，我们选出预测概率大于0.99的样本，并标注为1）；
将伪标签样本加入模型一起训练再得到自己最好的模型，然后对测试集进行预测，再回到步骤2.
这个操作，如果有效的话，第一轮和第二轮还是较为明显的，但是一般第三轮之后效果就变化不大了，在某些特定情况下，该操作带来的提升相较于第一版还是挺明显的。
1.1.3  微调版本¶
上面两个版本大多数情况下效果不错，但也有一个问题，就是大家实践中会发现，每次筛选样本的时候，概率阈值较难定，而且影响很大，那么怎么办呢？此处我们再讲述一个微调版本。
使用有标签的数据集训练得到自己最好的模型（可以是单个也可以是多个），然后对测试集进行预测；
不再做筛选，我们把所有预测的样本拿过来，重新训练，训练的时候，我们将loss修改为：loss(训练集合) + a * loss(伪标签集合);
微调a，提交测试。



回归分析的五个基本假设
线性性 & 可加性

假设因变量为Y，自变量为X1，X2，则回归分析的默认假设为Y=b+a1X1+a2X2+ε。
线性性：X1每变动一个单位，Y相应变动a1个单位，与X1的绝对数值大小无关。
可加性：X1对Y的影响是独立于其他自变量（如X2）的。

误差项（ε）之间应相互独立。

若不满足这一特性，我们称模型具有自相关性（Autocorrelation）。

自变量（X1，X2）之间应相互独立。

若不满足这一特性，我们称模型具有多重共线性性（Multicollinearity）。

误差项（ε）的方差应为常数。

若满足这一特性，我们称模型具有同方差性（Homoskedasticity），若不满足，则为异方差性（Heteroskedasticity）。

误差项（ε）应呈正态分布。

假设失效的影响
线性性 & 可加性

若事实上变量之间的关系不满足线性性（如含有X21, X31 项），或不满足可加性（如含有X1⋅X2项），则模型将无法很好的描述变量之间的关系，极有可能导致很大的泛化误差（generalization error）

自相关性（Autocorrelation）

自相关性经常发生于时间序列数据集上，后项会受到前项的影响。当自相关性发生的时候，我们测得的标准差往往会偏小，进而会导致置信区间变窄。
假设没有自相关性的情况下，自变量X的系数为15.02而标准差为2.08。假设同一样本是有自相关性的，测得的标准差可能会只有1.20，所以置信区间也会从(12.94,17.10)缩小到(13.82,16.22)。

多重共线性性（Multicollinearity）

如果我们发现本应相互独立的自变量们出现了一定程度（甚至高度）的相关性，那我们就很难得知自变量与因变量之间真正的关系了。
当多重共线性性出现的时候，变量之间的联动关系会导致我们测得的标准差偏大，置信区间变宽。
采用岭回归，Lasso回归或弹性网（ElasticNet）回归可以一定程度上减少方差，解决多重共线性性问题。因为这些方法，在最小二乘法的基础上，加入了一个与回归系数的模有关的惩罚项，可以收缩模型的系数。
岭回归：=argminβ∈Rp(∥y−Xβ∥22+λ∥β∥22)
Lasso回归：=argminβ∈Rp(∥y−Xβ∥22+λ∥β∥1)
弹性网回归：=argminβ∈Rp(∥y−Xβ∥22+λ1∥β∥1+λ2∥β∥22)
where∥Z∥p=(∑i=1N|Zi|p)(1/p)
异方差性（Heteroskedasticity）

异方差性的出现意味着误差项的方差不恒定，这常常出现在有异常值（Outlier）的数据集上，如果使用标准的回归模型，这些异常值的重要性往往被高估。在这种情况下，标准差和置信区间不一定会变大还是变小。

误差项（ε）应呈正态分布

如果误差项不呈正态分布，意味着置信区间会变得很不稳定，我们往往需要重点关注一些异常的点（误差较大但出现频率较高），来得到更好的模型。


机器学习中的“算法”是在数据上运行以创建机器学习“模型”的过程。
机器学习算法执行“模式识别”。算法从数据中“学习”，或者对数据集进行“拟合”。

机器学习中的“模型”是运行在数据上的机器学习算法的输出。
模型表示机器学习算法所学到的内容。
模型是在训练数据上运行机器学习算法后保存的“东西”，它表示用于进行预测所需的规则、数字和任何其他特定于算法的数据结构。