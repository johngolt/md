#### 时间序列回归模型

##### 线性模型

$$
y_t = \beta_0 + \beta_1x_{1,t}+\cdots+\beta_kx_{k,t}+\epsilon_t
$$

首先，我们假设预测变量和被预测变量之间的关系基本满足这个线性方程。

其次，我们对误差项$(\epsilon_1,\cdots,\epsilon_T)$做出如下假设：

- 期望为零$E[\epsilon_t]=0$；否则预测结果会产生系统性偏差。
- 随机误差项彼此不相关；否则预测效果会很差，因为这表明数据中尚有很多可用信息没有包含在模型中。
- 与预测变量不相关；若误差项与预测变量相关，则表明模型的系统部分中应该包含更多信息。

为了方便得到预测区间，我们还需要假设随机误差项服从方差为$\sigma^2$的正态分布。

##### 最小二乘估计

可决系数$R^2$评价线性回归模型对数据的拟合程度
$$
R^2 = \frac{\sum{(\hat{y}_t}-\overline{y})^2}{\sum(y_t-\overline{y})^2}
$$
利用模型在测试集上的预测结果来衡量模型好坏比直接根据$R^2$大小来衡量模型更加有效。

另外一个衡量模型拟合效果的指标是残差的标准偏差，通常称之为“残差标准误差”。
$$
\hat{\sigma}_e = \sqrt{\frac{1}{T-k-1}\sum_{t=1}^Te_t^2}
$$
其中， $k$是模型中预测变量的个数。

##### 回归模型的评估

残差项$e_t = y_t-\hat{y}_t$有两个非常有用的性质：

1. $\sum_{t=1}^Te_t=0$
2. $\sum_{t=1}^T{x_{k,t}e_t}=0$

###### 残差的自相关函数图

对于时间序列数据而言，在当前时间段观测到的变量值很可能与历史时段的变量值很相似。因此，当采用回归模型拟合时间序列数据时，残差经常会出现自相关效应。此时，模型违背了残差中无序列自相关的假设，并会导致模型的预测效率低下

另一个用于检验残差自相关的效果较好的检验方法是 Breusch-Godfrey 检验。假如p值小于一个特定值（例如0.05），则表明残差中存在显著的自相关性。

###### 残差直方图

检查残差是否服从正态分布也是很有必要的。它对预测值并不重要，但它可以让我们更加容易的确定预测区间。

残差直方图、残差时序图、ACF图

时序图显示了不同时间下残差的变化，显然存在异方差性。这种异方差性会导致预测区间的不准确。

预测变量与残差关系图：期望残差是随机分布的并且不显示任何规律，还需要对没有加入到模型中的预测变量绘制其与残差的散点图。如果某个残差图显示出明显的规律，则需要将对应的预测变量加入到模型之中

残差与拟合值之间也应没有明显规律。如果观察到明显规律，则残差中可能存在“异方差性”，这意味着残差的方差不是固定的。如果出现异方差性，可能需要对预测变量做对数或者平方根变换



时间序列数据一般都是“不平稳的”；也就是说，时间序列数据没有固定的均值和方差。不平稳的时间序列会导致伪回归。伪回归的特点是高$R^2$值和高残差自相关共存。

##### 高效的预测变量

如果有两个以上的类别，则可以使用多个虚拟变量（需要注意的是，虚拟变量个数应比类别数少1）对变量进行编码。

##### 预测变量的筛选

一个常见的但是不推荐的方法是画出被预测变量和特定的预测变量之间的关系图，如果不能看出明显的相关关系，则删除该预测变量。但这个方法常常会失效，尤其在未考虑其他预测变量时，散点图并不总能正确的反映两个变量之间的关系。

另一种常见的无效方法是对所有预测变量进行多元线性回归，并删除所有$p$值大于0.05的所有变量。统计显著性并不总能表示预测变量的预测价值。因为当两个或者多个预测变量相互关联时，$p$值可能会是错误的结果

对于$CV$，$AIC$，$AICc$和$BIC$准则，它们的值越小越好；而对于调整的可决系数$\overline{R}^2$，我们希望它尽可能的大。采用调整的可决系数可以解决以上问题：
$$
\overline{R}^2 = 1-(1-R^2)\frac{T-1}{T-k-1}
$$
最大化$\overline{R}^2$在筛选变量时一般会比较有效，但当变量数目太多时，效果往往会比较差。

对选择的预测变量使用经典的留一法交叉验证，该过程步骤如下：

1. 将$t$时刻的观测值从数据集中移出，用剩下的数据拟合出模型。然后计算$t$时刻观测值和预测值之间的误差$e_t^* = y_t-\hat{y}_t$。
2. 分别令$t=1,\cdots,T$，重复步骤一。
3. 计算$e_1^*,\cdots,e_T^*$的MSE 。我们称之为 **CV**。

赤池信息准则也是一个重要的方法，我们通常称之为 AIC 准则，其定义如下：
$$
AIC = T\times \log(\frac{SSE}{T}) + 2(k+2)
$$
其中，$T$是观测点的个数；$k$是预测变量的个数。

当$T$值较小时，$AIC$准则总是倾向于选择更多的预测变量，因此出现了修正的$AIC$准则，其定义如下：
$$
AIC_c = AIC + \frac{2(k+2)(k+3)}{T-k-3}
$$
施瓦茨的贝叶斯信息准则，通常被称为 BIC 、 SBIC 或 SC ，其定义如下：
$$
BIC = T\times \log(\frac{SSE}{T}) + (k+2)\log(T)
$$
与 AIC 一样，最小化 BIC 可以选择得到最佳模型。BIC 准则选择出的模型比 AIC 准则选择出的模型具有更少的预测变量。这是因为 BIC 准则对参数个数的惩罚力度更强。

被广泛用于模型筛选，但是由于它倾向于选择具有很多预测变量的模型，因此它并不适用于预测。测。在给定足够多数据情况下， BIC 准则能找出真正完美拟合这些数据的模型，因此统计学家更喜欢用 BIC 准则筛选模型。但是，很少有数据存在完美的模型，即使存在，该模型的预测结果也不一定准确。因此，我们建议使用$AIC_c$、 AIC 或 CV 准则的其中一个，因为他们都是以预测数据为目标。当$T$足够大时，它们会选择出相同的模型。

##### 回归预测

##### 矩阵方程

##### 非线性回归

##### 相关关系、因果关系和预测

当不同变量对被预测变量的影响无法分离时会产生混淆。事实上，任何一对相关预测变量都会有一定程度的混淆，但只有当两预测变量之间的相关性较高时，才把它们当作混淆变量处理。

当两个预测变量彼此高度相关时，就会导致模型出现多重共线性。当预测变量的线性组合与预测变量的另一个线性组合高度相关时，也可能导致多重共线性。在这种情况下，由于两组预测变量提供类似的信息，那么当我们知道第一组预测变量值的同时也会得到很多关于第二组预测变量值的信息。当存在多重共线性时，单个预测变量的回归系数的不确定性会很大。因此，回归系数的统计检验是不可靠的。