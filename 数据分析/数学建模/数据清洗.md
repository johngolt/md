#### 数据清洗

##### 缺失值处理

关于缺失值处理的方式， 有几种情况：

- 不处理：针对xgboost等树模型，有些模型有处理缺失的机制，所以可以不处理；
- 如果缺失的太多，可以考虑删除该列；
- 插值补全（均值，中位数，众数，建模预测，多重插补等）；
- 分箱处理，缺失值一个箱。

##### 异常值处理

常用的异常值处理操作包括BOX-COX转换（处理有偏分布），箱线图分析删除异常值， 长尾截断等方式， 当然这些操作一般都是处理数值型的数据。

- BOX-COX转换：用于连续的变量不满足正态的时候，在做线性回归的过程中，一般需要做线性模型假定。
- 箱线图分析：依据实际数据绘制，真实、直观地表现出了数据分布的本来面貌，其判断异常值的标准以四分位数和四分位距为基础。

##### 数据分箱

连续值经常离散化或者分离成“箱子”进行分析, 为什么要做数据分桶呢？

- 离散后稀疏向量内积乘法运算速度更快，计算结果也方便存储，容易扩展；
- 离散后的特征对异常值更具鲁棒性，如 age>30 为 1 否则为 0，对于年龄为 200 的也不会对模型造成很大的干扰；
- LR 属于广义线性模型，表达能力有限，经过离散化后，每个变量有单独的权重，这相当于引入了非线性，能够提升模型的表达能力，加大拟合；
- 离散后特征可以进行特征交叉，提升表达能力，由 M+N 个变量编程 M*N 个变量，进一步引入非线形，提升了表达能力；
- 特征离散后模型更稳定，如用户年龄区间，不会因为用户年龄长了一岁就变化



当然还有很多原因，LightGBM 在改进 XGBoost 时就增加了数据分桶，增强了模型的泛化性。现在介绍数据分桶的方式有：

- 等频分桶：区间的边界值要经过选择,使得每个区间包含大致相等的实例数量。比如说 N=10 ,每个区间应该包含大约10%的实例。
- 等距分桶：从最小值到最大值之间,均分为 N 等份；
- Best-KS分桶：类似利用基尼指数进行二分类；
- 卡方分桶：自底向上的(即基于合并的)数据离散化方法。它依赖于卡方检验：具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。

##### 特征归一化/标准化

数据转换的方式有：

- 数据归一化(MinMaxScaler)；
- 标准化(StandardScaler)；
- 对数变换(log1p)；
- 转换数据类型(astype)；
- 独热编码(OneHotEncoder)；
- 标签编码(LabelEncoder)；
- 修复偏斜特征(boxcox1p)等。