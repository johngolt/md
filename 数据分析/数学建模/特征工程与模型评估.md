#### 数据预处理

##### 缺失值处理

缺失值的处理有三种方法：直接使用含有缺失值的数据、删除含有缺失值的数据、缺失值补全。缺失值补全常见有以下方法：均值插补、同类均值插补、建模预测、高维映射、多重插补、压缩感知及矩阵补全

###### 均值插补&同类均值插补

均值插补：如果样本的属性是连续值，则该属性的缺失值就以该属性有效值的平均值来插补。如果样本的属性是离散值，则该属性的缺失值就以该属性有效值的众数来插补。均值插补在含有缺失值的属性上的所有缺失值都填补为同一个值。

同类均值插补首先将样本进行分类，然后以该类中的样本的均值来插补缺失值。

###### 建模预测

建模预测的思想是：将缺失的属性作为预测目标，通过建立模型来预测。

给定数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}$。假设属性$j$含有缺失值，根据$x_{i,j}$是否缺失，将数据集划分为：$\mathbb{D}_1=\{\vec{\mathbf{x}_i}|x_{i,j}\ne null\}$：属性$j$有效的样本的集合。$\mathbb{D}_2=\{\vec{\mathbf{x}_i}|x_{i,j}= null\}$：属性$j$缺失的样本的集合。将$\mathbb{D}_1$中的样本作为新的训练集，标签值重新定义为属性$j$的值，通过建模来完成属性$j$的学习。将$\mathbb{D}_2$中的样本作为测试集，通过学得的模型来预测其属性$j$的值。

这种方法的效果相对较好，但是该方法有个根本缺陷：

- 如果其他属性和属性$j$无关，则预测的结果无意义。
- 如果预测结果相当准确，则又说明属性  可以由其它属性计算得到， 于是属性$j$信息冗余，没有必要纳入数据集中。

###### 高位映射

高维映射的思想是：将属性映射到高维空间。

![](D:/MarkDown/picture/2/52.png)

对于连续特征，高维映射无法直接处理。可以在连续特征离散化之后，再进行高维映射。

优点：完整保留了原始数据的全部信息。缺点：计算量大大提升。而且只有在样本量非常大的时候效果才好，否则会因为过于稀疏，效果很差。

###### 多重插补

**多重插补**认为待插补的值是随机的，它的值来自于已观测到的值。具体实践上通常是估计出待插补的值，然后再加上不同的噪声，形成多组可选插补值。然后根据某种选择依据，选取最合适的插补值。

多重插补法的步骤：通过变量之间的关系对缺失数据进行预测，利用蒙特卡洛方法生成多个完整的数据集。在每个完整的数据集上进行训练，得到训练后的模型以及评价函数值。对来自各个完整的数据集的结果，根据评价函数值进行选择，选择评价函数值最大的模型，其对应的插值就是最终的插补值。

###### 压缩感知&矩阵补全

压缩感知分为感知测量和重构恢复两个阶段。感知测量：关注如何对原始信号进行处理以获得稀疏样本表示。常用的手段是傅里叶变换、小波变换、字典学习、稀疏编码等。重构恢复：关注的是如何基于稀疏性从少量观测中恢复原信号。

限定等距性：对于大小为$m \times n, m \ll n$的矩阵$\mathbf{A}$，若存在常数$\delta_{k} \in(0,1)$，使得对于任意向量$\vec{\mathbf{s}}$和$\mathbf{A}$的所有子矩阵$\mathbf{A}_{k} \in \mathbb{R}^{m \times k}$，都有：$\left(1-\delta_{k}\right)\|\vec{\mathbf{s}}\|_{2}^{2} \leq\left\|\mathbf{A}_{k} \vec{\mathbf{s}}\right\|_{2}^{2} \leq\left(1+\delta_{k}\right)\|\vec{\mathbf{s}}\|_{2}^{2}$则称$\mathbf{A}$满足$k$限定等距性。此时通过下面的最优化问题可以近乎完美的从$\vec{y}$中恢复出稀疏信号  ，进而恢复出$\overrightarrow{\mathbf{x}}$
$$
\begin{array}{c}{\min _{\overrightarrow{\mathrm{s}}}\|\overrightarrow{\mathbf{s}}\|_{1}} \\ {\text { s.t. } \overrightarrow{\mathbf{y}}=\mathbf{A} \overrightarrow{\mathbf{s}}}\end{array}
$$
矩阵补全`matrix completion`解决的问题是：
$$
\begin{array}{l}{\operatorname{min}_{\mathbf{X}} \operatorname{rank} (\mathbf{X})} \\ {\text {s.t. } \quad x_{i, j}=a_{i, j},(i, j) \in \Omega}\end{array}
$$
$\mathbf{A}$为观测矩阵，其中有很多缺失值。$\Omega$为$\mathbf{A}$中所有的有数值的下标的集合。$\mathbf{X}$为需要恢复的稀疏信号， 为矩阵$rank(\mathbf{X})$的秩。

考虑到$rank(\mathbf{X})$在集合$\left\{\mathbf{X} \in \mathbb{R}^{m \times n} :\|\mathbf{X}\|_{F}^{2} \leq 1\right\}$上的凸包是$\mathbf{X}$的核范数`nuclear norm`：
$$
\|\mathbf{x}\|_{*}=\sum_{j=1}^{\min \{m, n\}} \sigma_{j}(\mathbf{X})
$$
其中$\sigma_{j}(\mathbf{X})$表示$\mathbf{X}$的奇异值。于是可以通过最小化矩阵核范数来近似求解：
$$
\begin{array}{l}{\operatorname{min}_{\mathbf{X}} \|\mathbf{X}\|_*} \\ {\text {s.t. } \quad x_{i, j}=a_{i, j},(i, j) \in \Omega}\end{array}
$$
该最优化问题是一个凸优化问题，可以通过半正定规划求解。

##### 特征编码

###### 特征二元化

特征二元化的算法比较简单。 对属性 指定一个阈值 。

- 如果样本在属性  上的值大于等于 ，则二元化之后为 1 。
- 如果样本在属性  上的值小于 ，则二元化之后为 0 。

###### one-hot

假设属性 的取值为非数值的离散集合 ，独热码将其扩展成 个属性，每个新属性代表属性 的一个状态位：若样本在属性 上的取值为 ，则样本在新的属性 上的取值为 1，在新的属性 上的取值为 0 。

- 这种做法中，如果在 上取值全为 0，则表示发生了缺失。
- 也可以扩展成 个属性， 如果在 上取值全为 0，则表示样本在属性 上的取值为 。

`One-Hot Encoding` 的优点：

- 能够处理非数值属性。
- 在一定程度上也扩充了特征。
- 编码后的属性是稀疏的，存在大量的零元分量。

在决策树模型中，并不推荐对离散特征进行`one-hot`。 主要有两个原因：

- 产生样本切分不平衡的问题，此时且分增益会非常小。这种划分的增益非常小，因为拆分之后：较小的那个拆分样本集，它占总样本的比例太小。无论增益多大，乘以该比例之后几乎可以忽略。较大的那个拆分样本集，它几乎就是原始的样本集，增益几乎为零。
- 影响决策树的学习。决策树依赖的是数据的统计信息。而独热码编码会把数据切分到零散的小空间上。在这些零散的小空间上，统计信息是不准确的，学习效果变差。本质是因为独热码编码之后的特征的表达能力较差的。该特征的预测能力被人为的拆分成多份，每一份与其他特征竞争最优划分点都失败。最终该特征得到的重要性会比实际值低。

###### 离散化

离散化用于将连续的数值属性转化为离散的数值属性。是否使用特征离散化，这背后是：使用“海量离散特征+简单模型”，还是“少量连续特征+复杂模型”。

对于线性模型，通常使用“海量离散特征+简单模型”。优点：模型简单。缺点：特征工程比较困难。但是一旦有成功的经验就可以推广，并且可以很多人并行研究。对于非线性模型，通常使用“少量连续特征+复杂模型”。优点是：不需要进行复杂的特征工程。缺点是：模型复杂。

在工业界很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列 0/1 的离散特征。其优势有：

- 离散化之后得到的稀疏向量，内积乘法运算速度更快，计算结果方便存储。
- 离散化之后的特征对于异常数据具有很强的鲁棒性。
- 逻辑回归属于广义线性模型，表达能力受限，只能描述线性关系。特征离散化之后，相当于引入了非线性，提升模型的表达能力，增强拟合能力。
- 离散化之后可以进行特征交叉。假设有连续特征$j$，离散化为$N$个 0/1 特征；连续特征$k$，离散化为$M$特 0/1 特征，则分别进行离散化之后引入了$M+N$个特征。假设离散化时，并不是独立进行离散化，而是特征$j,k$联合进行离散化，则可以得到$M\times N$个组合特征。这会进一步引入非线性，提高模型表达能力。
- 离散化之后，模型会更稳定。

特征离散化简化了逻辑回归模型，同时降低模型过拟合的风险。能够对抗过拟合的原因：经过特征离散化之后，模型不再拟合特征的具体值，而是拟合特征的某个概念。因此能够对抗数据的扰动，更具有鲁棒性。另外它使得模型要拟合的值大幅度降低，也降低了模型的复杂度。

##### 数据标准化、正则化

###### 标准化

数据标准化是将样本的属性取值缩放到某个指定的范围。

数据标准化的两个原因：

- 某些算法要求样本数据的属性取值具有零均值和单位方差。
- 样本不同属性具有不同量级时，消除数量级的影响。数量级的差异将导致量级较大的属性占据主导地位。数量级的差异将导致迭代收敛速度减慢。标准化后进行梯度下降时，每一步梯度的方向都几乎指向最小值（等高线中心点）的方向，迭代次数较少。所有依赖于样本距离的算法对于数据的数量级都非常敏感。

设数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}, \vec{\mathbf{x}}_{i} =(x_{i,1},\cdots,x_{i,n})^T$。常用的标准化算法有：

- `min-max`标准化：对于属性 ，设所有样本在属性 上的最大值为 ，最小值为 。则标准化后的属性值为：
  $$
  \hat{x}_{x,j} = \frac{x_{i,j}-j_{min}}{j_{max}-j_{min}}
  $$

- `z-score`标准化：对于属性 ，设所有样本在属性 上的均值为 ，方差为 。则标准化后的属性值为：
  $$
  \hat{x}_{x,j} = \frac{x_{i,j}-\mu_j}{\sigma_j}
  $$

###### 正则化

数据正则化是将样本的某个范数缩放到单位1。

设数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}, \vec{\mathbf{x}}_{i} =(x_{i,1},\cdots,x_{i,n})^T$。 则样本$\vec{\mathbf{x}}_{i}$正则化后的结果为：
$$
\hat{\vec{\mathbf{x}}_{i}} = (\frac{x_{i,1}}{L_p(\vec{\mathbf{x}}_{i})},\cdots,\frac{x_{i,n}}{L_p(\vec{\mathbf{x}}_{i})})^T
$$
其中$L_P$为范数：$L_P(\vec{\mathbf{x}}_{i}) = (|x_{i,1}|^p+\cdots+|x_{i,n}|^p)^{\frac{1}{p}}$

正则化的过程是针对单个样本的，对每个样本将它缩放到单位范数。标准化是针对单个属性的，需要用到所有样本在该属性上的值。

##### 特征选择

特征选择可能会降低模型的预测能力。因为被剔除的特征中可能包含了有效的信息，抛弃了这部分信息会一定程度上降低预测准确率。这是计算复杂度和预测能力之间的折衷：

- 如果保留尽可能多的特征，则模型的预测能力会有所提升，但是计算复杂度会上升。
- 如果剔除尽可能多的特征，则模型的预测能力会有所下降，但是计算复杂度会下降。

###### 特征选择原理

要想从初始的特征集合中选取一个包含了所有重要信息的特征子集，如果没有任何领域知识作为先验假设，则只能遍历所有可能的特征组合。一个可选的方案是：

- 产生一个候选子集，评价出它的好坏。
- 基于评价结果产生下一个候选子集，再评价其好坏。
- 这个过程持续进行下去，直至无法找到更好的后续子集为止。

**子集搜索**：解决该问题的算法步骤如下：

- 给定特征集合$\mathbb{A} = \{A_1,\cdots,A_d\}$，首先将每个特征看作一个候选子集，然后对这$d$个候选子集进行评价。假设$A_2$最优，于是将$A_2$作为第一轮的选定子集。
- 然后在上一轮的选定子集中加入一个特征，构成了包含两个特征的候选子集。假定$A_2,A_5$最优，且优于$A_2$，于是将$A_2,A_5$作为第二轮的选定子集。
- 假定在第$k+1$轮时，本轮的最优的特征子集不如上一轮的最优的特征子集，则停止生成候选子集，并将上一轮选定的特征子集作为特征选择的结果。

这种逐渐增加相关特征的策略称作前向`forward`搜索。类似地，如果从完整的特征集合开始，每次尝试去掉一个无关特征，这样逐渐减小特征的策略称作后向`backward`搜索。也可以将前向和后向搜索结合起来，每一轮逐渐增加选定相关特征（这些特征在后续迭代中确定不会被去除）、同时减少无关特征，这样的策略被称作双向`bidirectional`搜索。该策略是贪心的，因为它们仅仅考虑了使本轮选定集最优。但是除非进行穷举搜索，否则这样的问题无法避免。

**子集评价**：特征子集$\mathbb{A}$实际上确定了对数据集$\mathbb{D}$的一个划分规则。

- 每个划分区域对应着$\mathbb{A}$上的一个取值，而样本标记信息$y$则对应着$\mathbb{D}$的真实划分。
- 通过估算这两种划分之间的差异，就能对$\mathbb{A}$进行评价：与$y$对应的划分的差异越小，则说明$\mathbb{A}$越好。
- 信息熵仅仅是判断这个差异的一种方法，其他能判断这两个划分差异的机制都能够用于特征子集的评价。

给定数据集$\mathbb{D}$，假设所有属性均为离散型。对属性子集$\mathbb{A}$， 假定根据其取值将$\mathbb{D}$分成了$V$个子集：$\{\mathbb{D}_1,\cdots,\mathbb{D}_V\}$。于是可以计算属性子集$\mathbb{A}$的信息增益：
$$
g(\mathbb{D},\mathbb{A}) = H(\mathbb{D})-H(\mathbb{D}|\mathbb{A}) = H(\mathbb{D}) = \sum_{v=1}^V\frac{|\mathbb{D}_v|}{|\mathbb{D}|}H(\mathbb{D}_v)
$$
其中$|\cdot|$为集合大小，$H(\cdot)$为熵。信息增益越大，则表明特征子集$\mathbb{A}$包含的有助于分类的信息越多。于是对于每个候选特征子集，可以基于训练数据集$\mathbb{D}$来计算其信息增益作为评价准则。

过滤式方法先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关。这相当于先用特征选择过程对初始特征进行过滤，再用过滤后的特征来训练模型。包裹式特征选择直接把最终将要使用的学习器的性能作为特征子集的评价准则。其目的就是为给定学习器选择最有利于其性能、量身定做的特征子集。嵌入式特征选择是将特征选择与学习器训练过程融为一体，两者在同一个优化过程中完成的。即学习器训练过程中自动进行了特征选择。

##### 稀疏表示和字典学习

数据集具有这样的稀疏表达形式时，对学习任务来讲会有不少好处：

- 如果数据集具有高度的稀疏性，则该问题很可能是线性可分的。对于线性支持向量机，这种情况能取得更佳的性能。
- 稀疏样本并不会造成存储上的巨大负担，因为稀疏矩阵已经有很多很高效的存储方法。

现在问题是：如果给定数据集 是稠密的（即普通的、非稀疏的），则能否将它转化为稀疏的形式？这就是字典学习 `dictionary learning`和稀疏编码`sparse coding`的目标。

字典学习：学习一个字典，通过该字典将样本转化为合适的稀疏表示形式。它侧重于学得字典的过程。稀疏编码：获取样本的稀疏表达，不一定需要通过字典。它侧重于对样本进行稀疏表达的过程。这两者通常是在同一个优化求解过程中完成的，因此这里不做区分，统称为字典学习。

给定数据集$\mathbb{D}=\left\{\left(\vec{\mathbf{x}}_{1}, \tilde{y}_{1}\right),\left(\vec{\mathbf{x}}_{2}, \tilde{y}_{2}\right), \cdots,\left(\vec{\mathbf{x}}_{N}, \tilde{y}_{N}\right)\right\}$，希望对样本$\vec{\mathbf{x}}_{i}$学习到它的一个稀疏表示 。其中$\vec{\alpha}_{i} \in \mathbb{R}^{k}$是一个$k$维列向量，且其中大量元素为 0 。一个自然的想法进行线性变换，即寻找一个矩阵$\mathbf{P} \in \mathbb{R}^{k \times n}$使得 $\mathbf{P} \vec{\mathbf{x}}_{i}=\vec{\alpha}_{i}$。

因此给出字典学习的最优化目标：$\min _{\mathbf{B}, \vec{\alpha}_{i}} \sum_{i=1}^{N}\left\|\vec{\mathbf{x}}_{i}-\mathbf{B} \vec{\alpha}_{i}\right\|_{2}^{2}+\lambda \sum_{i=1}^{N}\left\|\vec{\alpha}_{i}\right\|_{1}$。其中$\mathbf{B} \in \mathbb{R}^{n \times k}$称作字典矩阵。$k$称作字典的词汇量。

第一步：固定字典$\mathbf{B}$， 为每一个样本$\vec{\mathbf{x}_i}$找到相应的$\vec{\alpha_i}$：$\min _{\vec{\alpha}_{i}}\left\|\vec{\mathbf{x}}_{i}-\mathbf{B} \vec{\alpha}_{\dot{z}}\right\|_{2}^{2}+\lambda \sum_{i=1}^{N}\left\|\vec{\alpha}_{i}\right\|_{1}$。第二步：根据$\min _{\mathbf{B}}\|\mathbf{X}-\mathbf{B} \mathbf{A}\|_{F}^{2}$，以$\vec{\alpha_i}$为初值来更新字典$\mathbf{B}$。反复迭代上述两步，最终即可求得字典$\mathbf{B}$和样本$\vec{\mathbf{x}_i}$的稀疏表示$\vec{\alpha_i}$。

这里有个最优化问题：$\min _{\mathbf{B}}\|\mathbf{X}-\mathbf{B} \mathbf{A}\|_{F}^{2}$，该问题有多种求解方法，常用的有基于逐列更新策略的`KSVD`算法。令$\vec{\mathbf{b}}_i$为字典矩阵$\mathbf{B}$的第$i$列，$\vec{\mathbf{a}}^j$表示稀疏矩阵$\mathbf{A}$的第$j$行。 固定$\mathbf{B}$其他列，仅考虑第$i$列，则有：
$$
\min _{\overrightarrow{\mathbf{b}}_{i}}\left\|\mathbf{X}-\sum_{j=1}^{k} \overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{j}\right\|_{F}^{2}=\operatorname{mir}_{\overrightarrow{\mathbf{b}}_{i}}\left\|\left(\mathbf{X}-\sum_{j=1, j \neq i}^{k} \overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{j}\right)-\overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{i}\right\|_{F}^{2}
$$
令$\mathbf{E}_{i}=\mathbf{X}-\sum_{j=1, j \neq i}^{k} \overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{j}$，它表示去掉$\vec{\mathbf{x}}_i$的稀疏表示之后，样本集的稀疏表示与原样本集的误差矩阵。考虑到更新字典的第$i$列$\vec{\mathbf{b}}_i$时，其他各列都是固定的，则$\mathbf{E}_{i}$是固定的。则最优化问题转换为：
$$
\min _{\overrightarrow{\mathrm{b}}_{\mathfrak{i}}}\left\|\mathbf{E}_{i}-\overrightarrow{\mathbf{b}}_{i} \overrightarrow{\mathbf{a}}^{i}\right\|_{F}^{2}
$$
求解该最优化问题只需要对$\mathbf{E}_{i}$进行奇异值分解以取得最大奇异值所对应的正交向量。直接对$\mathbf{E}_{i}$进行奇异值分解会同时修改$\vec{\mathbf{b}}_i$和 $\vec{\mathbf{b}}^i$， 从而可能破坏$\mathbf{A}$的稀疏性。因为第二步 “以$\vec{\alpha}^i$为初值来更新字典$\mathbf{B}$” 中， 在更新$\mathbf{B}$前后$\vec{\alpha}^i$的非零元所处的位置和非零元素的值很可能不一致。为避免发生这样的情况 `KSVD` 对$\mathbf{E}_{i}$和$\overrightarrow{\mathbf{a}}^{i}$进行了专门处理：$\overrightarrow{\mathbf{a}}^{i}$仅保留非零元素。$\mathbf{E}_{i}$仅保留$\overrightarrow{\mathbf{b}}_{i}$和$\overrightarrow{\mathbf{a}}^{i}$的非零元素的乘积项，然后再进行奇异值分解，这样就保持了第一步得到的稀疏性。

##### 参数估计准则

###### 最大似然估计

假设数据集$\mathbf{X}=\left\{\overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right\}$中的样本独立同分布地由$p_{d a t a}(\overrightarrow{\mathbf{x}})$产生，但是该分布是未知的。$p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$是一族由$\theta$参数控制的概率分布函数族，希望通过$p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$来估计真实的概率分布函数$p_{d a t a}(\overrightarrow{\mathbf{x}})$，也就是要估计$\theta$参数。最大似然估计最大化数据集$\mathbf{X}$出现的概率。即：
$$
\theta_{M L}=\arg \max _{\theta} p_{m o d e l}(\mathbf{X} ; \theta)=\arg \max _{\theta} \prod_{i=1}^{m} p_{m o d e l}\left(\overrightarrow{\mathbf{x}}_{i} ; \theta\right)
$$
由于概率的乘积容易出现数值下溢出，因此转换为对数的形式。因为$m$与$\theta$无关，因此它也等价于： $\theta_{M L}=\arg \max _{\theta} \sum_{i=1}^{m} \frac{1}{m} \log p_{m o d e l}\left(\overrightarrow{\mathbf{x}}_{i} ; \theta\right)$。由于数据集的经验分布为：$\hat{p}_{\text {data}}(\overrightarrow{\mathbf{x}})=\frac{1}{m} \sum_{i=1}^{m} \delta\left(\overrightarrow{\mathbf{x}}-\overrightarrow{\mathbf{x}}_{i}\right)$，其中$\delta(\cdot)$狄拉克函数。因此：$\theta_{M L}=\arg \max _{\theta} \mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{\text {data}}} \log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$。考虑数据集的经验分布$\hat{p}_{data}$和真实分布函数的估计量$p_{model}$之间的差异，`KL`散度为：
$$
\left.D\right|_{K L}\left(\hat{p}_{\text {data}} \| p_{\text {model}} ; \theta\right)=\mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{\text {data}}}\left[\log \hat{p}_{\text {data}}(\overrightarrow{\mathbf{x}})-\log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)\right]
$$
由于$\log \hat{p}_{d a t a}(\overrightarrow{\mathbf{x}})$与$\theta$无关，因此要使得$\left.D\right|_{K L}\left(\hat{p}_{\text { data }} \| p_{\text {model}} ; \theta\right)$最小，则只需要最小化$\mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{\text { data }}}\left[-\log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)\right]$。也就是最大化$\mathbb{E}_{\overrightarrow{\mathbf{x}} \sim \hat{p}_{d a z a}} \log p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$。因此：最大似然估计就是最小化数据集的经验分布$\hat{p}_{data}$和真实分布函数的估计量$p_{model}$之间的差异。最大似然估计可以扩展到估计条件概率。假设数据集$\mathbf{X}=\left\{\overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right\}$，对应的观测值为$\mathbf{Y}=\left\{y_{1}, y_{2}, \cdots, y_{m}\right\}$。则条件概率的最大似然估计为：$\theta_{M L}=\arg \max _{\theta} p(\mathbf{Y} | \mathbf{X} ; \theta)$。如果样本是独立同分布的，则可以分解成：$\theta_{M L}=\arg \max _{\theta} \sum_{i=1}^{m} \log p\left(y_{i} | \overrightarrow{\mathbf{x}}_{i} ; \theta\right)$。最大似然估计有两个很好的性质：在某些条件下，最大似然估计具有一致性。这意味着当训练样本数量趋向于无穷时，参数的最大似然估计依概率收敛到参数的真实值。这些条件为：真实分布$p_{data}$必须位于分布函数族$p_{\text {model}}(\cdot ; \theta)$中；否则没有估计量可以表示$p_{data}$。真实分布$p_{data}$必须对应一个$\theta$值；否则从最大似然估计恢复出真实分布$p_{data}$之后，也不能解出参数$\theta$。最大似然估计具有很好的统计效率。即只需要较少的样本就能达到一个良好的泛化误差。最大似然估计通常是机器学习中的首选估计准则。

###### 贝叶斯估计

在最大似然估计中，频率学派的观点是：真实参数$\theta$是未知的固定的值，而点估计$\hat{\theta}$是随机变量。因为数据是随机生成的，所以数据集是随机的。在贝叶斯估计中，贝叶斯学派认为：数据集是能够直接观测到的，因此不是随机的。而真实参数$\theta$是未知的、不确定的，因此$\theta$是随机变量。对$\theta$的已知的知识表示成先验概率分布$p(\theta)$：表示在观测到任何数据之前，对于参数$\theta$的可能取值的一个分布。假设观测到一组数据$\mathbf{X}=\left\{\overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right\}$，根据贝叶斯法则，有：
$$
p(\theta | \mathbf{X})=\frac{p(\mathbf{X} | \theta) p(\theta)}{p(\mathbf{X})}
$$
贝叶斯估计与最大似然估计有两个重要区别：贝叶斯估计预测下，一个样本的分布为：
$$
p\left(\overrightarrow{\mathbf{x}}_{m+1} | \overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right)=\int p\left(\overrightarrow{\mathbf{x}}_{m+1} | \theta\right) p\left(\theta | \overrightarrow{\mathbf{x}}_{1}, \overrightarrow{\mathbf{x}}_{2}, \cdots, \overrightarrow{\mathbf{x}}_{m}\right) d \theta
$$
而最大似然估计预测下，一个样本的分布为：$p_{\text {model}}(\overrightarrow{\mathbf{x}} ; \theta)$ 。贝叶斯估计会使得概率密度函数向着先验概率分布的区域偏移。当训练数据有限时，贝叶斯估计通常比最大似然估计泛化性能更好。当训练样本数量很大时，贝叶斯估计往往比最大似然估计计算代价较高。

有时候希望获取参数$\theta$的一个可能的值，而不仅仅是它的一个分布。此时可以通过最大后验估计`MAP` 选择后验概率最大的点：
$$
\theta_{M A P}=\arg \max _{\theta} p(\theta | \mathbf{X})=\arg \max _{\theta}[\log p(\mathbf{X} | \theta)+\log p(\theta)]
$$
最大后验估计具有最大似然估计没有的优势：拥有先验知识带来的信息。该信息有助于减少估计量的方差，但是增加了偏差。一些正则化方法可以被解释为最大后验估计，正则化项就是对应于$\log p(\theta)$。最大后验估计估计`MAP` 提供了一个直观的方法去设计复杂的、可解释的正则化项。



##### 超参数调节

###### 搜索策略

超参数搜索有三种常见的策略：手动搜索：手动选择超参数；网格搜索：当超参数的数据相对较少时，这个方法很实用；随机搜索：通常推荐这种方式。

网格搜索的做法是：

- 对于每个超参数，选择一个较小的有限值集合去搜索。
- 然后这些超参数笛卡尔乘积得到多组超参数。
- 网格搜索使用每一组超参数训练模型，挑选验证集误差最小的超参数作为最好的超参数。

随机搜索是一种可以替代网格搜索的方法，它编程简单、使用方便、能更快收敛到超参数的良好取值。

- 首先为每个超参数定义一个边缘分布，如伯努利分布（对应着二元超参数）或者对数尺度上的均匀分布（对应着正实值超参数）。
- 然后假设超参数之间相互独立，从各分布中抽样出一组超参数。
- 使用这组超参数训练模型。
- 经过多次抽样 -> 训练过程，挑选验证集误差最小的超参数作为最好的超参数。

随机搜索的优点：

- 不需要离散化超参数的值，也不需要限定超参数的取值范围。这允许我们在一个更大的集合上进行搜索。
- 当某些超参数对于性能没有显著影响时，随机搜索相比于网格搜索指数级地高效，它能更快的减小验证集误差。

###### 调正原则

1. 通常先对超参数进行粗调，然后在粗调中表现良好的超参数区域进行精调。
2. 超参数随机搜索，并不意味着是在有效范围内随机均匀取值。需要选择合适的缩放来进行随机选取。
