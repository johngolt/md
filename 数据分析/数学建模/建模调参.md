##### 模型对比

| 模型       | 优点                                                         | 缺点                                                         |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 决策树     | 易于理解和解释，容易提取出规则；可以同时处理标类别和数值型数据；模型效果好；可以有效处理非线性。 | 对缺失数据处理比较困难；容易出现过拟合问题；忽略数据集中属性的相互关联；不适合处理高维数据 |
| 随机森林   | 可以计算和比较哪些特征比较重要；训练可以并行化，速度快；数据适应能力强，可以处理连续和离散变量；随机性的引入，抗过拟合能力比较强； | 模型的可解释性比较差；对于小数据或者低维数据效果不会太好；在噪声较大的数据集上容易过拟合 |
| `KNN`      | `KNN`是一种在线技术，新数据可以直接加入数据集而不必进行重新训练;`KNN`理论简单，容易实现 | 对于样本容量大的数据集计算量比较大；样本不平衡时，预测偏差比较大；`KNN`每一次分类都会重新进行一次全局运算；k值大小的选择。 |
| `SVM`      | 解决小样本下机器学习问题。解决非线性问题；无局部极小值问题；可以很好的处理高维数据集；泛化能力比较强。 | 对于核函数的高维映射解释力不强，尤其是径向基函数；对缺失数据敏感。 |
| 朴素贝叶斯 | 对大数量训练和查询时具有较高的速度；支持增量式运算，即可以实时的对新增的样本进行训练；朴素贝叶斯对结果解释容易理解。 | 由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。 |
| 逻辑回归   | 实现简单，速度快，模型可解释性好，模型稳定，鲁棒性好，易于部署。 | 容易产生欠拟合，分类精度不高；不能很好地处理大量多类特征或变量；  对数据要求高，缺失值，异常值共线性敏感 |
| `Adaboost` | 分类精度高，构造简单，结果可理解；不容易过拟合；可以使用各种分类模型来构建若学习器，灵活性高。 | 过度偏向分类困难的数据，容易收到噪声数据干扰；依赖于弱学习器，训练时间可能较长 |
| `GBDT`     | 泛化性能比较好；可以灵活处理各种类型数据                     | 对异常值比较敏感；分类器之间存在依赖关系，难以进行并行计算   |
|            |                                                              |                                                              |

#### 模型调参

##### 树模型调参

参数调优的一般步骤：

- 1.确定（较大）学习速率和提升参数调优的初始值
- 2.max_depth 和 min_child_weight 参数调优
- 3.gamma参数调优
- 4.subsample 和 colsample_bytree 参数优
- 5.正则化参数alpha调优
- 6.降低学习速率和使用更多的决策树

###### 树构建参数

| 参数                | 说明                                         | 作用                         |
| ------------------- | -------------------------------------------- | ---------------------------- |
| `min_samples_split` | 如果节点样本数小于最小可分样本数，则停止分裂 | 降低过拟合，如果过大会欠拟合 |
| `min_samples_leaf`  | 最小叶节点样本数                             | 降低过拟合                   |
| `max_depth`         | 树的深度                                     | 防止过拟合                   |
| `max_leaf_nodes`    | 树的叶节点数                                 | 防止过拟合                   |
| `max_features`      | 待分裂的特征数                               | 降低过拟合                   |
| `gamma`             | 分裂收益阈值，比较每次节点分裂增益           | 防止节点的过度分裂           |
| `lambda`            | `L2`范数的惩罚系数                           |                              |
| `alpha`             | `L1`范数的惩罚系数                           |                              |



###### `Boosting`参数

| 参数            | 说明                                   | 作用                                   |
| --------------- | -------------------------------------- | -------------------------------------- |
| `learning_rate` | 学习率控制基模型带来拟合效果的权重     | 低学习率会有较好拟合效果，但学习效率低 |
| `n_estimators`  | 基学习器的个数                         | 学习率不变较多的基学习器容易过拟合     |
| `subsample`     | 子采样数，构建基学习器时使用的样本比率 | 降低过拟合的风险                       |

###### 其他参数

| 参数           | 说明                     | 作用                     |
| -------------- | ------------------------ | ------------------------ |
| `random_state` | 随机状态参数，即随机种子 | 当调参时，该参数需固定   |
| `warm_start`   | 热启动                   | 在训练好的模型上继续训练 |
| `n_jobs`       | 并行训练                 | 模型训练调用机器的核心数 |

| 参数名称               | 作用                                                         |
| ---------------------- | ------------------------------------------------------------ |
| `booster`              | 使用哪个弱学习器训练，默认gbtree，可选gbtree，gblinear 或dart |
| `eta/learning_rate`    | 在更新中使用步长收缩以防止过度拟合，默认= 0.3，范围：[0,1]；典型值一般设置为：0.01-0.2 |
| `max_depth`            | 默认6，一棵树的最大深度。增加此值将使模型更复杂，并且更可能过度拟合。 |
| `min_child_weight`     | 默认值1，如果新分裂的节点的样本权重和小于`min_child_weight`则停止分裂 。用来防止过拟合，如果过大，会造成欠拟合。 |
| `gamma/min_split_loss` | 默认0，分裂节点时，损失函数减小值只有大于等于$\gamma$节点才分裂，$\gamma$值越大，越不容易过拟合，但是容易欠拟合。 |
| `subsample`            | 默认值1，构建每棵树对样本的采样率，如果设置成0.5，随机选择一半的样本作为训练集。 |
| `colsample_bytree`     | 默认1，列采样率，也就是特征采样率                            |
| `alpha/reg_alpha`      | 默认0，权重的$L_1$正则化项。                                 |
| `lambda/reg_lambda`    | 默认1，$L_2$正则化权重项。                                   |
| `eval_metric`          | 验证数据的评估指标，根据目标分配默认指标，用户可以添加多个评估指标 |










但如果找不到产生异常点的原因，它可能就是一个正常数据，此时可以考虑补充抽样，看看能不能把异常点与大多数数据中的空间填补上。

双峰（多峰）数据：把两组(或多组)数据混到一起了，可能每组数据都服从正态分布，做数据分析时尽可能把数据按不同属性分开分析。

平顶数据：平顶的数据是指在直方图上看到的图形是相对比较平坦的。原因：不同均值的数据混在一起（按其属性分开），或者是数据收集的周期过长，过程发生了缓慢的移动（只取近期的数据进行分析）。

##### 特征归一化/标准化

如果你的数据包含许多异常值，使用均值和方差缩放可能并不是一个很好的选择。这种情况下，你可以使用`robust_scale`以及`RobustScaler`作为替代品。它们对你的数据的中心和范围使用更有鲁棒性的估计。中心化稀疏数据会破坏数据的稀疏结构，因此很少有一个比较明智的实现方式。但是缩放稀疏输入是有意义的，尤其是当几个特征在不同的量级范围时，最推荐的缩放方式是采用最大绝对值缩放。

样本分布非正态的原因：数据分布本身就不是正态的；存在异常点；双峰（多峰）数据：可能是把两组(或多组)数据混到一起了，可能每组数据都服从正态分布；平顶的数据





#### Boosting/Bagging

当有多个混淆矩阵（多次训练、多个数据集、多分类任务）时，有两种方式估算 “全局” 性能：

- macro 方法：先计算每个 PR，取平均后，再计算 F1
- micro 方法：先计算混淆矩阵元素的平均，再计算 PR 和 F1

与 P-R 曲线相比，ROC 曲线有一个特点：当正负样本的分布发生变化时，ROC 曲线形状能基本保持不变，而 P-R 曲线的形状一般会发生比较剧烈的变化。因此，当数据不均匀时，ROC 曲线更能够反映模型好坏。

| 名称         | 定义                                                         |
| ------------ | ------------------------------------------------------------ |
| 平均精度`AP` | P-R曲线围起来的面积，通常来说一个越好的分类器，AP值越高。    |
| `mAP`        | 即是把每个类别的AP都单独拿出来，然后计算所有类别AP的平均值，代表着对检测到的目标平均精度的一个综合度量。 |
|              |                                                              |

秩相关系数，秩是指样本值的大小在全体样本从小到大排序后所占的次序。对于一对数$(X_1, Y_1)$和$(X_2, Y_2)$，如果$X_1>X_2$且$Y_1> Y_2$或者$X_1<X_2$且$Y_1<Y_2$，则称$(X_1,Y_1)$和$(X_2, Y_2)$是一致的；如果$X_1>X_2$且$Y_1<Y_2$或者$X_1<X_2$且$Y_1>Y_2$，则称$(X_1,Y_1)$和$(X_2, Y_2)$是不一致的；如果$X_1=X_2$或$Y_1=Y_2$，则称$(X_1, Y_1)$和$(X_2,Y_2)$是一个`tie`。记$n_c$为一致对的个数，$n_d$为不一致对的个数，$n_t$为$X$值不等而$Y$值相等的tie的个数，$N$为观测值的个数，可以有以下几个秩相关系数： 

一致性指标：$c=\frac{n_{c}+0.5 n_{t}}{n_{c}+n_{d}+n_{t}}$

`Gini coefficient`：$D_{Y X}=\frac{n_{c}-n_{d}}{n_{c}+n_{d}+n_{t}}$

`Goodman-Krustal Gamma`：$\Gamma=\frac{n_{c}-n_{d}}{n_{c}+n_{d}}$

`Kendall`：$\tau=\frac{n_{c}-n_{d}}{N(N-1) / 2}$

`ROC`：那么一个模型的特异度可以定义为`TNR=TN/(FP+TN)`，灵敏度可以定义为`TPR=TP/(TP+FN)`。而`ROC`曲线的横坐标是1-特异度=`1-TNR=FP/(FP+TN)=FPR`，纵坐标是灵敏度即`TPR`。`ROC`曲线以`FPR`为横轴，`TPR`为纵轴，而`KS`曲线以阈值为横轴，`TPR`、`FPR`为纵轴。 



提升度曲线：可以衡量使用这个模型比随机选择对坏样本的预测能力提升了多少倍。通常计算`LIFT`的时候会把模型的最终得分按照从低到高，排序并等频分为10组，计算分数最低的一组对应的`累计坏样本占比/累计总样本占比`就等于`LIFT`值了。从直观上理解，累计坏样本占比相当于是使用模型的情况下最差的这一组能够从所有的坏样本中挑出多少比例的坏样本，而累计总样本占比等于随机抽样的情况下从所有坏样本抽取了多少比例的坏样本。



模型特征重要性分析：`LGB/XGB`等的`importance`、`LR、SVM`的`coeff`等；特征重要性可以结合业务理解，有些奇怪的特征在模型中起着关键的作用，这些可以帮助我们更好地理解我们的业务，同时如果有些特征反常规，我们也可以看出来；可能这些就是过拟合的特征等等；     

模型分割方式分析：可视化模型的预测，包括`LGB`的每一颗数等；这些可以帮助我们很好的理解我们的模型，模型的分割方式是否符合常理也可以结合业务知识一起分析，帮助我们更好的设计模型；       

模型结果分析：这个在回归问题就是看预测的结果的分布；分类一般看混淆矩阵等。这么做可以帮助我们找到模型做的不好的地方，从而更好的修正我们的模型。

###### K-S检验

$\text{KS}$：KS用于模型风险区分能力进行评估， 指标衡量的是好坏样本累计分部之间的差值。 好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强。KS的计算步骤如下： 计算每个评分区间的好坏账户数。 计算每个评分区间的累计好账户数占总好账户数比率和累计坏账户数占总坏账户数比率。 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值，然后对这些绝对值取最大值即得此评分卡的K-S值。

KS检验，是统计学中的一种非参数假设检验，用来检测单样本是否服从某一分布，或者两样本是否服从相同分布。在单样本的情况下，我们想检验这个样本是否服从某一分布函数$F_0(x)$，记$F_1(x)$是该样本的经验分布函数。我们构造KS统计量：$D_n=\max_x|F_1(x)-F_0(x)|$

经验分布函数与目标分布的累积分布函数的最大差值就是我们要求的KS统计量：95%置信度的KS统计量的临界值由$D_n=\frac{1.36}{\sqrt{n}}$。两样本的KS检验，95%置信度的临界值为$D_n=1.36\sqrt{\frac{1}{n_x}+\frac{1}{n_y}}$，如果我们根据样本得到的KS统计量的值小于$D_n$，那么我们就接收原假设。否则，拒绝原假设。

#### 类别不平衡学习

不平衡数据集上分类困难的原因：①过多的少数类样本出现在多数类样本密集的区域；②类别之间的分布严重重叠；③数据中本身存在的噪声，尤其是少数类的噪声；④少数类分布的稀疏性以及稀疏性导致的拆分多个子概念并且每个子概念仅含有较少的样本数量。①②③都归因为一个因素：噪声，④又被称为small disjuncts问题，在同样的特征空间中，相比于只有一个cluster的简单少数类分布，具有多个子概念的少数类分布需要模型给出更复杂的决策边界来获得良好的预测。在模型复杂度不变的情况下，分类性能会因子概念个数的增多而变差。因此该问题的解决办法也较为简单：上更大容量的模型

#####  处理方法

###### 异常检测

分类问题的一个隐含假设是各个类别的数据都有自己的分布，当某类数据少到难以观察结构的时候，我们可以考虑抛弃该类数据，转而学习更为明显的多数类模式，而后将不符合多数类模式的样本判断为少数类，某些时候会有更好的效果。此时该问题退化为异常检测问题。

| 方法     | 说明                                                         | 优点                                                         | 缺点                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据级   | 该类方法关注于通过修改训练数据集以使得标准学习算法也能在其上有效训练。 | 该类方法能够去除噪声/平衡类别分布；欠采样方法减小数据集规模，降低计算量 | 采样过程计算效率低下；易被噪声影响；过采样方法生成过多数据；不适用于无法计算距离的复杂数据集： |
| 算法级   | 代价敏感学习给少数类样本分配较高的误分类代价，而给多数类样本分配较小的误分类代价。代价敏感学习在学习器的训练过程中人为提高了少数类别样本的重要性，以此减轻分类器对多数类的偏好。 | 不增加训练复杂度；可直接用于多分类问题                       | 需要领域先验知识，代价敏感学习中的代价矩阵需要由领域专家根据任务的先验知识提供；不能泛化到不同任务：对于特定问题设计的代价矩阵只能用于该特定任务；依赖于特定分类器 |
| 集成学习 | 专注于将一种数据级或算法级方法与集成学习相结合，一种是基于某种特定的集成学习算法并在集成的过程中嵌入一种其他的不平衡学习方法。另一种是集成学习的基学习器也是集成学习器。 | 效果通常较好；可使用迭代过程中的反馈进行动态调整             | 包含所使用的不平衡学习方法的缺点；过采样+集成进一步增大计算开销；对噪声不鲁棒 |

数据级方法可被进一步分类为：从多数类别中删除样本的方法（欠采样）；为少数类别生成新样本的方法（过采样）；结合上述两种方案的混合类方法（过采样+欠采样去噪，如SMOTE+ENN等）

标准的随机重采样方法使用随机方法来选择用于预处理的目标样本。然而随机方法可能会导致丢弃含有重要信息的样本（随机欠采样）或者引入无意义的甚至有害的新样本（随机过采样），因此有的方法试图根据根据数据的分布信息来在进行重采样的同时保持原有的数据结构。

` Edited Nearest Neighbours`：对于属于多数类的一个样本，如果其K个近邻点有超过一半都不属于多数类，则这个样本会被剔除。这个方法的另一个变种是所有的K个近邻点都不属于多数类，则这个样本会被剔除。

`Near Miss`有三种变种：选择到最近的K个少数类样本平均距离最近的多数类样本；选择到最远的K个少数类样本平均距离最近的多数类样本；对于每个少数类样本选择K个最近的多数类样本，目的是保证每个少数类样本都被多数类样本包围



对样本进行过采样或者降采样时需要在`cross-validation`之后，避免数据泄露问题





###### 相关分析

复相关

偏相关

###### 方差分析

协方差分析

> **横型诊断方法**
>
> 残差检验：观测值与估计值的差值要跟从正态分布
>
> 强影响点判断：寻找方式一般分为标准误差法、Mahalanobis距离法
>
> 共线性诊断：诊断方式：容忍度、方差扩大因子法(又称膨胀系数VIF)、特征根判定法、条件指针CI、方差比例，处理方法：增加样本容量或选取另外的回归如主成分回归等



 

惯例： `scikit-learn estimator`遵守以下惯例：

 

\- 除非显式指定数据类型，否则所有的输入数据都被转换成 `float64`

\- 回归问题的输出被转换成 `float64`；分类问题的输出不被转换

\- `estimator`的参数可以更新：

 \- `estimator.set_params(...)`方法可以显式更新一个`estimator`的参数值

 \- 多次调用`estimator.fit(...)`方法可以隐式更新一个`estimator`的参数值。最近的一次训练学到的参数会覆盖之前那次训练学到的参数值。





### 3.3 数据探索

主要包括四个方面：数据整体认知、数据质量分析、数据统计量分析、数据分布分析

3.3.1 数据整体认知

所谓的整体认知就是，研究训练集、测试集、表数、记录数、用户数、变量数、变量类型、变量属性值、标签等内容，然后绘制实体-关系图。实体-关系图（E-R图）包括三个组成部分：实体、属性、关系。学过数据库的同学应该熟悉E-R图这个概念。

3.3.2 数据质量分析

所谓数据质量分析，就是分析数据的缺失值、重复值、异常值、歧义值、正负样本比例（样本不平衡）等特性。

3.3.3 数据统计量分析

数据统计量分析主要分为三块：

第一，对单个变量的统计分析。比如考察单个变量的均值、中位数、众数、分位数、方差、变异系数等。常用的工具有：直方图、箱线图、小提琴图等。

第二，对两个变量的统计分析。这里主要考察的是两个变量统计分布之间的关系。常用的工具包括散点图、相关性分析图、热力图等。

第三，对多个变量的统计分析。

3.3.4 数据分布分析

数据分布分析指的是考察某个字段或某些字段的统计分布。包括频数、时间、空间三个方面。

频数统计。用概率论的语言讲叫累积分布函数CDF。比如在IJCAI2018阿里妈妈国际广告算法大赛中，我们就统计了不同点击次数下各有多少用户。基于类似的累积分布函数图我们就可以知道用户行为的分布情况，进而可以帮助我们充分理解数据。

时间维度上的统计分布。我们可以观察事件发生的趋势和周期性，这里会涉及不少时间序列的知识。比如下图所示的“每天的点击数趋势”，就是在时间维度上考察点击数的变化情况。

空间维度上的统计分布，我们可以寻找某个变量在地理位置上的相关关系。比如2020年以来我们十分熟悉的疫情地图，就是一种空间上的分布分析。

另外，以上三种分析常常结合分组or聚类方法，对细分的业务场景进行考察，为后面的数据建模做铺垫。

3.3.5 数据探索小结

对于数据探索，我总结了几个需要牢记在心的关键点，分别是：对比，分组，频数，抓大放小和可视化。

所谓对比，指的是在做数据探索时，考虑对比训练集不同样本之间的特征分布，还要考虑对比训练集和测试集中每一个特征的分布。

所谓分组，就是在做数据探索时，常常用到按类别标签、某个离散变量的不同取值groupby后的sum、unique。

所谓频数，就是要注意考察并自行计算某些变量的概率累积分布。诸如“事件发生次数”这样的的统计量需要自己计算；有时还要关注“同id下某个事件多次发生”的统计。

所谓抓大放小，就是对于那些特征重要性较高的变量，要做重点分析。因为这些变量对你模型预测能力的影响是较大的。

所谓可视化，就是建议大家在做数据探索的时候多画图（尤其是各种趋势图、分布图），图形给人的冲击力往往是要大于数字本身的。

3.4.1 数据预处理

首先来说一下为什么要做数据预处理。首先，考虑到海量原始数据中存在大量信息缺失、不一致、冗余值、异常值等，会影响我们模型的学习效果。另外，在用各种模型算法时也要牢记监督学习的假设，即正负样本要平衡且训练集和测试集样本是独立同分布的。第三，在模型训练时，数据规范化的操作可以让梯度下降算法收敛得更快，也就是更快地找到最优超参数。

传统意义上的数据预处理一般包括数据清洗、数据集成、数据重采样、数据变换（特征编码）和数据规范化（特征缩放），这一块的内容也是网络上流传最广、介绍最多的数据分析技巧，因此我不做具体的解释，仅仅把各自常用的处理技巧罗列一下。

数据清洗

- 缺失值插补

- - 均值、中位数、众数插补
  - 固定值插补
  - 最近邻插补

- 离群值

- - 直接删除
  - 替换法

- 异常、冗余值

- - 直接删除

- 小技巧：用训练集数据学习一个模型，然后用它预测训练集的标签，删除预测结果偏差较大的样本

数据集成

- 多表数据整合

- - 一对一
  - 一对多
  - 多对一
  - 多对多

数据重采样

- 滑窗法：

- - 对于时间序列数据，选取不同的时间窗间隔，可以得到多份训练数据集
  - 该方法可以增加训练样本，也方便做交叉验证实验

- 非平衡重采样：调整正负样本量

- - 欠采样
  - 过采样
  - 组合采样

数据变换

- 连续变量离散化（分箱）

- - 等频
  - 等宽
  - 聚类

- 离散变量编码

- - One-hot Encoding
  - Label Encoding

- 长尾分布

- - Ln、Log

数据规范化

- Min-Max
- Z-score
- MaxAbs

