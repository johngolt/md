##### 模型对比

| 模型       | 优点                                                         | 缺点                                                         |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 决策树     | 易于理解和解释，容易提取出规则；可以同时处理标类别和数值型数据；模型效果好；可以有效处理非线性。 | 对缺失数据处理比较困难；容易出现过拟合问题；忽略数据集中属性的相互关联；不适合处理高维数据 |
| 随机森林   | 可以计算和比较哪些特征比较重要；训练可以并行化，速度快；数据适应能力强，可以处理连续和离散变量；随机性的引入，抗过拟合能力比较强； | 模型的可解释性比较差；对于小数据或者低维数据效果不会太好；在噪声较大的数据集上容易过拟合 |
| `KNN`      | `KNN`是一种在线技术，新数据可以直接加入数据集而不必进行重新训练;`KNN`理论简单，容易实现 | 对于样本容量大的数据集计算量比较大；样本不平衡时，预测偏差比较大；`KNN`每一次分类都会重新进行一次全局运算；k值大小的选择。 |
| `SVM`      | 解决小样本下机器学习问题。解决非线性问题；无局部极小值问题；可以很好的处理高维数据集；泛化能力比较强。 | 对于核函数的高维映射解释力不强，尤其是径向基函数；对缺失数据敏感。 |
| 朴素贝叶斯 | 对大数量训练和查询时具有较高的速度；支持增量式运算，即可以实时的对新增的样本进行训练；朴素贝叶斯对结果解释容易理解。 | 由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。 |
| 逻辑回归   | 实现简单，速度快，模型可解释性好，模型稳定，鲁棒性好，易于部署。 | 容易产生欠拟合，分类精度不高；不能很好地处理大量多类特征或变量；  对数据要求高，缺失值，异常值共线性敏感 |
| `Adaboost` | 分类精度高，构造简单，结果可理解；不容易过拟合；可以使用各种分类模型来构建若学习器，灵活性高。 | 过度偏向分类困难的数据，容易收到噪声数据干扰；依赖于弱学习器，训练时间可能较长 |
| `GBDT`     | 泛化性能比较好；可以灵活处理各种类型数据                     | 对异常值比较敏感；分类器之间存在依赖关系，难以进行并行计算   |
|            |                                                              |                                                              |

#### 模型调参

##### 树模型调参

参数调优的一般步骤：

- 1.确定（较大）学习速率和提升参数调优的初始值
- 2.max_depth 和 min_child_weight 参数调优
- 3.gamma参数调优
- 4.subsample 和 colsample_bytree 参数优
- 5.正则化参数alpha调优
- 6.降低学习速率和使用更多的决策树

###### 树构建参数

| 参数                | 说明                                         | 作用                         |
| ------------------- | -------------------------------------------- | ---------------------------- |
| `min_samples_split` | 如果节点样本数小于最小可分样本数，则停止分裂 | 降低过拟合，如果过大会欠拟合 |
| `min_samples_leaf`  | 最小叶节点样本数                             | 降低过拟合                   |
| `max_depth`         | 树的深度                                     | 防止过拟合                   |
| `max_leaf_nodes`    | 树的叶节点数                                 | 防止过拟合                   |
| `max_features`      | 待分裂的特征数                               | 降低过拟合                   |
| `gamma`             | 分裂收益阈值，比较每次节点分裂增益           | 防止节点的过度分裂           |
| `lambda`            | `L2`范数的惩罚系数                           |                              |
| `alpha`             | `L1`范数的惩罚系数                           |                              |



###### `Boosting`参数

| 参数            | 说明                                   | 作用                                   |
| --------------- | -------------------------------------- | -------------------------------------- |
| `learning_rate` | 学习率控制基模型带来拟合效果的权重     | 低学习率会有较好拟合效果，但学习效率低 |
| `n_estimators`  | 基学习器的个数                         | 学习率不变较多的基学习器容易过拟合     |
| `subsample`     | 子采样数，构建基学习器时使用的样本比率 | 降低过拟合的风险                       |

###### 其他参数

| 参数           | 说明                     | 作用                     |
| -------------- | ------------------------ | ------------------------ |
| `random_state` | 随机状态参数，即随机种子 | 当调参时，该参数需固定   |
| `warm_start`   | 热启动                   | 在训练好的模型上继续训练 |
| `n_jobs`       | 并行训练                 | 模型训练调用机器的核心数 |

| 参数名称               | 作用                                                         |
| ---------------------- | ------------------------------------------------------------ |
| `booster`              | 使用哪个弱学习器训练，默认gbtree，可选gbtree，gblinear 或dart |
| `eta/learning_rate`    | 在更新中使用步长收缩以防止过度拟合，默认= 0.3，范围：[0,1]；典型值一般设置为：0.01-0.2 |
| `max_depth`            | 默认6，一棵树的最大深度。增加此值将使模型更复杂，并且更可能过度拟合。 |
| `min_child_weight`     | 默认值1，如果新分裂的节点的样本权重和小于`min_child_weight`则停止分裂 。用来防止过拟合，如果过大，会造成欠拟合。 |
| `gamma/min_split_loss` | 默认0，分裂节点时，损失函数减小值只有大于等于$\gamma$节点才分裂，$\gamma$值越大，越不容易过拟合，但是容易欠拟合。 |
| `subsample`            | 默认值1，构建每棵树对样本的采样率，如果设置成0.5，随机选择一半的样本作为训练集。 |
| `colsample_bytree`     | 默认1，列采样率，也就是特征采样率                            |
| `alpha/reg_alpha`      | 默认0，权重的$L_1$正则化项。                                 |
| `lambda/reg_lambda`    | 默认1，$L_2$正则化权重项。                                   |
| `eval_metric`          | 验证数据的评估指标，根据目标分配默认指标，用户可以添加多个评估指标 |










但如果找不到产生异常点的原因，它可能就是一个正常数据，此时可以考虑补充抽样，看看能不能把异常点与大多数数据中的空间填补上。

双峰（多峰）数据：把两组(或多组)数据混到一起了，可能每组数据都服从正态分布，做数据分析时尽可能把数据按不同属性分开分析。

平顶数据：平顶的数据是指在直方图上看到的图形是相对比较平坦的。原因：不同均值的数据混在一起（按其属性分开），或者是数据收集的周期过长，过程发生了缓慢的移动（只取近期的数据进行分析）。

##### 特征归一化/标准化

如果你的数据包含许多异常值，使用均值和方差缩放可能并不是一个很好的选择。这种情况下，你可以使用`robust_scale`以及`RobustScaler`作为替代品。它们对你的数据的中心和范围使用更有鲁棒性的估计。中心化稀疏数据会破坏数据的稀疏结构，因此很少有一个比较明智的实现方式。但是缩放稀疏输入是有意义的，尤其是当几个特征在不同的量级范围时，最推荐的缩放方式是采用最大绝对值缩放。

样本分布非正态的原因：数据分布本身就不是正态的；存在异常点；双峰（多峰）数据：可能是把两组(或多组)数据混到一起了，可能每组数据都服从正态分布；平顶的数据





#### Boosting/Bagging

当有多个混淆矩阵（多次训练、多个数据集、多分类任务）时，有两种方式估算 “全局” 性能：

- macro 方法：先计算每个 PR，取平均后，再计算 F1
- micro 方法：先计算混淆矩阵元素的平均，再计算 PR 和 F1

与 P-R 曲线相比，ROC 曲线有一个特点：当正负样本的分布发生变化时，ROC 曲线形状能基本保持不变，而 P-R 曲线的形状一般会发生比较剧烈的变化。因此，当数据不均匀时，ROC 曲线更能够反映模型好坏。

| 名称         | 定义                                                         |
| ------------ | ------------------------------------------------------------ |
| 平均精度`AP` | P-R曲线围起来的面积，通常来说一个越好的分类器，AP值越高。    |
| `mAP`        | 即是把每个类别的AP都单独拿出来，然后计算所有类别AP的平均值，代表着对检测到的目标平均精度的一个综合度量。 |
|              |                                                              |

秩相关系数，秩是指样本值的大小在全体样本从小到大排序后所占的次序。对于一对数$(X_1, Y_1)$和$(X_2, Y_2)$，如果$X_1>X_2$且$Y_1> Y_2$或者$X_1<X_2$且$Y_1<Y_2$，则称$(X_1,Y_1)$和$(X_2, Y_2)$是一致的；如果$X_1>X_2$且$Y_1<Y_2$或者$X_1<X_2$且$Y_1>Y_2$，则称$(X_1,Y_1)$和$(X_2, Y_2)$是不一致的；如果$X_1=X_2$或$Y_1=Y_2$，则称$(X_1, Y_1)$和$(X_2,Y_2)$是一个`tie`。记$n_c$为一致对的个数，$n_d$为不一致对的个数，$n_t$为$X$值不等而$Y$值相等的tie的个数，$N$为观测值的个数，可以有以下几个秩相关系数： 

一致性指标：$c=\frac{n_{c}+0.5 n_{t}}{n_{c}+n_{d}+n_{t}}$

`Gini coefficient`：$D_{Y X}=\frac{n_{c}-n_{d}}{n_{c}+n_{d}+n_{t}}$

`Goodman-Krustal Gamma`：$\Gamma=\frac{n_{c}-n_{d}}{n_{c}+n_{d}}$

`Kendall`：$\tau=\frac{n_{c}-n_{d}}{N(N-1) / 2}$

`ROC`：那么一个模型的特异度可以定义为`TNR=TN/(FP+TN)`，灵敏度可以定义为`TPR=TP/(TP+FN)`。而`ROC`曲线的横坐标是1-特异度=`1-TNR=FP/(FP+TN)=FPR`，纵坐标是灵敏度即`TPR`。`ROC`曲线以`FPR`为横轴，`TPR`为纵轴，而`KS`曲线以阈值为横轴，`TPR`、`FPR`为纵轴。 



提升度曲线：可以衡量使用这个模型比随机选择对坏样本的预测能力提升了多少倍。通常计算`LIFT`的时候会把模型的最终得分按照从低到高，排序并等频分为10组，计算分数最低的一组对应的`累计坏样本占比/累计总样本占比`就等于`LIFT`值了。从直观上理解，累计坏样本占比相当于是使用模型的情况下最差的这一组能够从所有的坏样本中挑出多少比例的坏样本，而累计总样本占比等于随机抽样的情况下从所有坏样本抽取了多少比例的坏样本。



模型特征重要性分析：`LGB/XGB`等的`importance`、`LR、SVM`的`coeff`等；特征重要性可以结合业务理解，有些奇怪的特征在模型中起着关键的作用，这些可以帮助我们更好地理解我们的业务，同时如果有些特征反常规，我们也可以看出来；可能这些就是过拟合的特征等等；     

模型分割方式分析：可视化模型的预测，包括`LGB`的每一颗数等；这些可以帮助我们很好的理解我们的模型，模型的分割方式是否符合常理也可以结合业务知识一起分析，帮助我们更好的设计模型；       

模型结果分析：这个在回归问题就是看预测的结果的分布；分类一般看混淆矩阵等。这么做可以帮助我们找到模型做的不好的地方，从而更好的修正我们的模型。

###### K-S检验

$\text{KS}$：KS用于模型风险区分能力进行评估， 指标衡量的是好坏样本累计分部之间的差值。 好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强。KS的计算步骤如下： 计算每个评分区间的好坏账户数。 计算每个评分区间的累计好账户数占总好账户数比率和累计坏账户数占总坏账户数比率。 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值，然后对这些绝对值取最大值即得此评分卡的K-S值。

KS检验，是统计学中的一种非参数假设检验，用来检测单样本是否服从某一分布，或者两样本是否服从相同分布。在单样本的情况下，我们想检验这个样本是否服从某一分布函数$F_0(x)$，记$F_1(x)$是该样本的经验分布函数。我们构造KS统计量：$D_n=\max_x|F_1(x)-F_0(x)|$

经验分布函数与目标分布的累积分布函数的最大差值就是我们要求的KS统计量：95%置信度的KS统计量的临界值由$D_n=\frac{1.36}{\sqrt{n}}$。两样本的KS检验，95%置信度的临界值为$D_n=1.36\sqrt{\frac{1}{n_x}+\frac{1}{n_y}}$，如果我们根据样本得到的KS统计量的值小于$D_n$，那么我们就接收原假设。否则，拒绝原假设。

#### 类别不平衡学习

不平衡数据集上分类困难的原因：①过多的少数类样本出现在多数类样本密集的区域；②类别之间的分布严重重叠；③数据中本身存在的噪声，尤其是少数类的噪声；④少数类分布的稀疏性以及稀疏性导致的拆分多个子概念并且每个子概念仅含有较少的样本数量。①②③都归因为一个因素：噪声，④又被称为small disjuncts问题，在同样的特征空间中，相比于只有一个cluster的简单少数类分布，具有多个子概念的少数类分布需要模型给出更复杂的决策边界来获得良好的预测。在模型复杂度不变的情况下，分类性能会因子概念个数的增多而变差。因此该问题的解决办法也较为简单：上更大容量的模型

#####  处理方法

###### 异常检测

分类问题的一个隐含假设是各个类别的数据都有自己的分布，当某类数据少到难以观察结构的时候，我们可以考虑抛弃该类数据，转而学习更为明显的多数类模式，而后将不符合多数类模式的样本判断为少数类，某些时候会有更好的效果。此时该问题退化为异常检测问题。

| 方法     | 说明                                                         | 优点                                                         | 缺点                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据级   | 该类方法关注于通过修改训练数据集以使得标准学习算法也能在其上有效训练。 | 该类方法能够去除噪声/平衡类别分布；欠采样方法减小数据集规模，降低计算量 | 采样过程计算效率低下；易被噪声影响；过采样方法生成过多数据；不适用于无法计算距离的复杂数据集： |
| 算法级   | 代价敏感学习给少数类样本分配较高的误分类代价，而给多数类样本分配较小的误分类代价。代价敏感学习在学习器的训练过程中人为提高了少数类别样本的重要性，以此减轻分类器对多数类的偏好。 | 不增加训练复杂度；可直接用于多分类问题                       | 需要领域先验知识，代价敏感学习中的代价矩阵需要由领域专家根据任务的先验知识提供；不能泛化到不同任务：对于特定问题设计的代价矩阵只能用于该特定任务；依赖于特定分类器 |
| 集成学习 | 专注于将一种数据级或算法级方法与集成学习相结合，一种是基于某种特定的集成学习算法并在集成的过程中嵌入一种其他的不平衡学习方法。另一种是集成学习的基学习器也是集成学习器。 | 效果通常较好；可使用迭代过程中的反馈进行动态调整             | 包含所使用的不平衡学习方法的缺点；过采样+集成进一步增大计算开销；对噪声不鲁棒 |

数据级方法可被进一步分类为：从多数类别中删除样本的方法（欠采样）；为少数类别生成新样本的方法（过采样）；结合上述两种方案的混合类方法（过采样+欠采样去噪，如SMOTE+ENN等）

标准的随机重采样方法使用随机方法来选择用于预处理的目标样本。然而随机方法可能会导致丢弃含有重要信息的样本（随机欠采样）或者引入无意义的甚至有害的新样本（随机过采样），因此有的方法试图根据根据数据的分布信息来在进行重采样的同时保持原有的数据结构。

` Edited Nearest Neighbours`：对于属于多数类的一个样本，如果其K个近邻点有超过一半都不属于多数类，则这个样本会被剔除。这个方法的另一个变种是所有的K个近邻点都不属于多数类，则这个样本会被剔除。

`Near Miss`有三种变种：选择到最近的K个少数类样本平均距离最近的多数类样本；选择到最远的K个少数类样本平均距离最近的多数类样本；对于每个少数类样本选择K个最近的多数类样本，目的是保证每个少数类样本都被多数类样本包围



对样本进行过采样或者降采样时需要在`cross-validation`之后，避免数据泄露问题





###### 相关分析

复相关

偏相关

###### 方差分析

协方差分析

> **横型诊断方法**
>
> 残差检验：观测值与估计值的差值要跟从正态分布
>
> 强影响点判断：寻找方式一般分为标准误差法、Mahalanobis距离法
>
> 共线性诊断：诊断方式：容忍度、方差扩大因子法(又称膨胀系数VIF)、特征根判定法、条件指针CI、方差比例，处理方法：增加样本容量或选取另外的回归如主成分回归等



 



###### WOE编码

WOE编码的好处：可提升模型的预测效果；将自变量规范到同一尺度上；WOE能反映自变量取值的贡献情况；有利于对变量的每个分箱进行评分；转化为连续变量之后，便于分析变量与变量之间的相关性；与独热向量编码相比，可以保证变量的完整性，同时避免稀疏矩阵和维度灾难

| 名称  | 定义              |
| ----- | ----------------- |
| $B_i$ | 第$i$分箱坏样本数 |
| $G_i$ | 第$i$分箱好样本数 |
| $G_T$ | 总体的好样本数    |

$$
WOE_i = \ln(\frac{B_i}{B_T}/\frac{G_i}{G_T})=\ln(\frac{B_i}{B_T})-\ln(\frac{G_i}{G_T})\\
IV_i = (\frac{B_i}{B_T}-\frac{G_i}{G_T})\times WOE_i\\
IV = \sum_{i=1}^mIV_i
$$

分箱后过程中需要注意：分箱时需要注意样本量充足，保证统计意义；若相邻分箱的WOE值相同，则将其合并为一个分箱；当一个分箱内只有好人或坏人时，可对WOE公式进行修正如下
$$
WOE_i = \ln(\frac{B_i+0.5}{B_T})-\ln(\frac{G_i+0.5}{G_T})
$$

分箱后，有时候需要保证每个分箱（除null分箱外）里woe值满足单调性，若不满足，则重新分箱（具体根据业务实际情况确定）。在实践中，我们还需跨数据集检验WOE分箱的单调性。如果在训练集上保持单调，但在验证集和测试集上发生翻转而不单调，那么说明分箱并不合理，需要再次调整。



##### 变量筛选

技术指标包括：

> 基于缺失率（Missing Rate）
> 基于变异系数（Coefficient of Variation，CV）
> 基于稳定性（Population Stability Index，PSI）
> 基于信息量（Information Value，IV）
> 基于RF/XGBoost特征重要性（Feature Importance）
> 变量聚类（Variable Cluster，VarClus）
> 基于线性相关性（Linear Correlation）
> 基于多重共线性（Multicollinearity）
> 基于逐步回归（stepwise)
> 基于P-Vaule显著性检验

IV称为信息价值(information value)，是目前评分卡模型中筛选变量最常用的指标之一，自变量的IV值越大，表示自变量的预测能力越强。类似的指标还有信息增益、基尼(gini)系数等。常用判断标准如下：

| IV范围                 | 预测能力   |
| ---------------------- | ---------- |
| $\text{IV}<0.02$       | 无效       |
| $0.02\le\text{IV}<0.1$ | 弱预测能力 |
| $0.1\le\text{IV}<0.2$  | 中预测能力 |
| $0.2\le\text{IV}$      | 强预测能力 |

##### 模型训练

该模块主要包括变量变换（如分箱）、样本准备（包括样本赋权、拒绝推断等）、模型参数估计、模型分数校准、模型文件保存等功能。

> WOE转换（Weight of Evidence）
> 样本权重（Sample Weight）
> 拒绝演绎（Reject Inference）
> 参数估计（Parameter Estimation）
> 分数校准（Calibration）
> 模型保存（Save Model）

##### 模型评估

根据预测为正例的样本从大到小排序，依次选取截断点，计算后绘图。

| 指标       | 含义                                                         |
| ---------- | ------------------------------------------------------------ |
| `ROC`      | x轴：`FPR`，y轴：`TPR`                                       |
| `RP`曲线   | x轴：召回率，y轴：精准率                                     |
| `KS`曲线   | 将预测值分成$N$等分，用`TPR​`和`FPR`分别作为纵坐标得到两个曲线 |
| `Lift`曲线 | x轴：分箱，y轴：`lift`                                       |
| `Gain`曲线 | x轴：`depth`，y轴：`PV+`                                     |
| `AUC`      | `ROC​`曲线下面积                                              |
| `KS`值     | `KS​`曲线之间的最大间隔距离                                   |
| `Gini`系数 | $2\times \text{AUC}-1$                                       |
| `PSI`      |                                                              |

| 相关概念 | 含义                                    |
| -------- | --------------------------------------- |
| `FPR`    | `FP/(FP+TN)`                            |
| `TPR`    | `TP/(TP+FN)`                            |
| 召回率   | `TP/(TP+FN)`                            |
| 精准率   | `TP/(TP+FP)`                            |
| `depth`  | 预测成正例的比例                        |
| `lift`   | $\frac{\text{精准率}}{\text{正例占比}}$ |
| `PV+`    | $\frac{TP}{TP+FP}$                      |

模型想过评估：区分效果评估，模型KS大小；训练、测试、样本外KS对比，稳定性评估

模型不能一味的追求高KS，所有变量在建模过程中都针对显著性、相关性、冗余及多重共线性进行测试。如果变量在各维度上不能符合标准，即使会牺牲KS，也将被从模型中剔除。

| $\text{KS}$范围          | 说明                                                         |
| ------------------------ | ------------------------------------------------------------ |
| $\text{KS}<0.2$          | 模型的区分能力不高，价值不大                                 |
| $0.2\le\text{KS}<0.4$    | 一般金融机构开发的评分模型KS大部分都集中在这个区间内,模型具有一定的使用价值，此时可以结合其他指标继续观察调优模型 |
| $0.4\le\text{KS}\le 0.7$ | 模型区分能力比较好，模型有应用价值                           |
| $\text{KS}>0.7$          | 模型好的难以令人置信，可能在变量中加入了业务目标衍生指标，需要对模型特征工程进行排查。 |

| $\text{Gini}$范围           | 说明                                |
| --------------------------- | ----------------------------------- |
| $\text{Gini}<0.3$           | 模型不太能接受                      |
| $0.3\le\text{Gini}<0.35$    | 模型区分能力一般，模型有优化空间    |
| $0.35\le\text{Gini}\le 0.5$ | 模型区分能力比较满意                |
| $\text{Gini}>0.5$           | $\text{Gini}$越高越有过拟合的可能性 |

虽然`Gini`指标与`KS`一样也是金融评分模型界通用的核心指标，但是它的使用也是有2点需要注意的地方：评估评分卡的区分能力时，如果坏客户的定义不是那么严格，`Gini`系数对应代表的区分能力可能被夸大效果；`Gini`对目标变量类别的定义比较敏感，比如账户的好坏。