##### 方差分析

方差分析是通过检验各个总体均值是否相等来判断分类型自变量对数值型自变量是否有显著影响。在方差分析中，所要检验的对象称为因素，因素的不同表现称为水平，因素的每一个水平都可以看作一个总体，每个因素水平下得到样本数据称为观测值。

基本假定：每个总体都应符合正态分布；各个总体的方差$\sigma^2$必须相同；观测是独立的。

###### 误差分解

水平内部的数据误差称为组内误差，它是由抽样的随机性造成的随机误差。显然，组内误差只含有随机误差。不同水平之间的数据误差称为组间误差，它可能由抽样造成的随机误差，也可能是由因素的不同水平造成的系统误差。组间误差是随机误差和系统误差的总和。反映全部数据误差大小的平方和称为总平方和，反映组内误差大小的平方和称为组内平方和，反映组间误差大小的平方和称为组间平方和。如果因素的不同水平对每个水平下的均值没有影响，则组间误差只有随机误差而没有系统误差。组内误差和组间误差的均方之比应该接近1；否则它们的比值就会大于1，当大到某个程度时，就认为因素的不同水平之间存在着显著差异，也即自变量对因变量有显著影响。

###### 单因素方差分析

设有$k$组样本，每组有$n_i$个独立样本，$N$为样本总数。定义零假设$H_0:\mu_1=\mu_2=\cdots=\mu_k$ 。对应的备择假设  ：$H_1:$样本均值不完全相等

| 名称       | 公式                                                         |
| ---------- | ------------------------------------------------------------ |
| 各组均值   | $\overline{x}_i=\frac{1}{n_i}\sum_{j=1}^{n_i}x_{ij}$         |
| 各组方差   | $S_i=\frac{1}{n_i-1}\sum_{j=1}^{n_i}(x_{ij}-\overline{x}_i)^2$ |
| 总体均值   | $\mu=\frac{1}{N}\sum_{i=1}^k\sum_{j=1}^{n_i}x_{ij}$          |
| 总平方和   | $SST=\sum_{i=1}^k\sum_{j=1}^{n_i}(x_{ij}-\mu)^2$             |
| 组间平方和 | $SSA=\sum_{i=1}^k(\overline{x}_i-\mu)^2*n_i$                 |
| 组内平方和 | $SSE=\sum_{i=1}^k\sum_{j=1}^{n_i}(x_{ij}-\overline{x}_i)^2$  |
| 组间方差   | $MSA=\frac{SSA}{k-1}$                                        |
| 组内方差   | $MSE=\frac{SSE}{n-k}$                                        |

将组间方差与组内方差进行对比，就得到了所需的检验统计量F，当$H_0$为真时，有
$$
F=\frac{MSA}{MSE}\sim F(k-1,n-k)
$$
若$F>F_\alpha$，则拒绝原假设，因素水平对观测值有显著影响；若$F<F_\alpha$，则接受原假设，不能认为因素水平对观测值有显著影响。

###### 双因素方差分析（无交互作用）

将一个因素放在行的位置，称为行因素，设有$k$个水平；另一个因素放在列的位置，称为列因素，设有$r$个水平。

对行因素提出的假设为：$H_0:\mu_1=\mu_2=\cdots=\mu_k$ 。对应的备择假设  ：$H_1:$样本均值不完全相等对列因素提出的假设为：$H_0:\mu_1=\mu_2=\cdots=\mu_r$ 。对应的备择假设  ：$H_1:$样本均值不完全相等

$\overline{x}_{i\cdot}$是行因素的第i个水平下的观测值的平均值：$\overline{x}_{i\cdot}=\frac{1}{r}\sum_{j=1}^{r}x_{ij}$；列因素的第j个水平下的观测值的平均值:$\overline{x}_{\cdot j}=\frac{1}{k}\sum_{j=1}^{k}x_{ij}$；所有观测值的总平均值：$\mu=\frac{1}{kr}\sum_{i=1}^k\sum_{j=1}^rx_{ij}$

| 名称                 | 公式                                                         |
| -------------------- | ------------------------------------------------------------ |
| 总平方和             | $SST=\sum_{i=1}^k\sum_{j=1}^r(x_{ij}-\mu)^2$                 |
| 行因素的组间平方和   | $SSR=\sum_{i=1}^k\sum_{j=1}^r(\overline{x}_{i\cdot}-\mu)^2$  |
| 列因素的组间平方和   | $SSC=\sum_{i=1}^k\sum_{j=1}^r(\overline{x}_{\cdot j}-\mu)^2$ |
| 剩余因素产生的平方和 | $SSE=\sum_{i=1}^k\sum_{j=1}^r(x_{ij}-\overline{x}_{i\cdot}-\overline{x}_{\cdot j}+\mu)^2$ |
| 行因素均方           | $MSR=\frac{SSR}{k-1}$                                        |
| 列因素均方           | $MSC=\frac{SSC}{r-1}$                                        |
| 随机误差均方         | $MSE=\frac{SSE}{(k-1)(r-1)}$                                 |

检验行变量对因变量的影响，采用统计量$F_R$：$F=\frac{MSR}{MSE}\sim F(k-1,(k-1)(r-1))$

检验行变量对因变量的影响，采用统计量$F_C$：$F=\frac{MSC}{MSE}\sim F(r-1,(k-1)(r-1))$

将$F_R$和$F_C$与临界值$F_\alpha$进行比较：如果$F_R>F_\alpha$，则拒绝原假设$H_0$，行因素对观测值有显著影响；如果$F_C>F_\alpha$，则拒绝原假设$H_0$，列因素对观测值有显著影响。

##### 统计检验

###### 回归检验

回归检验：适用于预测变量是数值型的情况。

|              | 预测变量       | 结果变量 |
| ------------ | -------------- | -------- |
| 简单线性回归 | 单个，连续数值 | 连续数值 |
| 多重线性回归 | 多个，连续数值 | 连续数值 |
| 逻辑回归     | 连续变量       | 二元类别 |

###### 比较检验

比较检验：适用于预测变量是类别型，结果变量是数值型的情况。 

|                    | 预测变量         | 结果变量             |
| ------------------ | ---------------- | -------------------- |
| Paired t-test      | 两组，类别       | 组来自同一总体，数值 |
| Independent t-test | 两组，类别       | 组来自不同总体，数值 |
| ANOVA              | 两组及以上，类别 | 单个，数值           |
| MANOVA             | 两组及以上，类别 | 两个及以上，数值     |

###### 关联检验

常用的只有卡方检验一种，适用于预测变量和结果变量均为类别型的情况。

#### 推断统计

##### 假设检验

显著性水平：通过小概率准则来理解，在假设检验时先确定一个小概率标准----显著性水平；用$\alpha$表示；凡出现概率小于显著性水平的事件称小概率事件；

|             | $H_0$为真          | $H_0$为假         |
| ----------- | ------------------ | ----------------- |
| 未拒绝$H_0$ | 正确               | 第二类错误$\beta$ |
| 拒绝$H_0$   | 第一类错误$\alpha$ | 正确              |

如何设置原假设：$H_0$与$H_1$是完备事件组，相互对立，有且只有一个成立；在确立假设时，先确定备设$H_1$，然后再确定$H_1$，且保证“=”总在$H_0$上；原$H_0$一般是需要反驳的，而$H_1$是需要支持的；假设检验只提供原假设不利证据

 当$H_0$采用等号，而$H_1$采用不等号，双尾检验；当$H_0$是有方向性的，单尾检验

P值：当原假设为真时，比所得到的样本观察，结果更极端的结果会出现的概率。如果P值很小，我们拒绝原假设的理由越充分。

当样本容量n够大，样本观察值符合正态分布，可采用U检验。当样本容量n较小，若观测值符合正态分布，可采用T型检验

假设检验的基本步骤：

1. 根据实际问题提出原假设$H_0$和备择假设$H_1$
2. 选择适当的显著水平$\alpha$以及样本容量$n$
3. 构造合适的检验统计量，需要考虑的因素有样本容量大小，整体方差是否已知等。
4. 根据检验统计量和显著水平，做出拒绝域
5. 根据样本观测值，计算出检验统计量的观测值
6. 做出判断，若检验统计量的观测值落在拒绝域，则拒绝原假设；否则不拒绝原假设。

###### 均值检验

![](../picture/1/298.png)

对于总体比例的检验，通常是在大样本条件下进行的，而小样本得到的结果是极不稳定的；所以对总体比例进行检验时，通常用正态分布来确定临界值，即采用$Z$统计量，$Z$统计量计算公式：
$$
z = \frac{p-\pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}
$$
$p$为样本比例；$\pi_0$为总体比例

![](../picture/1/299.png)

![](../picture/1/300.png)

##### 参数估计

参数估计 是为了判定总体数据特征性质，而从中抽取部分样本数据，通过样本的参数进而估计总体数据的特征

点估计：用样本的估计量直接作为总体参数的估计值(不能很好的说明估计出来的值与总体数据值之间的差距情况)

区间估计：在点估计的估计的基础之上，给出总体参数估计一个区间范围，该区间由样本统计量加减抽样误差而得到的

置信水平：重复抽取样本很多次，并每次构造置信区间，其中置信区间包含总体参数真值的次数所占的比值称为置信水平。

置信区间：由样本统计量所构造的总体参数的估计区间称为置信区间，统计学家在某种程度上确信这个区间会包含真正的总体参数，所以给它取名为置信区间





对于变化量的归因，一般流程如下：

1. 判断波动的严重程度，需要设置对比的参照值和波动报警的阈值；
2. 排除数据问题，比如底层表是不是有改动或者有人修改了报表中的指标规则，一般来说新上线的业务比较容易出现数据问题；
3. 定位问题环节，将$\Delta Y$在更细的维度上拆解，时间维度上可以看是什么时候开始的以及持续了多久，空间维度上可以从“人货场”各维度拆分，看看是什么用户群、商品、业务场景问题最严重；
4. 是否历史有类似情况或者波动规律；
5. 先查内因(渠道入口、转化环节、人货场)；
6. 再查外因(政策、市场、竞品等)；

横向维度上的拆解或者纵向业务环节的拆分（横向的组间差异，纵向的同比环节）