##### 数据结构

###### 数组

数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。

![](D:/MarkDown/picture/1/252.png)

###### 链表

链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。

![](D:/MarkDown/picture/1/253.png)

|              | 数组                                               | 链表                                             |
| ------------ | -------------------------------------------------- | ------------------------------------------------ |
| 内存地址     | 连续的内存空间                                     | 非连续的内存空间                                 |
| 数据长度     | 长度固定，一般不可动态扩展                         | 长度可动态变化                                   |
| 增删效率     | 低，需要移动被修改元素之后的所有元素               | 高，只需要修改指针                               |
| 查询效率     | 高，可通过数组名和下标直接访问，时间复杂度为$O(1)$ | 低，只能通过遍历节点依次查询，时间复杂度为$O(n)$ |
| 数据访问方式 | 随机访问                                           | 顺序访问                                         |

###### 跳表

跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从$O(n)$提升至$O(logn)$。跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。

![](D:/MarkDown/picture/1/254.png)

从上图可以看出，索引级的指针域除了指向下一个索引位置的指针，还有一个down指针指向低一级的链表位置，这样才能实现跳跃查询的目的。

###### 栈

栈是一种比较简单的数据结构，常用一句话描述其特性，后进先出。栈本身是一个线性表，但是在这个表中只有一个口子允许数据的进出。

栈的常用操作包括入栈push和出栈pop，对应于数据的压入和压出。还有访问栈顶数据、判断栈是否为空和判断栈的大小等。由于栈后进先出的特性，常可以作为数据操作的临时容器，对数据的顺序进行调控

###### 队列

队列是栈的兄弟结构，与栈的后进先出相对应，队列是一种先进先出的数据结构。顾名思义，队列的数据存储是如同排队一般，先存入的数据先被压出。



![](D:/MarkDown/picture/2/1.png)

###### 时间复杂度和空间复杂度

**所以好的算法应该具备时效高和存储低的特点**。这里的时效是指时间效率，也就是算法的执行时间，对于同一个问题的多种不同解决算法，执行时间越短的算法效率越高，越长的效率越低；存储是指算法在执行的时候需要的存储空间，主要是指算法程序运行的时候所占用的内存空间。

如果我们把算法程序中的每一步看作是一个基本的计量单位，那么一个算法的执行时间就可以看作是解决一个问题所需要的总步骤数。

某个特定的数据集能让算法的执行情况极好，这就是最最好情况，而另一个不同的数据会让算法的执行情况变得极差，这就是最坏情况。不过在大多数情况下，算法的执行情况都介于这两种极端情况之间，也就是平均情况。对于最优情况，没有什么大的价值，因为它没有提供什么有用信息。平均情况是对算法的一个全面评价，因为它完整全面的反映了这个算法的性质，但从另一方面来说，这种衡量并没有什么保证，并不是每个运算都能在这种情况内完成。而对于最坏情况，它提供了一种保证，这个保证运行时间将不会再坏了，**所以一般我们所算的时间复杂度是最坏情况下的时间复杂度**，这和我们平时做事要考虑到最坏的情况是一个道理。

一般情况下，我们的程序在机器上运行时，刨去需要存储程序本身的输入数据等之外，还需要存储对数据操作的存储单元。如果输入数据所占空间和算法无关，只取决于问题本身，那么只需要分析算法在实现过程中所占的辅助单元即可。如果所需的辅助单元是个常数，那么空间复杂度就是 O(1)。空间复杂度其实在这里更多的是说一下这个概念，因为当今硬件的存储量级比较大，一般不会为了稍微减少一点儿空间复杂度而大动干戈，更多的是去想怎么优化算法的时间复杂度。所以我们在日常写代码的时候就衍生出了用空间换时间的做法，并且成为常态

##### 二叉堆

堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。对于任意一个父节点的序号n来说（这里n从0算），它的子节点的序号一定是2n+1，2n+2，因此可以直接用数组来表示一个堆。不仅如此，堆还有一个性质：堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆

![](D:/MarkDown/picture/1/256.png)

###### **堆的自我调整**

对于二叉堆，如下有几种操作：插入节点；删除节点；构建二叉堆。这几种操作都是基于堆的自我调整。

插入节点：二叉堆的节点插入，插入位置是完全二叉树的最后一个位置。比如我们插入一个新节点，值是 0。

![](D:/MarkDown/picture/2/11.png)

这时候，我们让节点0的它的父节点5做比较，如果0小于5，则让新节点“上浮”，和父节点交换位置。

![](D:/MarkDown/picture/2/12.png)

继续用节点0和父节点3做比较，如果0小于3，则让新节点继续“上浮”。继续比较，最终让新节点0上浮到了堆顶位置。

删除节点：二叉堆的节点删除过程和插入过程正好相反，所删除的是处于堆顶的节点。比如我们删除最小堆的堆顶节点1。这时候，为了维持完全二叉树的结构，我们把堆的最后一个节点10补到原本堆顶的位置。接下来我们让移动到堆顶的节点10和它的左右孩子进行比较，如果左右孩子中最小的一个（显然是节点2）比节点10小，那么让节点10“下沉”。继续让节点10和它的左右孩子做比较，左右孩子中最小的是节点7，由于10大于7，让节点10继续“下沉”。

![](D:/MarkDown/picture/2/15.png)

构建二叉堆：构建二叉堆，也就是把一个无序的完全二叉树调整为二叉堆，本质上就是让**所有非叶子节点依次下沉**。首先，我们从最后一个**非叶子**节点开始，也就是从节点10开始。如果节点10大于它左右孩子中最小的一个，则节点10下沉。接下来轮到节点3，如果节点3大于它左右孩子中最小的一个，则节点3下沉。接下来轮到节点1，如果节点1大于它左右孩子中最小的一个，则节点1下沉。事实上节点1小于它的左右孩子，所以不用改变。接下来轮到节点7，如果节点7大于它左右孩子中最小的一个，则节点7下沉。

![](D:/MarkDown/picture/2/14.png)

二叉堆虽然是一颗完全二叉树，但它的存储方式并不是链式存储，而是顺序存储。换句话说，二叉堆的所有节点都存储在数组当中。假设父节点的下标是parent，那么它的左孩子下标就是 **2\*parent+1**；它的右孩子下标就是  **2\*parent+2** 。

![](D:/MarkDown/picture/2/13.png)

###### 堆排序

我们再来回顾一下堆排序算法的步骤：把无序数组构建成二叉堆。循环删除堆顶元素，移到集合尾部，调节堆产生新的堆顶。第一步，把无序数组构建成二叉堆，需要进行$n/2$次循环。每次循环调用一次$ downAdjust$方法，所以第一步的计算规模是 $ n/2 * logn$，时间复杂度$O(nlogn)$。第二步，需要进行$n-1$次循环。每次循环调用一次 $downAdjust $方法，所以第二步的计算规模是$ (n-1) * logn$ ，时间复杂度 $O(nlogn)$。两个步骤是并列关系，所以整体的时间复杂度同样是$ O(nlogn)$。

###### 优先队列

优先队列不再遵循先入先出的原则，而是分为两种情况：最大优先队列，无论入队顺序，当前最大的元素优先出队。最小优先队列，无论入队顺序，当前最小的元素优先出队。